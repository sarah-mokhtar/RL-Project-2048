{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100",
      "authorship_tag": "ABX9TyO5ByuDpS4cCojUV1yufdTv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sarah-mokhtar/RL-Project-2048/blob/main/2048PPODiffTweaks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0mfmUFGk6al",
        "outputId": "b2cd7455-0bcc-4d34-e6ce-fba705031522"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gymnasium in /usr/local/lib/python3.12/dist-packages (1.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Collecting stable-baselines3[extra]\n",
            "  Downloading stable_baselines3-2.7.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: torch<3.0,>=2.3 in /usr/local/lib/python3.12/dist-packages (from stable-baselines3[extra]) (2.9.0+cu126)\n",
            "Requirement already satisfied: cloudpickle in /usr/local/lib/python3.12/dist-packages (from stable-baselines3[extra]) (3.1.2)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from stable-baselines3[extra]) (2.2.2)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.12/dist-packages (from stable-baselines3[extra]) (3.10.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.12/dist-packages (from stable-baselines3[extra]) (4.12.0.88)\n",
            "Requirement already satisfied: pygame in /usr/local/lib/python3.12/dist-packages (from stable-baselines3[extra]) (2.6.1)\n",
            "Requirement already satisfied: tensorboard>=2.9.1 in /usr/local/lib/python3.12/dist-packages (from stable-baselines3[extra]) (2.19.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from stable-baselines3[extra]) (5.9.5)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from stable-baselines3[extra]) (4.67.1)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.12/dist-packages (from stable-baselines3[extra]) (13.9.4)\n",
            "Requirement already satisfied: ale-py>=0.9.0 in /usr/local/lib/python3.12/dist-packages (from stable-baselines3[extra]) (0.11.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.12/dist-packages (from stable-baselines3[extra]) (11.3.0)\n",
            "Requirement already satisfied: typing-extensions>=4.3.0 in /usr/local/lib/python3.12/dist-packages (from gymnasium) (4.15.0)\n",
            "Requirement already satisfied: farama-notifications>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from gymnasium) (0.0.4)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.4.0)\n",
            "Requirement already satisfied: grpcio>=1.48.2 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.76.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.10)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (25.0)\n",
            "Requirement already satisfied: protobuf!=4.24.0,>=3.19.6 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (5.29.5)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (75.2.0)\n",
            "Requirement already satisfied: six>1.9 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.17.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.1.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.20.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.6)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.1.6)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.6.77)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.6.80)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.6.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (11.3.0.4)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (10.3.7.77)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (11.7.1.2)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.5.4.2)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.6.77)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (12.6.85)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (1.11.1.6)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch<3.0,>=2.3->stable-baselines3[extra]) (3.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3[extra]) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3[extra]) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3[extra]) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3[extra]) (1.4.9)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3[extra]) (3.2.5)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.12/dist-packages (from matplotlib->stable-baselines3[extra]) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->stable-baselines3[extra]) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->stable-baselines3[extra]) (2025.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich->stable-baselines3[extra]) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich->stable-baselines3[extra]) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]) (0.1.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch<3.0,>=2.3->stable-baselines3[extra]) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]) (3.0.3)\n",
            "Downloading stable_baselines3-2.7.0-py3-none-any.whl (187 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m187.2/187.2 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: stable-baselines3\n",
            "Successfully installed stable-baselines3-2.7.0\n"
          ]
        }
      ],
      "source": [
        "!pip install stable-baselines3[extra] gymnasium numpy\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "\n",
        "\n",
        "class Game2048Env(gym.Env):\n",
        "\n",
        "\n",
        "    metadata = {\"render_modes\": [\"ansi\"], \"render_fps\": 60}\n",
        "\n",
        "    def __init__(self, render_mode=None, target_tile=2048):\n",
        "        super().__init__()\n",
        "\n",
        "        self.board_size = 4\n",
        "        self.target_tile = target_tile\n",
        "        self.observation_space = spaces.Box(\n",
        "            low=0,\n",
        "            high=15,\n",
        "            shape=(self.board_size, self.board_size),\n",
        "            dtype=np.int32,\n",
        "        )\n",
        "        self.action_space = spaces.Discrete(4)\n",
        "\n",
        "        self.render_mode = render_mode\n",
        "        self.board = np.zeros((self.board_size, self.board_size), dtype=np.int32)\n",
        "        self.score = 0\n",
        "        self.rng = np.random.default_rng()\n",
        "\n",
        "    def _slide_and_merge_line(self, line):\n",
        "        \"\"\"\n",
        "        line: 1D np.array of exponents (0 = empty)\n",
        "        Returns: (new_line, reward_from_merges)\n",
        "        \"\"\"\n",
        "        non_zero = line[line != 0].tolist()\n",
        "        new = []\n",
        "        reward = 0\n",
        "        i = 0\n",
        "        while i < len(non_zero):\n",
        "            if i + 1 < len(non_zero) and non_zero[i] == non_zero[i + 1]:\n",
        "                exp = non_zero[i] + 1\n",
        "                new.append(exp)\n",
        "                reward += 2 ** exp\n",
        "                i += 2\n",
        "            else:\n",
        "                new.append(non_zero[i])\n",
        "                i += 1\n",
        "        # pad with zeros\n",
        "        new += [0] * (len(line) - len(new))\n",
        "        return np.array(new, dtype=np.int32), reward\n",
        "\n",
        "    def _add_random_tile(self):\n",
        "        empty_positions = list(zip(*np.where(self.board == 0)))\n",
        "        if not empty_positions:\n",
        "            return\n",
        "        row, col = empty_positions[self.rng.integers(len(empty_positions))]\n",
        "\n",
        "        if self.rng.random() < 0.9:\n",
        "            self.board[row, col] = 1\n",
        "        else:\n",
        "            self.board[row, col] = 2\n",
        "\n",
        "    def _can_move(self):\n",
        "        # If any cell empty -> can move\n",
        "        if np.any(self.board == 0):\n",
        "            return True\n",
        "        # If any horizontal merge possible\n",
        "        for i in range(self.board_size):\n",
        "            for j in range(self.board_size - 1):\n",
        "                if self.board[i, j] == self.board[i, j + 1]:\n",
        "                    return True\n",
        "        # If any vertical merge possible\n",
        "        for j in range(self.board_size):\n",
        "            for i in range(self.board_size - 1):\n",
        "                if self.board[i, j] == self.board[i + 1, j]:\n",
        "                    return True\n",
        "        return False\n",
        "\n",
        "    def _get_max_tile(self):\n",
        "        exp = int(self.board.max())\n",
        "        return 0 if exp == 0 else 2 ** exp\n",
        "\n",
        "    def reset(self, seed=None, options=None):\n",
        "        super().reset(seed=seed)\n",
        "        if seed is not None:\n",
        "            self.rng = np.random.default_rng(seed)\n",
        "\n",
        "        self.board[:] = 0\n",
        "        self.score = 0\n",
        "\n",
        "        self._add_random_tile()\n",
        "        self._add_random_tile()\n",
        "\n",
        "        observation = self.board.copy()\n",
        "        info = {\"score\": self.score, \"max_tile\": self._get_max_tile()}\n",
        "        return observation, info\n",
        "\n",
        "    def step(self, action):\n",
        "        assert self.action_space.contains(action), \"Invalid action\"\n",
        "\n",
        "        old_board = self.board.copy()\n",
        "        reward = 0\n",
        "\n",
        "\n",
        "        if action == 0:  # up\n",
        "            for col in range(self.board_size):\n",
        "                line = self.board[:, col]\n",
        "                new_line, r = self._slide_and_merge_line(line)\n",
        "                self.board[:, col] = new_line\n",
        "                reward += r\n",
        "        elif action == 1:  # down\n",
        "            for col in range(self.board_size):\n",
        "                line = self.board[:, col][::-1]\n",
        "                new_line, r = self._slide_and_merge_line(line)\n",
        "                self.board[:, col] = new_line[::-1]\n",
        "                reward += r\n",
        "        elif action == 2:  # left\n",
        "            for row in range(self.board_size):\n",
        "                line = self.board[row, :]\n",
        "                new_line, r = self._slide_and_merge_line(line)\n",
        "                self.board[row, :] = new_line\n",
        "                reward += r\n",
        "        elif action == 3:  # right\n",
        "            for row in range(self.board_size):\n",
        "                line = self.board[row, :][::-1]\n",
        "                new_line, r = self._slide_and_merge_line(line)\n",
        "                self.board[row, :] = new_line[::-1]\n",
        "                reward += r\n",
        "\n",
        "        moved = not np.array_equal(old_board, self.board)\n",
        "\n",
        "        if not moved:\n",
        "            reward -= 1.0\n",
        "        else:\n",
        "            self._add_random_tile()\n",
        "\n",
        "        self.score += reward\n",
        "\n",
        "        max_tile = self._get_max_tile()\n",
        "        terminated = False\n",
        "        if not self._can_move():\n",
        "            terminated = True\n",
        "        if max_tile >= self.target_tile:\n",
        "            terminated = True\n",
        "\n",
        "        truncated = False\n",
        "\n",
        "        observation = self.board.copy()\n",
        "        info = {\"score\": self.score, \"max_tile\": max_tile}\n",
        "\n",
        "        return observation, reward, terminated, truncated, info\n",
        "\n",
        "    def render(self):\n",
        "        if self.render_mode == \"ansi\":\n",
        "            return self._board_to_string()\n",
        "        else:\n",
        "            print(self._board_to_string())\n",
        "\n",
        "    def _board_to_string(self):\n",
        "        display = []\n",
        "        for row in self.board:\n",
        "            display_row = []\n",
        "            for exp in row:\n",
        "                if exp == 0:\n",
        "                    display_row.append(\".\")\n",
        "                else:\n",
        "                    display_row.append(str(2 ** int(exp)))\n",
        "            display.append(\"\\t\".join(display_row))\n",
        "        return \"\\n\".join(display)\n"
      ],
      "metadata": {
        "id": "HLLA-2EjlU6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gymnasium as gym\n",
        "from stable_baselines3 import PPO\n",
        "from stable_baselines3.common.env_checker import check_env\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n",
        "\n",
        "# We already defined Game2048Env above\n",
        "\n",
        "\n",
        "def make_env():\n",
        "    def _init():\n",
        "        env = Game2048Env()\n",
        "        return env\n",
        "    return _init\n",
        "\n",
        "\n",
        "# Create one env to check API\n",
        "env = Game2048Env()\n",
        "check_env(env, warn=True)\n",
        "\n",
        "# Vectorized env for PPO\n",
        "vec_env = DummyVecEnv([make_env()])\n",
        "\n",
        "model = PPO(\n",
        "    \"MlpPolicy\",\n",
        "    vec_env,\n",
        "    verbose=1,\n",
        "    learning_rate=3e-4,\n",
        "    n_steps=2048,\n",
        "    batch_size=256,\n",
        "    gamma=0.99,\n",
        "    gae_lambda=0.95,\n",
        "    clip_range=0.2,\n",
        "    ent_coef=0.01,\n",
        ")\n",
        "\n",
        "# üîÅ Training ‚Äì you can increase timesteps later\n",
        "model.learn(total_timesteps=2000000)\n",
        "\n",
        "model.save(\"ppo_2048\")\n",
        "print(\"Model saved as ppo_2048.zip\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U2CAcUx2lnB4",
        "outputId": "fa1e3018-e665-4c37-c8fc-a94ee7d3e57b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "|    total_timesteps      | 1433600      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018848357 |\n",
            "|    clip_fraction        | 0.0085       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.546       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 9.44e+03     |\n",
            "|    n_updates            | 6990         |\n",
            "|    policy_gradient_loss | -0.00285     |\n",
            "|    value_loss           | 2.21e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 701          |\n",
            "|    time_elapsed         | 2457         |\n",
            "|    total_timesteps      | 1435648      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0014606611 |\n",
            "|    clip_fraction        | 0.00464      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.535       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 9.41e+03     |\n",
            "|    n_updates            | 7000         |\n",
            "|    policy_gradient_loss | -0.00308     |\n",
            "|    value_loss           | 2.35e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 702          |\n",
            "|    time_elapsed         | 2460         |\n",
            "|    total_timesteps      | 1437696      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0041113095 |\n",
            "|    clip_fraction        | 0.0421       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.542       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 9.39e+03     |\n",
            "|    n_updates            | 7010         |\n",
            "|    policy_gradient_loss | -0.005       |\n",
            "|    value_loss           | 2.09e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 703          |\n",
            "|    time_elapsed         | 2464         |\n",
            "|    total_timesteps      | 1439744      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0021986933 |\n",
            "|    clip_fraction        | 0.00508      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.575       |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 8.31e+03     |\n",
            "|    n_updates            | 7020         |\n",
            "|    policy_gradient_loss | -0.00291     |\n",
            "|    value_loss           | 2.11e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 704          |\n",
            "|    time_elapsed         | 2467         |\n",
            "|    total_timesteps      | 1441792      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0142816035 |\n",
            "|    clip_fraction        | 0.0625       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.553       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.05e+04     |\n",
            "|    n_updates            | 7030         |\n",
            "|    policy_gradient_loss | -0.00177     |\n",
            "|    value_loss           | 2.3e+04      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 705          |\n",
            "|    time_elapsed         | 2471         |\n",
            "|    total_timesteps      | 1443840      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0005339472 |\n",
            "|    clip_fraction        | 0.0019       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.573       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 9.56e+03     |\n",
            "|    n_updates            | 7040         |\n",
            "|    policy_gradient_loss | -0.00136     |\n",
            "|    value_loss           | 2.26e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 706          |\n",
            "|    time_elapsed         | 2474         |\n",
            "|    total_timesteps      | 1445888      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0012651911 |\n",
            "|    clip_fraction        | 0.013        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.571       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1e+04        |\n",
            "|    n_updates            | 7050         |\n",
            "|    policy_gradient_loss | -0.00202     |\n",
            "|    value_loss           | 2.12e+04     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 584         |\n",
            "|    iterations           | 707         |\n",
            "|    time_elapsed         | 2478        |\n",
            "|    total_timesteps      | 1447936     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002289161 |\n",
            "|    clip_fraction        | 0.0398      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.528      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.07e+04    |\n",
            "|    n_updates            | 7060        |\n",
            "|    policy_gradient_loss | -0.005      |\n",
            "|    value_loss           | 2.32e+04    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 708          |\n",
            "|    time_elapsed         | 2481         |\n",
            "|    total_timesteps      | 1449984      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0030338094 |\n",
            "|    clip_fraction        | 0.0302       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.543       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.1e+04      |\n",
            "|    n_updates            | 7070         |\n",
            "|    policy_gradient_loss | -0.00463     |\n",
            "|    value_loss           | 2.19e+04     |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 584        |\n",
            "|    iterations           | 709        |\n",
            "|    time_elapsed         | 2485       |\n",
            "|    total_timesteps      | 1452032    |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00327591 |\n",
            "|    clip_fraction        | 0.0495     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.516     |\n",
            "|    explained_variance   | 0          |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 9.65e+03   |\n",
            "|    n_updates            | 7080       |\n",
            "|    policy_gradient_loss | -0.00584   |\n",
            "|    value_loss           | 2.06e+04   |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 710          |\n",
            "|    time_elapsed         | 2488         |\n",
            "|    total_timesteps      | 1454080      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0070760627 |\n",
            "|    clip_fraction        | 0.106        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.591       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 9.03e+03     |\n",
            "|    n_updates            | 7090         |\n",
            "|    policy_gradient_loss | -0.000992    |\n",
            "|    value_loss           | 2.12e+04     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 584         |\n",
            "|    iterations           | 711         |\n",
            "|    time_elapsed         | 2492        |\n",
            "|    total_timesteps      | 1456128     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009745864 |\n",
            "|    clip_fraction        | 0.0456      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.567      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.09e+04    |\n",
            "|    n_updates            | 7100        |\n",
            "|    policy_gradient_loss | -0.00486    |\n",
            "|    value_loss           | 2.1e+04     |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 584         |\n",
            "|    iterations           | 712         |\n",
            "|    time_elapsed         | 2495        |\n",
            "|    total_timesteps      | 1458176     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006391137 |\n",
            "|    clip_fraction        | 0.101       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.566      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.11e+04    |\n",
            "|    n_updates            | 7110        |\n",
            "|    policy_gradient_loss | -0.00509    |\n",
            "|    value_loss           | 2.12e+04    |\n",
            "-----------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 584           |\n",
            "|    iterations           | 713           |\n",
            "|    time_elapsed         | 2499          |\n",
            "|    total_timesteps      | 1460224       |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00013457594 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.578        |\n",
            "|    explained_variance   | 1.19e-07      |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 1.02e+04      |\n",
            "|    n_updates            | 7120          |\n",
            "|    policy_gradient_loss | -0.00068      |\n",
            "|    value_loss           | 2.17e+04      |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 714          |\n",
            "|    time_elapsed         | 2502         |\n",
            "|    total_timesteps      | 1462272      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0047863517 |\n",
            "|    clip_fraction        | 0.0396       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.581       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.23e+04     |\n",
            "|    n_updates            | 7130         |\n",
            "|    policy_gradient_loss | -0.00318     |\n",
            "|    value_loss           | 2.15e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 715          |\n",
            "|    time_elapsed         | 2506         |\n",
            "|    total_timesteps      | 1464320      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0041372683 |\n",
            "|    clip_fraction        | 0.0464       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.569       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.27e+04     |\n",
            "|    n_updates            | 7140         |\n",
            "|    policy_gradient_loss | -0.00749     |\n",
            "|    value_loss           | 2.29e+04     |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 584           |\n",
            "|    iterations           | 716           |\n",
            "|    time_elapsed         | 2509          |\n",
            "|    total_timesteps      | 1466368       |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00066841906 |\n",
            "|    clip_fraction        | 9.77e-05      |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.587        |\n",
            "|    explained_variance   | 0             |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 1.03e+04      |\n",
            "|    n_updates            | 7150          |\n",
            "|    policy_gradient_loss | -0.00149      |\n",
            "|    value_loss           | 1.98e+04      |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 584         |\n",
            "|    iterations           | 717         |\n",
            "|    time_elapsed         | 2513        |\n",
            "|    total_timesteps      | 1468416     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003274487 |\n",
            "|    clip_fraction        | 0.0838      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.582      |\n",
            "|    explained_variance   | 1.19e-07    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.16e+04    |\n",
            "|    n_updates            | 7160        |\n",
            "|    policy_gradient_loss | -0.000493   |\n",
            "|    value_loss           | 2.16e+04    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 584         |\n",
            "|    iterations           | 718         |\n",
            "|    time_elapsed         | 2516        |\n",
            "|    total_timesteps      | 1470464     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008129628 |\n",
            "|    clip_fraction        | 0.0298      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.566      |\n",
            "|    explained_variance   | 5.96e-08    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.13e+04    |\n",
            "|    n_updates            | 7170        |\n",
            "|    policy_gradient_loss | -0.000301   |\n",
            "|    value_loss           | 2.21e+04    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 719          |\n",
            "|    time_elapsed         | 2520         |\n",
            "|    total_timesteps      | 1472512      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017819582 |\n",
            "|    clip_fraction        | 0.00508      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.549       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.21e+04     |\n",
            "|    n_updates            | 7180         |\n",
            "|    policy_gradient_loss | -0.00315     |\n",
            "|    value_loss           | 1.94e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 720          |\n",
            "|    time_elapsed         | 2523         |\n",
            "|    total_timesteps      | 1474560      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034948282 |\n",
            "|    clip_fraction        | 0.0345       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.578       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.25e+04     |\n",
            "|    n_updates            | 7190         |\n",
            "|    policy_gradient_loss | -0.00426     |\n",
            "|    value_loss           | 2.15e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 721          |\n",
            "|    time_elapsed         | 2527         |\n",
            "|    total_timesteps      | 1476608      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0048420234 |\n",
            "|    clip_fraction        | 0.0789       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.579       |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.09e+04     |\n",
            "|    n_updates            | 7200         |\n",
            "|    policy_gradient_loss | -0.00347     |\n",
            "|    value_loss           | 2.28e+04     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 584         |\n",
            "|    iterations           | 722         |\n",
            "|    time_elapsed         | 2530        |\n",
            "|    total_timesteps      | 1478656     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005022879 |\n",
            "|    clip_fraction        | 0.044       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.599      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.24e+04    |\n",
            "|    n_updates            | 7210        |\n",
            "|    policy_gradient_loss | -0.0059     |\n",
            "|    value_loss           | 2.11e+04    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 584         |\n",
            "|    iterations           | 723         |\n",
            "|    time_elapsed         | 2534        |\n",
            "|    total_timesteps      | 1480704     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004045033 |\n",
            "|    clip_fraction        | 0.0478      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.58       |\n",
            "|    explained_variance   | 5.96e-08    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 9.83e+03    |\n",
            "|    n_updates            | 7220        |\n",
            "|    policy_gradient_loss | 0.00118     |\n",
            "|    value_loss           | 2.23e+04    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 724          |\n",
            "|    time_elapsed         | 2537         |\n",
            "|    total_timesteps      | 1482752      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0025072414 |\n",
            "|    clip_fraction        | 0.0476       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.604       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 9.38e+03     |\n",
            "|    n_updates            | 7230         |\n",
            "|    policy_gradient_loss | -0.00429     |\n",
            "|    value_loss           | 1.95e+04     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 584         |\n",
            "|    iterations           | 725         |\n",
            "|    time_elapsed         | 2541        |\n",
            "|    total_timesteps      | 1484800     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004231872 |\n",
            "|    clip_fraction        | 0.0544      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.611      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.07e+04    |\n",
            "|    n_updates            | 7240        |\n",
            "|    policy_gradient_loss | -0.0017     |\n",
            "|    value_loss           | 1.97e+04    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 726          |\n",
            "|    time_elapsed         | 2544         |\n",
            "|    total_timesteps      | 1486848      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0022444143 |\n",
            "|    clip_fraction        | 0.0041       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.645       |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 9.49e+03     |\n",
            "|    n_updates            | 7250         |\n",
            "|    policy_gradient_loss | -0.00229     |\n",
            "|    value_loss           | 2.01e+04     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 584         |\n",
            "|    iterations           | 727         |\n",
            "|    time_elapsed         | 2548        |\n",
            "|    total_timesteps      | 1488896     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001008624 |\n",
            "|    clip_fraction        | 0.00181     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.605      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.11e+04    |\n",
            "|    n_updates            | 7260        |\n",
            "|    policy_gradient_loss | -0.00313    |\n",
            "|    value_loss           | 2.28e+04    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 728          |\n",
            "|    time_elapsed         | 2551         |\n",
            "|    total_timesteps      | 1490944      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017798685 |\n",
            "|    clip_fraction        | 0.0118       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.602       |\n",
            "|    explained_variance   | 1.19e-07     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.1e+04      |\n",
            "|    n_updates            | 7270         |\n",
            "|    policy_gradient_loss | -0.00375     |\n",
            "|    value_loss           | 1.96e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 729          |\n",
            "|    time_elapsed         | 2555         |\n",
            "|    total_timesteps      | 1492992      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0045749666 |\n",
            "|    clip_fraction        | 0.0139       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.63        |\n",
            "|    explained_variance   | 1.19e-07     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.31e+04     |\n",
            "|    n_updates            | 7280         |\n",
            "|    policy_gradient_loss | -0.00383     |\n",
            "|    value_loss           | 2.16e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 730          |\n",
            "|    time_elapsed         | 2558         |\n",
            "|    total_timesteps      | 1495040      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017099647 |\n",
            "|    clip_fraction        | 0.00234      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.596       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.34e+04     |\n",
            "|    n_updates            | 7290         |\n",
            "|    policy_gradient_loss | -0.0028      |\n",
            "|    value_loss           | 2.34e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 731          |\n",
            "|    time_elapsed         | 2562         |\n",
            "|    total_timesteps      | 1497088      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034033027 |\n",
            "|    clip_fraction        | 0.0383       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.592       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.14e+04     |\n",
            "|    n_updates            | 7300         |\n",
            "|    policy_gradient_loss | -0.00323     |\n",
            "|    value_loss           | 2.22e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 732          |\n",
            "|    time_elapsed         | 2565         |\n",
            "|    total_timesteps      | 1499136      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032295599 |\n",
            "|    clip_fraction        | 0.0241       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.626       |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.14e+04     |\n",
            "|    n_updates            | 7310         |\n",
            "|    policy_gradient_loss | -0.00578     |\n",
            "|    value_loss           | 2.25e+04     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 584         |\n",
            "|    iterations           | 733         |\n",
            "|    time_elapsed         | 2569        |\n",
            "|    total_timesteps      | 1501184     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002349459 |\n",
            "|    clip_fraction        | 0.0153      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.605      |\n",
            "|    explained_variance   | -1.19e-07   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 9.98e+03    |\n",
            "|    n_updates            | 7320        |\n",
            "|    policy_gradient_loss | -0.00236    |\n",
            "|    value_loss           | 2.35e+04    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 734          |\n",
            "|    time_elapsed         | 2572         |\n",
            "|    total_timesteps      | 1503232      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0027168705 |\n",
            "|    clip_fraction        | 0.0215       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.636       |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.09e+04     |\n",
            "|    n_updates            | 7330         |\n",
            "|    policy_gradient_loss | -0.0013      |\n",
            "|    value_loss           | 2.04e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 735          |\n",
            "|    time_elapsed         | 2576         |\n",
            "|    total_timesteps      | 1505280      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036433353 |\n",
            "|    clip_fraction        | 0.0572       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.578       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 9.92e+03     |\n",
            "|    n_updates            | 7340         |\n",
            "|    policy_gradient_loss | 0.000495     |\n",
            "|    value_loss           | 2.09e+04     |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 584           |\n",
            "|    iterations           | 736           |\n",
            "|    time_elapsed         | 2579          |\n",
            "|    total_timesteps      | 1507328       |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00013388088 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.582        |\n",
            "|    explained_variance   | 0             |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 1.12e+04      |\n",
            "|    n_updates            | 7350          |\n",
            "|    policy_gradient_loss | -0.000816     |\n",
            "|    value_loss           | 1.96e+04      |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 737          |\n",
            "|    time_elapsed         | 2583         |\n",
            "|    total_timesteps      | 1509376      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0048487717 |\n",
            "|    clip_fraction        | 0.0161       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.639       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.06e+04     |\n",
            "|    n_updates            | 7360         |\n",
            "|    policy_gradient_loss | -0.00226     |\n",
            "|    value_loss           | 2.06e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 738          |\n",
            "|    time_elapsed         | 2586         |\n",
            "|    total_timesteps      | 1511424      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0019840966 |\n",
            "|    clip_fraction        | 0.00391      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.55        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 9.31e+03     |\n",
            "|    n_updates            | 7370         |\n",
            "|    policy_gradient_loss | -0.00293     |\n",
            "|    value_loss           | 1.87e+04     |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 584           |\n",
            "|    iterations           | 739           |\n",
            "|    time_elapsed         | 2590          |\n",
            "|    total_timesteps      | 1513472       |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00056713144 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.608        |\n",
            "|    explained_variance   | 0             |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 1.27e+04      |\n",
            "|    n_updates            | 7380          |\n",
            "|    policy_gradient_loss | 5.45e-05      |\n",
            "|    value_loss           | 2.29e+04      |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 584           |\n",
            "|    iterations           | 740           |\n",
            "|    time_elapsed         | 2593          |\n",
            "|    total_timesteps      | 1515520       |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00064449874 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.566        |\n",
            "|    explained_variance   | 0             |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 1.06e+04      |\n",
            "|    n_updates            | 7390          |\n",
            "|    policy_gradient_loss | -0.000723     |\n",
            "|    value_loss           | 2.24e+04      |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 584         |\n",
            "|    iterations           | 741         |\n",
            "|    time_elapsed         | 2597        |\n",
            "|    total_timesteps      | 1517568     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009704782 |\n",
            "|    clip_fraction        | 0.0393      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.595      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 9.96e+03    |\n",
            "|    n_updates            | 7400        |\n",
            "|    policy_gradient_loss | -0.00183    |\n",
            "|    value_loss           | 2.07e+04    |\n",
            "-----------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 584           |\n",
            "|    iterations           | 742           |\n",
            "|    time_elapsed         | 2600          |\n",
            "|    total_timesteps      | 1519616       |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00061955734 |\n",
            "|    clip_fraction        | 4.88e-05      |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.597        |\n",
            "|    explained_variance   | 0             |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 1.06e+04      |\n",
            "|    n_updates            | 7410          |\n",
            "|    policy_gradient_loss | -0.00146      |\n",
            "|    value_loss           | 2.17e+04      |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 584           |\n",
            "|    iterations           | 743           |\n",
            "|    time_elapsed         | 2604          |\n",
            "|    total_timesteps      | 1521664       |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00039796458 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.608        |\n",
            "|    explained_variance   | 0             |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 9.95e+03      |\n",
            "|    n_updates            | 7420          |\n",
            "|    policy_gradient_loss | -0.00152      |\n",
            "|    value_loss           | 1.94e+04      |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 584         |\n",
            "|    iterations           | 744         |\n",
            "|    time_elapsed         | 2607        |\n",
            "|    total_timesteps      | 1523712     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010334246 |\n",
            "|    clip_fraction        | 0.0558      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.573      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 8.45e+03    |\n",
            "|    n_updates            | 7430        |\n",
            "|    policy_gradient_loss | -0.00137    |\n",
            "|    value_loss           | 2.11e+04    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 745          |\n",
            "|    time_elapsed         | 2611         |\n",
            "|    total_timesteps      | 1525760      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0024405522 |\n",
            "|    clip_fraction        | 0.0365       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.632       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 9.05e+03     |\n",
            "|    n_updates            | 7440         |\n",
            "|    policy_gradient_loss | -0.00492     |\n",
            "|    value_loss           | 1.86e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 746          |\n",
            "|    time_elapsed         | 2614         |\n",
            "|    total_timesteps      | 1527808      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035045757 |\n",
            "|    clip_fraction        | 0.0212       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.589       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.23e+04     |\n",
            "|    n_updates            | 7450         |\n",
            "|    policy_gradient_loss | -0.0055      |\n",
            "|    value_loss           | 2.06e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 747          |\n",
            "|    time_elapsed         | 2618         |\n",
            "|    total_timesteps      | 1529856      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028394363 |\n",
            "|    clip_fraction        | 0.0122       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.587       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.31e+04     |\n",
            "|    n_updates            | 7460         |\n",
            "|    policy_gradient_loss | -0.00484     |\n",
            "|    value_loss           | 2.14e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 748          |\n",
            "|    time_elapsed         | 2621         |\n",
            "|    total_timesteps      | 1531904      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0026765675 |\n",
            "|    clip_fraction        | 0.0504       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.599       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.15e+04     |\n",
            "|    n_updates            | 7470         |\n",
            "|    policy_gradient_loss | -0.00367     |\n",
            "|    value_loss           | 2.15e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 749          |\n",
            "|    time_elapsed         | 2625         |\n",
            "|    total_timesteps      | 1533952      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0027432765 |\n",
            "|    clip_fraction        | 0.0378       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.581       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 8.58e+03     |\n",
            "|    n_updates            | 7480         |\n",
            "|    policy_gradient_loss | -0.00247     |\n",
            "|    value_loss           | 2.12e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 750          |\n",
            "|    time_elapsed         | 2628         |\n",
            "|    total_timesteps      | 1536000      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0026528866 |\n",
            "|    clip_fraction        | 0.0141       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.598       |\n",
            "|    explained_variance   | 5.96e-08     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.12e+04     |\n",
            "|    n_updates            | 7490         |\n",
            "|    policy_gradient_loss | -0.00391     |\n",
            "|    value_loss           | 2.2e+04      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 751          |\n",
            "|    time_elapsed         | 2632         |\n",
            "|    total_timesteps      | 1538048      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0039179637 |\n",
            "|    clip_fraction        | 0.0397       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.629       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.2e+04      |\n",
            "|    n_updates            | 7500         |\n",
            "|    policy_gradient_loss | -0.00357     |\n",
            "|    value_loss           | 2.16e+04     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 584         |\n",
            "|    iterations           | 752         |\n",
            "|    time_elapsed         | 2635        |\n",
            "|    total_timesteps      | 1540096     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004553512 |\n",
            "|    clip_fraction        | 0.0572      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.624      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 9.58e+03    |\n",
            "|    n_updates            | 7510        |\n",
            "|    policy_gradient_loss | -0.00657    |\n",
            "|    value_loss           | 2.07e+04    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 584         |\n",
            "|    iterations           | 753         |\n",
            "|    time_elapsed         | 2639        |\n",
            "|    total_timesteps      | 1542144     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007990491 |\n",
            "|    clip_fraction        | 0.0316      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.63       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.06e+04    |\n",
            "|    n_updates            | 7520        |\n",
            "|    policy_gradient_loss | -0.00587    |\n",
            "|    value_loss           | 2.12e+04    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 584         |\n",
            "|    iterations           | 754         |\n",
            "|    time_elapsed         | 2642        |\n",
            "|    total_timesteps      | 1544192     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004200085 |\n",
            "|    clip_fraction        | 0.0253      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.649      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.07e+04    |\n",
            "|    n_updates            | 7530        |\n",
            "|    policy_gradient_loss | -0.00701    |\n",
            "|    value_loss           | 2.02e+04    |\n",
            "-----------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 584           |\n",
            "|    iterations           | 755           |\n",
            "|    time_elapsed         | 2646          |\n",
            "|    total_timesteps      | 1546240       |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00068508624 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.661        |\n",
            "|    explained_variance   | 0             |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 1.36e+04      |\n",
            "|    n_updates            | 7540          |\n",
            "|    policy_gradient_loss | -0.000752     |\n",
            "|    value_loss           | 2.2e+04       |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 756          |\n",
            "|    time_elapsed         | 2649         |\n",
            "|    total_timesteps      | 1548288      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015905474 |\n",
            "|    clip_fraction        | 0.0222       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.668       |\n",
            "|    explained_variance   | 1.19e-07     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1e+04        |\n",
            "|    n_updates            | 7550         |\n",
            "|    policy_gradient_loss | -0.00402     |\n",
            "|    value_loss           | 2.08e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 757          |\n",
            "|    time_elapsed         | 2653         |\n",
            "|    total_timesteps      | 1550336      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0025158734 |\n",
            "|    clip_fraction        | 0.0122       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.622       |\n",
            "|    explained_variance   | 5.96e-08     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.42e+04     |\n",
            "|    n_updates            | 7560         |\n",
            "|    policy_gradient_loss | -0.00389     |\n",
            "|    value_loss           | 2.41e+04     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 584         |\n",
            "|    iterations           | 758         |\n",
            "|    time_elapsed         | 2656        |\n",
            "|    total_timesteps      | 1552384     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002355074 |\n",
            "|    clip_fraction        | 0.0216      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.614      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.17e+04    |\n",
            "|    n_updates            | 7570        |\n",
            "|    policy_gradient_loss | -0.00309    |\n",
            "|    value_loss           | 2.27e+04    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 759          |\n",
            "|    time_elapsed         | 2660         |\n",
            "|    total_timesteps      | 1554432      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017874232 |\n",
            "|    clip_fraction        | 0.0265       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.639       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.02e+04     |\n",
            "|    n_updates            | 7580         |\n",
            "|    policy_gradient_loss | -0.00101     |\n",
            "|    value_loss           | 2.15e+04     |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 584           |\n",
            "|    iterations           | 760           |\n",
            "|    time_elapsed         | 2663          |\n",
            "|    total_timesteps      | 1556480       |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00041527487 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.63         |\n",
            "|    explained_variance   | 0             |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 9.11e+03      |\n",
            "|    n_updates            | 7590          |\n",
            "|    policy_gradient_loss | -0.00152      |\n",
            "|    value_loss           | 2.31e+04      |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 761          |\n",
            "|    time_elapsed         | 2667         |\n",
            "|    total_timesteps      | 1558528      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0054100878 |\n",
            "|    clip_fraction        | 0.0541       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.606       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.03e+04     |\n",
            "|    n_updates            | 7600         |\n",
            "|    policy_gradient_loss | -0.00599     |\n",
            "|    value_loss           | 2.24e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 762          |\n",
            "|    time_elapsed         | 2670         |\n",
            "|    total_timesteps      | 1560576      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0019425538 |\n",
            "|    clip_fraction        | 0.0254       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.634       |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.1e+04      |\n",
            "|    n_updates            | 7610         |\n",
            "|    policy_gradient_loss | -0.00333     |\n",
            "|    value_loss           | 2.25e+04     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 584         |\n",
            "|    iterations           | 763         |\n",
            "|    time_elapsed         | 2674        |\n",
            "|    total_timesteps      | 1562624     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004865854 |\n",
            "|    clip_fraction        | 0.0667      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.614      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.04e+04    |\n",
            "|    n_updates            | 7620        |\n",
            "|    policy_gradient_loss | -0.00206    |\n",
            "|    value_loss           | 2.31e+04    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 584         |\n",
            "|    iterations           | 764         |\n",
            "|    time_elapsed         | 2677        |\n",
            "|    total_timesteps      | 1564672     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011129973 |\n",
            "|    clip_fraction        | 0.0734      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.64       |\n",
            "|    explained_variance   | 1.19e-07    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 7.95e+03    |\n",
            "|    n_updates            | 7630        |\n",
            "|    policy_gradient_loss | -0.00518    |\n",
            "|    value_loss           | 2.09e+04    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 584         |\n",
            "|    iterations           | 765         |\n",
            "|    time_elapsed         | 2681        |\n",
            "|    total_timesteps      | 1566720     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005427701 |\n",
            "|    clip_fraction        | 0.0499      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.653      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.32e+04    |\n",
            "|    n_updates            | 7640        |\n",
            "|    policy_gradient_loss | -0.00128    |\n",
            "|    value_loss           | 2.1e+04     |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 584         |\n",
            "|    iterations           | 766         |\n",
            "|    time_elapsed         | 2684        |\n",
            "|    total_timesteps      | 1568768     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002543995 |\n",
            "|    clip_fraction        | 0.0191      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.705      |\n",
            "|    explained_variance   | 1.19e-07    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.06e+04    |\n",
            "|    n_updates            | 7650        |\n",
            "|    policy_gradient_loss | -0.00371    |\n",
            "|    value_loss           | 2.09e+04    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 584         |\n",
            "|    iterations           | 767         |\n",
            "|    time_elapsed         | 2688        |\n",
            "|    total_timesteps      | 1570816     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005742478 |\n",
            "|    clip_fraction        | 0.037       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.671      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.24e+04    |\n",
            "|    n_updates            | 7660        |\n",
            "|    policy_gradient_loss | -0.0033     |\n",
            "|    value_loss           | 2.15e+04    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 768          |\n",
            "|    time_elapsed         | 2691         |\n",
            "|    total_timesteps      | 1572864      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0053549404 |\n",
            "|    clip_fraction        | 0.0299       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.667       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.2e+04      |\n",
            "|    n_updates            | 7670         |\n",
            "|    policy_gradient_loss | -0.00274     |\n",
            "|    value_loss           | 2.28e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 769          |\n",
            "|    time_elapsed         | 2695         |\n",
            "|    total_timesteps      | 1574912      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0040193647 |\n",
            "|    clip_fraction        | 0.13         |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.687       |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.3e+04      |\n",
            "|    n_updates            | 7680         |\n",
            "|    policy_gradient_loss | 0.00441      |\n",
            "|    value_loss           | 2.18e+04     |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 584           |\n",
            "|    iterations           | 770           |\n",
            "|    time_elapsed         | 2698          |\n",
            "|    total_timesteps      | 1576960       |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00030967165 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.689        |\n",
            "|    explained_variance   | 0             |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 9.58e+03      |\n",
            "|    n_updates            | 7690          |\n",
            "|    policy_gradient_loss | -0.00107      |\n",
            "|    value_loss           | 2.16e+04      |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 584         |\n",
            "|    iterations           | 771         |\n",
            "|    time_elapsed         | 2702        |\n",
            "|    total_timesteps      | 1579008     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002771562 |\n",
            "|    clip_fraction        | 0.0169      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.689      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 8.14e+03    |\n",
            "|    n_updates            | 7700        |\n",
            "|    policy_gradient_loss | -0.00384    |\n",
            "|    value_loss           | 2.2e+04     |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 772          |\n",
            "|    time_elapsed         | 2705         |\n",
            "|    total_timesteps      | 1581056      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032728026 |\n",
            "|    clip_fraction        | 0.00835      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.658       |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.13e+04     |\n",
            "|    n_updates            | 7710         |\n",
            "|    policy_gradient_loss | -0.00396     |\n",
            "|    value_loss           | 2e+04        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 773          |\n",
            "|    time_elapsed         | 2709         |\n",
            "|    total_timesteps      | 1583104      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0054868665 |\n",
            "|    clip_fraction        | 0.0819       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.664       |\n",
            "|    explained_variance   | 5.96e-08     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.18e+04     |\n",
            "|    n_updates            | 7720         |\n",
            "|    policy_gradient_loss | -0.00269     |\n",
            "|    value_loss           | 2.19e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 774          |\n",
            "|    time_elapsed         | 2712         |\n",
            "|    total_timesteps      | 1585152      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0047264406 |\n",
            "|    clip_fraction        | 0.0543       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.645       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.05e+04     |\n",
            "|    n_updates            | 7730         |\n",
            "|    policy_gradient_loss | -0.00689     |\n",
            "|    value_loss           | 2.08e+04     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 584         |\n",
            "|    iterations           | 775         |\n",
            "|    time_elapsed         | 2716        |\n",
            "|    total_timesteps      | 1587200     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002060165 |\n",
            "|    clip_fraction        | 0.00518     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.646      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.21e+04    |\n",
            "|    n_updates            | 7740        |\n",
            "|    policy_gradient_loss | -0.00305    |\n",
            "|    value_loss           | 2.26e+04    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 776          |\n",
            "|    time_elapsed         | 2719         |\n",
            "|    total_timesteps      | 1589248      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037139233 |\n",
            "|    clip_fraction        | 0.0597       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.657       |\n",
            "|    explained_variance   | 5.96e-08     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.2e+04      |\n",
            "|    n_updates            | 7750         |\n",
            "|    policy_gradient_loss | -0.00417     |\n",
            "|    value_loss           | 2.27e+04     |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 584           |\n",
            "|    iterations           | 777           |\n",
            "|    time_elapsed         | 2723          |\n",
            "|    total_timesteps      | 1591296       |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00041206396 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.696        |\n",
            "|    explained_variance   | 0             |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 1.12e+04      |\n",
            "|    n_updates            | 7760          |\n",
            "|    policy_gradient_loss | -0.00138      |\n",
            "|    value_loss           | 2.36e+04      |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 778          |\n",
            "|    time_elapsed         | 2726         |\n",
            "|    total_timesteps      | 1593344      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0004285506 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.666       |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.29e+04     |\n",
            "|    n_updates            | 7770         |\n",
            "|    policy_gradient_loss | -0.00122     |\n",
            "|    value_loss           | 2.29e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 779          |\n",
            "|    time_elapsed         | 2730         |\n",
            "|    total_timesteps      | 1595392      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0084744375 |\n",
            "|    clip_fraction        | 0.0358       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.661       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.06e+04     |\n",
            "|    n_updates            | 7780         |\n",
            "|    policy_gradient_loss | -0.00201     |\n",
            "|    value_loss           | 2.25e+04     |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 584           |\n",
            "|    iterations           | 780           |\n",
            "|    time_elapsed         | 2733          |\n",
            "|    total_timesteps      | 1597440       |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00064548914 |\n",
            "|    clip_fraction        | 0.000391      |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.691        |\n",
            "|    explained_variance   | -1.19e-07     |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 9.55e+03      |\n",
            "|    n_updates            | 7790          |\n",
            "|    policy_gradient_loss | -0.00166      |\n",
            "|    value_loss           | 2.11e+04      |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 781          |\n",
            "|    time_elapsed         | 2737         |\n",
            "|    total_timesteps      | 1599488      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0040137926 |\n",
            "|    clip_fraction        | 0.126        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.688       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.21e+04     |\n",
            "|    n_updates            | 7800         |\n",
            "|    policy_gradient_loss | 0.00189      |\n",
            "|    value_loss           | 2.35e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 782          |\n",
            "|    time_elapsed         | 2740         |\n",
            "|    total_timesteps      | 1601536      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0010040128 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.679       |\n",
            "|    explained_variance   | 5.96e-08     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.24e+04     |\n",
            "|    n_updates            | 7810         |\n",
            "|    policy_gradient_loss | -0.00233     |\n",
            "|    value_loss           | 2.45e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 783          |\n",
            "|    time_elapsed         | 2744         |\n",
            "|    total_timesteps      | 1603584      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033600698 |\n",
            "|    clip_fraction        | 0.0159       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.678       |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.27e+04     |\n",
            "|    n_updates            | 7820         |\n",
            "|    policy_gradient_loss | -0.00261     |\n",
            "|    value_loss           | 2.33e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 784          |\n",
            "|    time_elapsed         | 2747         |\n",
            "|    total_timesteps      | 1605632      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0006821725 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.679       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.08e+04     |\n",
            "|    n_updates            | 7830         |\n",
            "|    policy_gradient_loss | -0.00277     |\n",
            "|    value_loss           | 2.26e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 785          |\n",
            "|    time_elapsed         | 2751         |\n",
            "|    total_timesteps      | 1607680      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0039479984 |\n",
            "|    clip_fraction        | 0.00957      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.654       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.24e+04     |\n",
            "|    n_updates            | 7840         |\n",
            "|    policy_gradient_loss | -0.00187     |\n",
            "|    value_loss           | 2.32e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 786          |\n",
            "|    time_elapsed         | 2754         |\n",
            "|    total_timesteps      | 1609728      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0022132332 |\n",
            "|    clip_fraction        | 0.0208       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.66        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.04e+04     |\n",
            "|    n_updates            | 7850         |\n",
            "|    policy_gradient_loss | -0.00716     |\n",
            "|    value_loss           | 2.28e+04     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 584         |\n",
            "|    iterations           | 787         |\n",
            "|    time_elapsed         | 2758        |\n",
            "|    total_timesteps      | 1611776     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014541523 |\n",
            "|    clip_fraction        | 0.0449      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.688      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.14e+04    |\n",
            "|    n_updates            | 7860        |\n",
            "|    policy_gradient_loss | -0.00013    |\n",
            "|    value_loss           | 2.36e+04    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 584         |\n",
            "|    iterations           | 788         |\n",
            "|    time_elapsed         | 2761        |\n",
            "|    total_timesteps      | 1613824     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002753946 |\n",
            "|    clip_fraction        | 0.00933     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.716      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.17e+04    |\n",
            "|    n_updates            | 7870        |\n",
            "|    policy_gradient_loss | -0.00321    |\n",
            "|    value_loss           | 2.11e+04    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 789          |\n",
            "|    time_elapsed         | 2765         |\n",
            "|    total_timesteps      | 1615872      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035805213 |\n",
            "|    clip_fraction        | 0.0663       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.686       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.14e+04     |\n",
            "|    n_updates            | 7880         |\n",
            "|    policy_gradient_loss | -0.00263     |\n",
            "|    value_loss           | 2.12e+04     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 584         |\n",
            "|    iterations           | 790         |\n",
            "|    time_elapsed         | 2768        |\n",
            "|    total_timesteps      | 1617920     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003587109 |\n",
            "|    clip_fraction        | 0.0246      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.714      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.21e+04    |\n",
            "|    n_updates            | 7890        |\n",
            "|    policy_gradient_loss | -0.00493    |\n",
            "|    value_loss           | 2.51e+04    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 584         |\n",
            "|    iterations           | 791         |\n",
            "|    time_elapsed         | 2772        |\n",
            "|    total_timesteps      | 1619968     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004243497 |\n",
            "|    clip_fraction        | 0.0529      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.668      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.02e+04    |\n",
            "|    n_updates            | 7900        |\n",
            "|    policy_gradient_loss | -0.00809    |\n",
            "|    value_loss           | 2.01e+04    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 792          |\n",
            "|    time_elapsed         | 2775         |\n",
            "|    total_timesteps      | 1622016      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0076044113 |\n",
            "|    clip_fraction        | 0.0546       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.692       |\n",
            "|    explained_variance   | 5.96e-08     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 9.78e+03     |\n",
            "|    n_updates            | 7910         |\n",
            "|    policy_gradient_loss | -0.00725     |\n",
            "|    value_loss           | 2.32e+04     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 584         |\n",
            "|    iterations           | 793         |\n",
            "|    time_elapsed         | 2779        |\n",
            "|    total_timesteps      | 1624064     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008353002 |\n",
            "|    clip_fraction        | 0.139       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.704      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.13e+04    |\n",
            "|    n_updates            | 7920        |\n",
            "|    policy_gradient_loss | -0.00362    |\n",
            "|    value_loss           | 2.05e+04    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 794          |\n",
            "|    time_elapsed         | 2782         |\n",
            "|    total_timesteps      | 1626112      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0009676294 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.659       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.33e+04     |\n",
            "|    n_updates            | 7930         |\n",
            "|    policy_gradient_loss | -0.0014      |\n",
            "|    value_loss           | 2.32e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 795          |\n",
            "|    time_elapsed         | 2786         |\n",
            "|    total_timesteps      | 1628160      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0023131487 |\n",
            "|    clip_fraction        | 0.0155       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.679       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 9.98e+03     |\n",
            "|    n_updates            | 7940         |\n",
            "|    policy_gradient_loss | -0.00368     |\n",
            "|    value_loss           | 2.28e+04     |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 584           |\n",
            "|    iterations           | 796           |\n",
            "|    time_elapsed         | 2789          |\n",
            "|    total_timesteps      | 1630208       |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00058861944 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.667        |\n",
            "|    explained_variance   | 0             |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 1e+04         |\n",
            "|    n_updates            | 7950          |\n",
            "|    policy_gradient_loss | -0.0016       |\n",
            "|    value_loss           | 2.39e+04      |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 797          |\n",
            "|    time_elapsed         | 2793         |\n",
            "|    total_timesteps      | 1632256      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0025542774 |\n",
            "|    clip_fraction        | 0.00293      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.698       |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.2e+04      |\n",
            "|    n_updates            | 7960         |\n",
            "|    policy_gradient_loss | -0.00276     |\n",
            "|    value_loss           | 1.96e+04     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 584         |\n",
            "|    iterations           | 798         |\n",
            "|    time_elapsed         | 2796        |\n",
            "|    total_timesteps      | 1634304     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004413519 |\n",
            "|    clip_fraction        | 0.0128      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.635      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 9.89e+03    |\n",
            "|    n_updates            | 7970        |\n",
            "|    policy_gradient_loss | -0.00312    |\n",
            "|    value_loss           | 2.36e+04    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 799          |\n",
            "|    time_elapsed         | 2800         |\n",
            "|    total_timesteps      | 1636352      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0023679843 |\n",
            "|    clip_fraction        | 0.0137       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.687       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 8.41e+03     |\n",
            "|    n_updates            | 7980         |\n",
            "|    policy_gradient_loss | -0.0035      |\n",
            "|    value_loss           | 1.83e+04     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 584         |\n",
            "|    iterations           | 800         |\n",
            "|    time_elapsed         | 2803        |\n",
            "|    total_timesteps      | 1638400     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006788017 |\n",
            "|    clip_fraction        | 0.0545      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.684      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 9.68e+03    |\n",
            "|    n_updates            | 7990        |\n",
            "|    policy_gradient_loss | -0.00251    |\n",
            "|    value_loss           | 2.1e+04     |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 801          |\n",
            "|    time_elapsed         | 2807         |\n",
            "|    total_timesteps      | 1640448      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0056396006 |\n",
            "|    clip_fraction        | 0.104        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.655       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.22e+04     |\n",
            "|    n_updates            | 8000         |\n",
            "|    policy_gradient_loss | 0.000868     |\n",
            "|    value_loss           | 2.15e+04     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 584         |\n",
            "|    iterations           | 802         |\n",
            "|    time_elapsed         | 2810        |\n",
            "|    total_timesteps      | 1642496     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011893575 |\n",
            "|    clip_fraction        | 0.0575      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.688      |\n",
            "|    explained_variance   | 1.19e-07    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.17e+04    |\n",
            "|    n_updates            | 8010        |\n",
            "|    policy_gradient_loss | 0.000801    |\n",
            "|    value_loss           | 2.04e+04    |\n",
            "-----------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 584           |\n",
            "|    iterations           | 803           |\n",
            "|    time_elapsed         | 2814          |\n",
            "|    total_timesteps      | 1644544       |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00081340654 |\n",
            "|    clip_fraction        | 0.000195      |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.629        |\n",
            "|    explained_variance   | 1.19e-07      |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 8.79e+03      |\n",
            "|    n_updates            | 8020          |\n",
            "|    policy_gradient_loss | -0.000109     |\n",
            "|    value_loss           | 2.08e+04      |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 584           |\n",
            "|    iterations           | 804           |\n",
            "|    time_elapsed         | 2817          |\n",
            "|    total_timesteps      | 1646592       |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00040615065 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.7          |\n",
            "|    explained_variance   | 0             |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 1.25e+04      |\n",
            "|    n_updates            | 8030          |\n",
            "|    policy_gradient_loss | -0.00104      |\n",
            "|    value_loss           | 2.14e+04      |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 584         |\n",
            "|    iterations           | 805         |\n",
            "|    time_elapsed         | 2821        |\n",
            "|    total_timesteps      | 1648640     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.014034481 |\n",
            "|    clip_fraction        | 0.0189      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.629      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 9.21e+03    |\n",
            "|    n_updates            | 8040        |\n",
            "|    policy_gradient_loss | -0.00024    |\n",
            "|    value_loss           | 2.14e+04    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 806          |\n",
            "|    time_elapsed         | 2824         |\n",
            "|    total_timesteps      | 1650688      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0060434565 |\n",
            "|    clip_fraction        | 0.082        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.623       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.09e+04     |\n",
            "|    n_updates            | 8050         |\n",
            "|    policy_gradient_loss | -0.000784    |\n",
            "|    value_loss           | 2.19e+04     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 584         |\n",
            "|    iterations           | 807         |\n",
            "|    time_elapsed         | 2828        |\n",
            "|    total_timesteps      | 1652736     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.017433658 |\n",
            "|    clip_fraction        | 0.0951      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.701      |\n",
            "|    explained_variance   | 1.19e-07    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.18e+04    |\n",
            "|    n_updates            | 8060        |\n",
            "|    policy_gradient_loss | -0.00243    |\n",
            "|    value_loss           | 2.11e+04    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 808          |\n",
            "|    time_elapsed         | 2831         |\n",
            "|    total_timesteps      | 1654784      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0011227427 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.695       |\n",
            "|    explained_variance   | -2.38e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 8.24e+03     |\n",
            "|    n_updates            | 8070         |\n",
            "|    policy_gradient_loss | -0.0014      |\n",
            "|    value_loss           | 2e+04        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 809          |\n",
            "|    time_elapsed         | 2835         |\n",
            "|    total_timesteps      | 1656832      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0070534423 |\n",
            "|    clip_fraction        | 0.0535       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.687       |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.24e+04     |\n",
            "|    n_updates            | 8080         |\n",
            "|    policy_gradient_loss | -0.00454     |\n",
            "|    value_loss           | 2.21e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 810          |\n",
            "|    time_elapsed         | 2838         |\n",
            "|    total_timesteps      | 1658880      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0012350093 |\n",
            "|    clip_fraction        | 0.00195      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.637       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 8.69e+03     |\n",
            "|    n_updates            | 8090         |\n",
            "|    policy_gradient_loss | -0.00285     |\n",
            "|    value_loss           | 2.22e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 811          |\n",
            "|    time_elapsed         | 2842         |\n",
            "|    total_timesteps      | 1660928      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038049982 |\n",
            "|    clip_fraction        | 0.0277       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.674       |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.08e+04     |\n",
            "|    n_updates            | 8100         |\n",
            "|    policy_gradient_loss | -0.00666     |\n",
            "|    value_loss           | 2.36e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 812          |\n",
            "|    time_elapsed         | 2845         |\n",
            "|    total_timesteps      | 1662976      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 4.380918e-05 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.658       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 8.13e+03     |\n",
            "|    n_updates            | 8110         |\n",
            "|    policy_gradient_loss | -0.000554    |\n",
            "|    value_loss           | 1.96e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 813          |\n",
            "|    time_elapsed         | 2849         |\n",
            "|    total_timesteps      | 1665024      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034463047 |\n",
            "|    clip_fraction        | 0.00991      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.594       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.23e+04     |\n",
            "|    n_updates            | 8120         |\n",
            "|    policy_gradient_loss | -0.00628     |\n",
            "|    value_loss           | 2.22e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 814          |\n",
            "|    time_elapsed         | 2852         |\n",
            "|    total_timesteps      | 1667072      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0070475517 |\n",
            "|    clip_fraction        | 0.0419       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.629       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 9.87e+03     |\n",
            "|    n_updates            | 8130         |\n",
            "|    policy_gradient_loss | -0.00482     |\n",
            "|    value_loss           | 2.19e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 815          |\n",
            "|    time_elapsed         | 2856         |\n",
            "|    total_timesteps      | 1669120      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0076221535 |\n",
            "|    clip_fraction        | 0.0286       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.641       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.15e+04     |\n",
            "|    n_updates            | 8140         |\n",
            "|    policy_gradient_loss | -0.00279     |\n",
            "|    value_loss           | 2.34e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 816          |\n",
            "|    time_elapsed         | 2859         |\n",
            "|    total_timesteps      | 1671168      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0025657215 |\n",
            "|    clip_fraction        | 0.00713      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.608       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.01e+04     |\n",
            "|    n_updates            | 8150         |\n",
            "|    policy_gradient_loss | -0.00615     |\n",
            "|    value_loss           | 2.29e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 817          |\n",
            "|    time_elapsed         | 2863         |\n",
            "|    total_timesteps      | 1673216      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038051638 |\n",
            "|    clip_fraction        | 0.0349       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.614       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.25e+04     |\n",
            "|    n_updates            | 8160         |\n",
            "|    policy_gradient_loss | -0.00604     |\n",
            "|    value_loss           | 2.26e+04     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 584         |\n",
            "|    iterations           | 818         |\n",
            "|    time_elapsed         | 2866        |\n",
            "|    total_timesteps      | 1675264     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 5.47065e-05 |\n",
            "|    clip_fraction        | 0           |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.642      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.25e+04    |\n",
            "|    n_updates            | 8170        |\n",
            "|    policy_gradient_loss | -8.46e-05   |\n",
            "|    value_loss           | 2.21e+04    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 584         |\n",
            "|    iterations           | 819         |\n",
            "|    time_elapsed         | 2870        |\n",
            "|    total_timesteps      | 1677312     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008962976 |\n",
            "|    clip_fraction        | 0.0456      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.575      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.06e+04    |\n",
            "|    n_updates            | 8180        |\n",
            "|    policy_gradient_loss | -0.00262    |\n",
            "|    value_loss           | 1.94e+04    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 820          |\n",
            "|    time_elapsed         | 2873         |\n",
            "|    total_timesteps      | 1679360      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0064172237 |\n",
            "|    clip_fraction        | 0.0347       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.598       |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.07e+04     |\n",
            "|    n_updates            | 8190         |\n",
            "|    policy_gradient_loss | -0.00284     |\n",
            "|    value_loss           | 2.3e+04      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 821          |\n",
            "|    time_elapsed         | 2877         |\n",
            "|    total_timesteps      | 1681408      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035843118 |\n",
            "|    clip_fraction        | 0.0303       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.643       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.1e+04      |\n",
            "|    n_updates            | 8200         |\n",
            "|    policy_gradient_loss | -0.00377     |\n",
            "|    value_loss           | 2.31e+04     |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 584           |\n",
            "|    iterations           | 822           |\n",
            "|    time_elapsed         | 2880          |\n",
            "|    total_timesteps      | 1683456       |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00021075865 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.679        |\n",
            "|    explained_variance   | 0             |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 8.07e+03      |\n",
            "|    n_updates            | 8210          |\n",
            "|    policy_gradient_loss | -0.000785     |\n",
            "|    value_loss           | 2.11e+04      |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 823          |\n",
            "|    time_elapsed         | 2884         |\n",
            "|    total_timesteps      | 1685504      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0020619174 |\n",
            "|    clip_fraction        | 0.00991      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.651       |\n",
            "|    explained_variance   | 1.19e-07     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 9.43e+03     |\n",
            "|    n_updates            | 8220         |\n",
            "|    policy_gradient_loss | -0.00416     |\n",
            "|    value_loss           | 2.15e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 824          |\n",
            "|    time_elapsed         | 2888         |\n",
            "|    total_timesteps      | 1687552      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0045072655 |\n",
            "|    clip_fraction        | 0.0126       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.641       |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 8.92e+03     |\n",
            "|    n_updates            | 8230         |\n",
            "|    policy_gradient_loss | -0.0031      |\n",
            "|    value_loss           | 2.19e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 825          |\n",
            "|    time_elapsed         | 2891         |\n",
            "|    total_timesteps      | 1689600      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0022135333 |\n",
            "|    clip_fraction        | 0.0108       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.617       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.22e+04     |\n",
            "|    n_updates            | 8240         |\n",
            "|    policy_gradient_loss | -0.00436     |\n",
            "|    value_loss           | 2.36e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 826          |\n",
            "|    time_elapsed         | 2895         |\n",
            "|    total_timesteps      | 1691648      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0020640919 |\n",
            "|    clip_fraction        | 0.0134       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.625       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.02e+04     |\n",
            "|    n_updates            | 8250         |\n",
            "|    policy_gradient_loss | -0.00485     |\n",
            "|    value_loss           | 2.3e+04      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 827          |\n",
            "|    time_elapsed         | 2898         |\n",
            "|    total_timesteps      | 1693696      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0068116845 |\n",
            "|    clip_fraction        | 0.0386       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.628       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.08e+04     |\n",
            "|    n_updates            | 8260         |\n",
            "|    policy_gradient_loss | -0.0015      |\n",
            "|    value_loss           | 2.16e+04     |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 584        |\n",
            "|    iterations           | 828        |\n",
            "|    time_elapsed         | 2902       |\n",
            "|    total_timesteps      | 1695744    |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.02011433 |\n",
            "|    clip_fraction        | 0.0806     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.594     |\n",
            "|    explained_variance   | 5.96e-08   |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 1.19e+04   |\n",
            "|    n_updates            | 8270       |\n",
            "|    policy_gradient_loss | 0.00022    |\n",
            "|    value_loss           | 2.33e+04   |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 584         |\n",
            "|    iterations           | 829         |\n",
            "|    time_elapsed         | 2905        |\n",
            "|    total_timesteps      | 1697792     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008523356 |\n",
            "|    clip_fraction        | 0.0293      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.592      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.07e+04    |\n",
            "|    n_updates            | 8280        |\n",
            "|    policy_gradient_loss | 0.000696    |\n",
            "|    value_loss           | 2.1e+04     |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 830          |\n",
            "|    time_elapsed         | 2909         |\n",
            "|    total_timesteps      | 1699840      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0010035076 |\n",
            "|    clip_fraction        | 0.00415      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.596       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 8.81e+03     |\n",
            "|    n_updates            | 8290         |\n",
            "|    policy_gradient_loss | -0.00331     |\n",
            "|    value_loss           | 2.11e+04     |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 584        |\n",
            "|    iterations           | 831        |\n",
            "|    time_elapsed         | 2912       |\n",
            "|    total_timesteps      | 1701888    |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00300392 |\n",
            "|    clip_fraction        | 0.079      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.557     |\n",
            "|    explained_variance   | 0          |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 1.15e+04   |\n",
            "|    n_updates            | 8300       |\n",
            "|    policy_gradient_loss | 0.000916   |\n",
            "|    value_loss           | 2e+04      |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 832          |\n",
            "|    time_elapsed         | 2916         |\n",
            "|    total_timesteps      | 1703936      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0059031607 |\n",
            "|    clip_fraction        | 0.0697       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.587       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.04e+04     |\n",
            "|    n_updates            | 8310         |\n",
            "|    policy_gradient_loss | -0.00228     |\n",
            "|    value_loss           | 1.94e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 833          |\n",
            "|    time_elapsed         | 2919         |\n",
            "|    total_timesteps      | 1705984      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0001139449 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.574       |\n",
            "|    explained_variance   | 1.19e-07     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.27e+04     |\n",
            "|    n_updates            | 8320         |\n",
            "|    policy_gradient_loss | -6.21e-05    |\n",
            "|    value_loss           | 2.24e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 834          |\n",
            "|    time_elapsed         | 2923         |\n",
            "|    total_timesteps      | 1708032      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038337943 |\n",
            "|    clip_fraction        | 0.0479       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.595       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 9.48e+03     |\n",
            "|    n_updates            | 8330         |\n",
            "|    policy_gradient_loss | -0.00107     |\n",
            "|    value_loss           | 1.94e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 835          |\n",
            "|    time_elapsed         | 2926         |\n",
            "|    total_timesteps      | 1710080      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0002514322 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.606       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 9.08e+03     |\n",
            "|    n_updates            | 8340         |\n",
            "|    policy_gradient_loss | -0.000615    |\n",
            "|    value_loss           | 2.06e+04     |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 584           |\n",
            "|    iterations           | 836           |\n",
            "|    time_elapsed         | 2930          |\n",
            "|    total_timesteps      | 1712128       |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00010154102 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.593        |\n",
            "|    explained_variance   | 0             |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 1.2e+04       |\n",
            "|    n_updates            | 8350          |\n",
            "|    policy_gradient_loss | -0.000927     |\n",
            "|    value_loss           | 2.12e+04      |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 584           |\n",
            "|    iterations           | 837           |\n",
            "|    time_elapsed         | 2933          |\n",
            "|    total_timesteps      | 1714176       |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 4.7345704e-05 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.573        |\n",
            "|    explained_variance   | -1.19e-07     |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 1.28e+04      |\n",
            "|    n_updates            | 8360          |\n",
            "|    policy_gradient_loss | -0.000397     |\n",
            "|    value_loss           | 2.2e+04       |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 584         |\n",
            "|    iterations           | 838         |\n",
            "|    time_elapsed         | 2937        |\n",
            "|    total_timesteps      | 1716224     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002189909 |\n",
            "|    clip_fraction        | 0.0181      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.62       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 9e+03       |\n",
            "|    n_updates            | 8370        |\n",
            "|    policy_gradient_loss | -0.00516    |\n",
            "|    value_loss           | 1.96e+04    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 839          |\n",
            "|    time_elapsed         | 2940         |\n",
            "|    total_timesteps      | 1718272      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0020003908 |\n",
            "|    clip_fraction        | 0.0103       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.626       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 9.59e+03     |\n",
            "|    n_updates            | 8380         |\n",
            "|    policy_gradient_loss | -0.00183     |\n",
            "|    value_loss           | 1.9e+04      |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 584         |\n",
            "|    iterations           | 840         |\n",
            "|    time_elapsed         | 2944        |\n",
            "|    total_timesteps      | 1720320     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.016024493 |\n",
            "|    clip_fraction        | 0.0469      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.594      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.14e+04    |\n",
            "|    n_updates            | 8390        |\n",
            "|    policy_gradient_loss | -0.000917   |\n",
            "|    value_loss           | 2.23e+04    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 841          |\n",
            "|    time_elapsed         | 2947         |\n",
            "|    total_timesteps      | 1722368      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0022987616 |\n",
            "|    clip_fraction        | 0.00679      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.607       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 8.64e+03     |\n",
            "|    n_updates            | 8400         |\n",
            "|    policy_gradient_loss | -0.00226     |\n",
            "|    value_loss           | 1.81e+04     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 584         |\n",
            "|    iterations           | 842         |\n",
            "|    time_elapsed         | 2951        |\n",
            "|    total_timesteps      | 1724416     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005760012 |\n",
            "|    clip_fraction        | 0.0574      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.635      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 8.96e+03    |\n",
            "|    n_updates            | 8410        |\n",
            "|    policy_gradient_loss | -0.000887   |\n",
            "|    value_loss           | 1.96e+04    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 843          |\n",
            "|    time_elapsed         | 2954         |\n",
            "|    total_timesteps      | 1726464      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0025172443 |\n",
            "|    clip_fraction        | 0.00664      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.627       |\n",
            "|    explained_variance   | 1.19e-07     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.01e+04     |\n",
            "|    n_updates            | 8420         |\n",
            "|    policy_gradient_loss | -0.00261     |\n",
            "|    value_loss           | 2.15e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 844          |\n",
            "|    time_elapsed         | 2958         |\n",
            "|    total_timesteps      | 1728512      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0057669664 |\n",
            "|    clip_fraction        | 0.049        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.64        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 9.03e+03     |\n",
            "|    n_updates            | 8430         |\n",
            "|    policy_gradient_loss | -0.00553     |\n",
            "|    value_loss           | 2.02e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 845          |\n",
            "|    time_elapsed         | 2961         |\n",
            "|    total_timesteps      | 1730560      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032844213 |\n",
            "|    clip_fraction        | 0.0356       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.638       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 8.94e+03     |\n",
            "|    n_updates            | 8440         |\n",
            "|    policy_gradient_loss | -0.00485     |\n",
            "|    value_loss           | 1.98e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 846          |\n",
            "|    time_elapsed         | 2965         |\n",
            "|    total_timesteps      | 1732608      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033174888 |\n",
            "|    clip_fraction        | 0.0249       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.645       |\n",
            "|    explained_variance   | 1.19e-07     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1e+04        |\n",
            "|    n_updates            | 8450         |\n",
            "|    policy_gradient_loss | -0.00381     |\n",
            "|    value_loss           | 2e+04        |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 584         |\n",
            "|    iterations           | 847         |\n",
            "|    time_elapsed         | 2968        |\n",
            "|    total_timesteps      | 1734656     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004799539 |\n",
            "|    clip_fraction        | 0.039       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.643      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 9.34e+03    |\n",
            "|    n_updates            | 8460        |\n",
            "|    policy_gradient_loss | -0.00653    |\n",
            "|    value_loss           | 1.94e+04    |\n",
            "-----------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 584           |\n",
            "|    iterations           | 848           |\n",
            "|    time_elapsed         | 2972          |\n",
            "|    total_timesteps      | 1736704       |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00010448575 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.627        |\n",
            "|    explained_variance   | 0             |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 8.32e+03      |\n",
            "|    n_updates            | 8470          |\n",
            "|    policy_gradient_loss | -0.000483     |\n",
            "|    value_loss           | 2.08e+04      |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 849          |\n",
            "|    time_elapsed         | 2975         |\n",
            "|    total_timesteps      | 1738752      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0002568437 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.642       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 8.77e+03     |\n",
            "|    n_updates            | 8480         |\n",
            "|    policy_gradient_loss | -0.000941    |\n",
            "|    value_loss           | 2.03e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 850          |\n",
            "|    time_elapsed         | 2979         |\n",
            "|    total_timesteps      | 1740800      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0054903133 |\n",
            "|    clip_fraction        | 0.0697       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.642       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 8.31e+03     |\n",
            "|    n_updates            | 8490         |\n",
            "|    policy_gradient_loss | -0.00347     |\n",
            "|    value_loss           | 1.8e+04      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 851          |\n",
            "|    time_elapsed         | 2982         |\n",
            "|    total_timesteps      | 1742848      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0052282955 |\n",
            "|    clip_fraction        | 0.0544       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.664       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 9.37e+03     |\n",
            "|    n_updates            | 8500         |\n",
            "|    policy_gradient_loss | -0.002       |\n",
            "|    value_loss           | 2.03e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 852          |\n",
            "|    time_elapsed         | 2986         |\n",
            "|    total_timesteps      | 1744896      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0009842045 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.649       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 8.34e+03     |\n",
            "|    n_updates            | 8510         |\n",
            "|    policy_gradient_loss | -0.00103     |\n",
            "|    value_loss           | 1.83e+04     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 584         |\n",
            "|    iterations           | 853         |\n",
            "|    time_elapsed         | 2989        |\n",
            "|    total_timesteps      | 1746944     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004211205 |\n",
            "|    clip_fraction        | 0.0424      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.653      |\n",
            "|    explained_variance   | -2.38e-07   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 9.67e+03    |\n",
            "|    n_updates            | 8520        |\n",
            "|    policy_gradient_loss | -0.00366    |\n",
            "|    value_loss           | 1.77e+04    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 854          |\n",
            "|    time_elapsed         | 2993         |\n",
            "|    total_timesteps      | 1748992      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0023256857 |\n",
            "|    clip_fraction        | 0.00684      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.654       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 9.69e+03     |\n",
            "|    n_updates            | 8530         |\n",
            "|    policy_gradient_loss | -0.00292     |\n",
            "|    value_loss           | 1.85e+04     |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 584        |\n",
            "|    iterations           | 855        |\n",
            "|    time_elapsed         | 2996       |\n",
            "|    total_timesteps      | 1751040    |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00670239 |\n",
            "|    clip_fraction        | 0.00947    |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.642     |\n",
            "|    explained_variance   | 1.19e-07   |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 9.72e+03   |\n",
            "|    n_updates            | 8540       |\n",
            "|    policy_gradient_loss | -0.00374   |\n",
            "|    value_loss           | 2.03e+04   |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 584         |\n",
            "|    iterations           | 856         |\n",
            "|    time_elapsed         | 3000        |\n",
            "|    total_timesteps      | 1753088     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005245576 |\n",
            "|    clip_fraction        | 0.113       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.714      |\n",
            "|    explained_variance   | 1.19e-07    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 8.8e+03     |\n",
            "|    n_updates            | 8550        |\n",
            "|    policy_gradient_loss | -0.00397    |\n",
            "|    value_loss           | 1.96e+04    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 857          |\n",
            "|    time_elapsed         | 3003         |\n",
            "|    total_timesteps      | 1755136      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0022572167 |\n",
            "|    clip_fraction        | 0.00845      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.644       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.01e+04     |\n",
            "|    n_updates            | 8560         |\n",
            "|    policy_gradient_loss | -0.00283     |\n",
            "|    value_loss           | 2.15e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 858          |\n",
            "|    time_elapsed         | 3007         |\n",
            "|    total_timesteps      | 1757184      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0057522077 |\n",
            "|    clip_fraction        | 0.0529       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.704       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 7.06e+03     |\n",
            "|    n_updates            | 8570         |\n",
            "|    policy_gradient_loss | -0.00641     |\n",
            "|    value_loss           | 1.64e+04     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 584         |\n",
            "|    iterations           | 859         |\n",
            "|    time_elapsed         | 3010        |\n",
            "|    total_timesteps      | 1759232     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001970725 |\n",
            "|    clip_fraction        | 0.0216      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.674      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 9.1e+03     |\n",
            "|    n_updates            | 8580        |\n",
            "|    policy_gradient_loss | 0.00196     |\n",
            "|    value_loss           | 2.04e+04    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 860          |\n",
            "|    time_elapsed         | 3014         |\n",
            "|    total_timesteps      | 1761280      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0026996043 |\n",
            "|    clip_fraction        | 0.0281       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.676       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.99e+03     |\n",
            "|    n_updates            | 8590         |\n",
            "|    policy_gradient_loss | -0.00352     |\n",
            "|    value_loss           | 1.81e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 861          |\n",
            "|    time_elapsed         | 3017         |\n",
            "|    total_timesteps      | 1763328      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031436053 |\n",
            "|    clip_fraction        | 0.0705       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.654       |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 8.41e+03     |\n",
            "|    n_updates            | 8600         |\n",
            "|    policy_gradient_loss | -0.00108     |\n",
            "|    value_loss           | 2e+04        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 862          |\n",
            "|    time_elapsed         | 3021         |\n",
            "|    total_timesteps      | 1765376      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0008574588 |\n",
            "|    clip_fraction        | 0.000244     |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.662       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 8.13e+03     |\n",
            "|    n_updates            | 8610         |\n",
            "|    policy_gradient_loss | -0.00154     |\n",
            "|    value_loss           | 1.83e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 863          |\n",
            "|    time_elapsed         | 3024         |\n",
            "|    total_timesteps      | 1767424      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0040714596 |\n",
            "|    clip_fraction        | 0.0524       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.701       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.03e+04     |\n",
            "|    n_updates            | 8620         |\n",
            "|    policy_gradient_loss | -0.0064      |\n",
            "|    value_loss           | 1.9e+04      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 864          |\n",
            "|    time_elapsed         | 3028         |\n",
            "|    total_timesteps      | 1769472      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017724993 |\n",
            "|    clip_fraction        | 0.00396      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.659       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 9.99e+03     |\n",
            "|    n_updates            | 8630         |\n",
            "|    policy_gradient_loss | -0.00309     |\n",
            "|    value_loss           | 1.96e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 865          |\n",
            "|    time_elapsed         | 3031         |\n",
            "|    total_timesteps      | 1771520      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0026663125 |\n",
            "|    clip_fraction        | 0.00269      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.725       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.09e+04     |\n",
            "|    n_updates            | 8640         |\n",
            "|    policy_gradient_loss | -0.00266     |\n",
            "|    value_loss           | 1.95e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 866          |\n",
            "|    time_elapsed         | 3035         |\n",
            "|    total_timesteps      | 1773568      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0024955273 |\n",
            "|    clip_fraction        | 0.0235       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.693       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 7.85e+03     |\n",
            "|    n_updates            | 8650         |\n",
            "|    policy_gradient_loss | -0.00424     |\n",
            "|    value_loss           | 1.77e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 867          |\n",
            "|    time_elapsed         | 3038         |\n",
            "|    total_timesteps      | 1775616      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0048683435 |\n",
            "|    clip_fraction        | 0.0183       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.631       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 9.13e+03     |\n",
            "|    n_updates            | 8660         |\n",
            "|    policy_gradient_loss | -0.00566     |\n",
            "|    value_loss           | 2.03e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 868          |\n",
            "|    time_elapsed         | 3042         |\n",
            "|    total_timesteps      | 1777664      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0029848646 |\n",
            "|    clip_fraction        | 0.00649      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.664       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.07e+04     |\n",
            "|    n_updates            | 8670         |\n",
            "|    policy_gradient_loss | -0.00159     |\n",
            "|    value_loss           | 1.94e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 869          |\n",
            "|    time_elapsed         | 3045         |\n",
            "|    total_timesteps      | 1779712      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 6.136816e-05 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.629       |\n",
            "|    explained_variance   | 1.19e-07     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 9.33e+03     |\n",
            "|    n_updates            | 8680         |\n",
            "|    policy_gradient_loss | -0.00056     |\n",
            "|    value_loss           | 2.1e+04      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 870          |\n",
            "|    time_elapsed         | 3049         |\n",
            "|    total_timesteps      | 1781760      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0014212246 |\n",
            "|    clip_fraction        | 0.00195      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.642       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.01e+04     |\n",
            "|    n_updates            | 8690         |\n",
            "|    policy_gradient_loss | -0.00287     |\n",
            "|    value_loss           | 1.84e+04     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 584         |\n",
            "|    iterations           | 871         |\n",
            "|    time_elapsed         | 3052        |\n",
            "|    total_timesteps      | 1783808     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011714271 |\n",
            "|    clip_fraction        | 0.0416      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.705      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 7.73e+03    |\n",
            "|    n_updates            | 8700        |\n",
            "|    policy_gradient_loss | -0.00379    |\n",
            "|    value_loss           | 1.72e+04    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 872          |\n",
            "|    time_elapsed         | 3056         |\n",
            "|    total_timesteps      | 1785856      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0025732294 |\n",
            "|    clip_fraction        | 0.0757       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.622       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.04e+04     |\n",
            "|    n_updates            | 8710         |\n",
            "|    policy_gradient_loss | -0.00367     |\n",
            "|    value_loss           | 2.06e+04     |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 584        |\n",
            "|    iterations           | 873        |\n",
            "|    time_elapsed         | 3059       |\n",
            "|    total_timesteps      | 1787904    |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.01812575 |\n",
            "|    clip_fraction        | 0.127      |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.633     |\n",
            "|    explained_variance   | -1.19e-07  |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 1.06e+04   |\n",
            "|    n_updates            | 8720       |\n",
            "|    policy_gradient_loss | 0.00364    |\n",
            "|    value_loss           | 2.12e+04   |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 874          |\n",
            "|    time_elapsed         | 3063         |\n",
            "|    total_timesteps      | 1789952      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0020404682 |\n",
            "|    clip_fraction        | 0.00435      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.64        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.01e+04     |\n",
            "|    n_updates            | 8730         |\n",
            "|    policy_gradient_loss | -0.00156     |\n",
            "|    value_loss           | 2.17e+04     |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 584           |\n",
            "|    iterations           | 875           |\n",
            "|    time_elapsed         | 3066          |\n",
            "|    total_timesteps      | 1792000       |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00024533545 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.619        |\n",
            "|    explained_variance   | 0             |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 1.1e+04       |\n",
            "|    n_updates            | 8740          |\n",
            "|    policy_gradient_loss | -0.000294     |\n",
            "|    value_loss           | 2.06e+04      |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 876          |\n",
            "|    time_elapsed         | 3070         |\n",
            "|    total_timesteps      | 1794048      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0024070414 |\n",
            "|    clip_fraction        | 0.0429       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.615       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 9.46e+03     |\n",
            "|    n_updates            | 8750         |\n",
            "|    policy_gradient_loss | -0.00416     |\n",
            "|    value_loss           | 1.94e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 877          |\n",
            "|    time_elapsed         | 3073         |\n",
            "|    total_timesteps      | 1796096      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0055981297 |\n",
            "|    clip_fraction        | 0.025        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.645       |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.14e+04     |\n",
            "|    n_updates            | 8760         |\n",
            "|    policy_gradient_loss | -0.00439     |\n",
            "|    value_loss           | 2.01e+04     |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 584        |\n",
            "|    iterations           | 878        |\n",
            "|    time_elapsed         | 3077       |\n",
            "|    total_timesteps      | 1798144    |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00477421 |\n",
            "|    clip_fraction        | 0.0916     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.629     |\n",
            "|    explained_variance   | 0          |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 9.67e+03   |\n",
            "|    n_updates            | 8770       |\n",
            "|    policy_gradient_loss | -0.000307  |\n",
            "|    value_loss           | 1.91e+04   |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 879          |\n",
            "|    time_elapsed         | 3080         |\n",
            "|    total_timesteps      | 1800192      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028837475 |\n",
            "|    clip_fraction        | 0.0194       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.621       |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.2e+04      |\n",
            "|    n_updates            | 8780         |\n",
            "|    policy_gradient_loss | -0.00537     |\n",
            "|    value_loss           | 2.06e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 880          |\n",
            "|    time_elapsed         | 3084         |\n",
            "|    total_timesteps      | 1802240      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0010566628 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.639       |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.14e+04     |\n",
            "|    n_updates            | 8790         |\n",
            "|    policy_gradient_loss | -0.00167     |\n",
            "|    value_loss           | 2.09e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 881          |\n",
            "|    time_elapsed         | 3087         |\n",
            "|    total_timesteps      | 1804288      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0011595059 |\n",
            "|    clip_fraction        | 0.000586     |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.625       |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 8.91e+03     |\n",
            "|    n_updates            | 8800         |\n",
            "|    policy_gradient_loss | -0.00135     |\n",
            "|    value_loss           | 1.77e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 882          |\n",
            "|    time_elapsed         | 3091         |\n",
            "|    total_timesteps      | 1806336      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0061055883 |\n",
            "|    clip_fraction        | 0.0543       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.632       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 9.38e+03     |\n",
            "|    n_updates            | 8810         |\n",
            "|    policy_gradient_loss | -0.00176     |\n",
            "|    value_loss           | 2.04e+04     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 584         |\n",
            "|    iterations           | 883         |\n",
            "|    time_elapsed         | 3094        |\n",
            "|    total_timesteps      | 1808384     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.010161805 |\n",
            "|    clip_fraction        | 0.0448      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.552      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 8.78e+03    |\n",
            "|    n_updates            | 8820        |\n",
            "|    policy_gradient_loss | -0.00129    |\n",
            "|    value_loss           | 1.96e+04    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 884          |\n",
            "|    time_elapsed         | 3098         |\n",
            "|    total_timesteps      | 1810432      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0019493066 |\n",
            "|    clip_fraction        | 0.0042       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.594       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 9.89e+03     |\n",
            "|    n_updates            | 8830         |\n",
            "|    policy_gradient_loss | -0.00364     |\n",
            "|    value_loss           | 2e+04        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 885          |\n",
            "|    time_elapsed         | 3101         |\n",
            "|    total_timesteps      | 1812480      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0030008946 |\n",
            "|    clip_fraction        | 0.0392       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.598       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 8.68e+03     |\n",
            "|    n_updates            | 8840         |\n",
            "|    policy_gradient_loss | -0.00118     |\n",
            "|    value_loss           | 1.79e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 886          |\n",
            "|    time_elapsed         | 3105         |\n",
            "|    total_timesteps      | 1814528      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0010863123 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.597       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.07e+04     |\n",
            "|    n_updates            | 8850         |\n",
            "|    policy_gradient_loss | -0.000288    |\n",
            "|    value_loss           | 1.79e+04     |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 584           |\n",
            "|    iterations           | 887           |\n",
            "|    time_elapsed         | 3108          |\n",
            "|    total_timesteps      | 1816576       |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00018310169 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.59         |\n",
            "|    explained_variance   | 0             |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 1.08e+04      |\n",
            "|    n_updates            | 8860          |\n",
            "|    policy_gradient_loss | -0.000761     |\n",
            "|    value_loss           | 1.81e+04      |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 584         |\n",
            "|    iterations           | 888         |\n",
            "|    time_elapsed         | 3112        |\n",
            "|    total_timesteps      | 1818624     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007376807 |\n",
            "|    clip_fraction        | 0.0327      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.634      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 7.91e+03    |\n",
            "|    n_updates            | 8870        |\n",
            "|    policy_gradient_loss | -0.00443    |\n",
            "|    value_loss           | 2.1e+04     |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 889          |\n",
            "|    time_elapsed         | 3115         |\n",
            "|    total_timesteps      | 1820672      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0030131992 |\n",
            "|    clip_fraction        | 0.0219       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.64        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.1e+04      |\n",
            "|    n_updates            | 8880         |\n",
            "|    policy_gradient_loss | -0.00505     |\n",
            "|    value_loss           | 1.95e+04     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 584         |\n",
            "|    iterations           | 890         |\n",
            "|    time_elapsed         | 3119        |\n",
            "|    total_timesteps      | 1822720     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008461458 |\n",
            "|    clip_fraction        | 0.0447      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.623      |\n",
            "|    explained_variance   | 1.19e-07    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 7.95e+03    |\n",
            "|    n_updates            | 8890        |\n",
            "|    policy_gradient_loss | -0.00343    |\n",
            "|    value_loss           | 1.77e+04    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 891          |\n",
            "|    time_elapsed         | 3122         |\n",
            "|    total_timesteps      | 1824768      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0041301893 |\n",
            "|    clip_fraction        | 0.0144       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.62        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.1e+04      |\n",
            "|    n_updates            | 8900         |\n",
            "|    policy_gradient_loss | -0.00377     |\n",
            "|    value_loss           | 1.91e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 892          |\n",
            "|    time_elapsed         | 3126         |\n",
            "|    total_timesteps      | 1826816      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0025779004 |\n",
            "|    clip_fraction        | 0.0267       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.615       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 8.97e+03     |\n",
            "|    n_updates            | 8910         |\n",
            "|    policy_gradient_loss | -0.00482     |\n",
            "|    value_loss           | 2.02e+04     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 584         |\n",
            "|    iterations           | 893         |\n",
            "|    time_elapsed         | 3129        |\n",
            "|    total_timesteps      | 1828864     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005910491 |\n",
            "|    clip_fraction        | 0.0204      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.607      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 8.62e+03    |\n",
            "|    n_updates            | 8920        |\n",
            "|    policy_gradient_loss | -0.00517    |\n",
            "|    value_loss           | 1.79e+04    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 894          |\n",
            "|    time_elapsed         | 3133         |\n",
            "|    total_timesteps      | 1830912      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0042056246 |\n",
            "|    clip_fraction        | 0.036        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.634       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.11e+04     |\n",
            "|    n_updates            | 8930         |\n",
            "|    policy_gradient_loss | -0.00314     |\n",
            "|    value_loss           | 1.91e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 895          |\n",
            "|    time_elapsed         | 3136         |\n",
            "|    total_timesteps      | 1832960      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033104673 |\n",
            "|    clip_fraction        | 0.0152       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.632       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 9.79e+03     |\n",
            "|    n_updates            | 8940         |\n",
            "|    policy_gradient_loss | -0.00655     |\n",
            "|    value_loss           | 1.78e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 896          |\n",
            "|    time_elapsed         | 3140         |\n",
            "|    total_timesteps      | 1835008      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0004535638 |\n",
            "|    clip_fraction        | 4.88e-05     |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.611       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 9.69e+03     |\n",
            "|    n_updates            | 8950         |\n",
            "|    policy_gradient_loss | -0.00149     |\n",
            "|    value_loss           | 2.01e+04     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 584         |\n",
            "|    iterations           | 897         |\n",
            "|    time_elapsed         | 3143        |\n",
            "|    total_timesteps      | 1837056     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001436985 |\n",
            "|    clip_fraction        | 0.00522     |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.63       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.03e+04    |\n",
            "|    n_updates            | 8960        |\n",
            "|    policy_gradient_loss | -0.00297    |\n",
            "|    value_loss           | 1.97e+04    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 898          |\n",
            "|    time_elapsed         | 3147         |\n",
            "|    total_timesteps      | 1839104      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028544879 |\n",
            "|    clip_fraction        | 0.0117       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.575       |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.21e+04     |\n",
            "|    n_updates            | 8970         |\n",
            "|    policy_gradient_loss | -0.00297     |\n",
            "|    value_loss           | 1.86e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 899          |\n",
            "|    time_elapsed         | 3150         |\n",
            "|    total_timesteps      | 1841152      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0077282684 |\n",
            "|    clip_fraction        | 0.0737       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.59        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 9.58e+03     |\n",
            "|    n_updates            | 8980         |\n",
            "|    policy_gradient_loss | -0.00253     |\n",
            "|    value_loss           | 2.26e+04     |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 584           |\n",
            "|    iterations           | 900           |\n",
            "|    time_elapsed         | 3154          |\n",
            "|    total_timesteps      | 1843200       |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00015935497 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.588        |\n",
            "|    explained_variance   | 0             |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 1.18e+04      |\n",
            "|    n_updates            | 8990          |\n",
            "|    policy_gradient_loss | -0.000423     |\n",
            "|    value_loss           | 2.21e+04      |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 901          |\n",
            "|    time_elapsed         | 3157         |\n",
            "|    total_timesteps      | 1845248      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 7.552287e-05 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.656       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 8.03e+03     |\n",
            "|    n_updates            | 9000         |\n",
            "|    policy_gradient_loss | -0.000711    |\n",
            "|    value_loss           | 2e+04        |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 902          |\n",
            "|    time_elapsed         | 3161         |\n",
            "|    total_timesteps      | 1847296      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0051775044 |\n",
            "|    clip_fraction        | 0.035        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.571       |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 9.25e+03     |\n",
            "|    n_updates            | 9010         |\n",
            "|    policy_gradient_loss | -0.00386     |\n",
            "|    value_loss           | 2.12e+04     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 584         |\n",
            "|    iterations           | 903         |\n",
            "|    time_elapsed         | 3164        |\n",
            "|    total_timesteps      | 1849344     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.013534174 |\n",
            "|    clip_fraction        | 0.0811      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.625      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 8.96e+03    |\n",
            "|    n_updates            | 9020        |\n",
            "|    policy_gradient_loss | 0.00123     |\n",
            "|    value_loss           | 1.92e+04    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 584         |\n",
            "|    iterations           | 904         |\n",
            "|    time_elapsed         | 3168        |\n",
            "|    total_timesteps      | 1851392     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006151116 |\n",
            "|    clip_fraction        | 0.025       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.563      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.1e+04     |\n",
            "|    n_updates            | 9030        |\n",
            "|    policy_gradient_loss | -0.00354    |\n",
            "|    value_loss           | 2.19e+04    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 905          |\n",
            "|    time_elapsed         | 3171         |\n",
            "|    total_timesteps      | 1853440      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0070407335 |\n",
            "|    clip_fraction        | 0.0679       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.606       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 9.32e+03     |\n",
            "|    n_updates            | 9040         |\n",
            "|    policy_gradient_loss | -0.00753     |\n",
            "|    value_loss           | 1.9e+04      |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 584         |\n",
            "|    iterations           | 906         |\n",
            "|    time_elapsed         | 3175        |\n",
            "|    total_timesteps      | 1855488     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.015278995 |\n",
            "|    clip_fraction        | 0.0715      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.58       |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 8.12e+03    |\n",
            "|    n_updates            | 9050        |\n",
            "|    policy_gradient_loss | -0.00139    |\n",
            "|    value_loss           | 1.98e+04    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 907          |\n",
            "|    time_elapsed         | 3178         |\n",
            "|    total_timesteps      | 1857536      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0020293146 |\n",
            "|    clip_fraction        | 0.0111       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.622       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 8.09e+03     |\n",
            "|    n_updates            | 9060         |\n",
            "|    policy_gradient_loss | -0.00461     |\n",
            "|    value_loss           | 1.86e+04     |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 584           |\n",
            "|    iterations           | 908           |\n",
            "|    time_elapsed         | 3182          |\n",
            "|    total_timesteps      | 1859584       |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00051681953 |\n",
            "|    clip_fraction        | 4.88e-05      |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.64         |\n",
            "|    explained_variance   | 0             |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 1.01e+04      |\n",
            "|    n_updates            | 9070          |\n",
            "|    policy_gradient_loss | -0.00158      |\n",
            "|    value_loss           | 2.01e+04      |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 909          |\n",
            "|    time_elapsed         | 3185         |\n",
            "|    total_timesteps      | 1861632      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0054836893 |\n",
            "|    clip_fraction        | 0.00874      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.626       |\n",
            "|    explained_variance   | 1.19e-07     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.09e+04     |\n",
            "|    n_updates            | 9080         |\n",
            "|    policy_gradient_loss | -0.0046      |\n",
            "|    value_loss           | 2.04e+04     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 584         |\n",
            "|    iterations           | 910         |\n",
            "|    time_elapsed         | 3189        |\n",
            "|    total_timesteps      | 1863680     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001770235 |\n",
            "|    clip_fraction        | 0.0121      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.586      |\n",
            "|    explained_variance   | 1.19e-07    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.11e+04    |\n",
            "|    n_updates            | 9090        |\n",
            "|    policy_gradient_loss | -0.00501    |\n",
            "|    value_loss           | 2.08e+04    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 911          |\n",
            "|    time_elapsed         | 3192         |\n",
            "|    total_timesteps      | 1865728      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0020097601 |\n",
            "|    clip_fraction        | 0.053        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.639       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 8.65e+03     |\n",
            "|    n_updates            | 9100         |\n",
            "|    policy_gradient_loss | -0.00327     |\n",
            "|    value_loss           | 1.72e+04     |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 584           |\n",
            "|    iterations           | 912           |\n",
            "|    time_elapsed         | 3196          |\n",
            "|    total_timesteps      | 1867776       |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00068092195 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.623        |\n",
            "|    explained_variance   | 0             |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 1.13e+04      |\n",
            "|    n_updates            | 9110          |\n",
            "|    policy_gradient_loss | -0.00091      |\n",
            "|    value_loss           | 2.07e+04      |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 584           |\n",
            "|    iterations           | 913           |\n",
            "|    time_elapsed         | 3199          |\n",
            "|    total_timesteps      | 1869824       |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00013303655 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.619        |\n",
            "|    explained_variance   | 0             |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 1.26e+04      |\n",
            "|    n_updates            | 9120          |\n",
            "|    policy_gradient_loss | -0.000988     |\n",
            "|    value_loss           | 2.31e+04      |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 914          |\n",
            "|    time_elapsed         | 3203         |\n",
            "|    total_timesteps      | 1871872      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0008906777 |\n",
            "|    clip_fraction        | 0.00137      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.612       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.02e+04     |\n",
            "|    n_updates            | 9130         |\n",
            "|    policy_gradient_loss | -0.00225     |\n",
            "|    value_loss           | 2.07e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 915          |\n",
            "|    time_elapsed         | 3206         |\n",
            "|    total_timesteps      | 1873920      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0044694766 |\n",
            "|    clip_fraction        | 0.00645      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.629       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.17e+04     |\n",
            "|    n_updates            | 9140         |\n",
            "|    policy_gradient_loss | -0.000664    |\n",
            "|    value_loss           | 2.1e+04      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 916          |\n",
            "|    time_elapsed         | 3210         |\n",
            "|    total_timesteps      | 1875968      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0005766946 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.608       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.06e+04     |\n",
            "|    n_updates            | 9150         |\n",
            "|    policy_gradient_loss | -0.00151     |\n",
            "|    value_loss           | 1.98e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 917          |\n",
            "|    time_elapsed         | 3213         |\n",
            "|    total_timesteps      | 1878016      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032364351 |\n",
            "|    clip_fraction        | 0.0723       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.613       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 7.7e+03      |\n",
            "|    n_updates            | 9160         |\n",
            "|    policy_gradient_loss | -0.000803    |\n",
            "|    value_loss           | 2e+04        |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 584           |\n",
            "|    iterations           | 918           |\n",
            "|    time_elapsed         | 3217          |\n",
            "|    total_timesteps      | 1880064       |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00072660414 |\n",
            "|    clip_fraction        | 0.000342      |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.602        |\n",
            "|    explained_variance   | 0             |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 8.67e+03      |\n",
            "|    n_updates            | 9170          |\n",
            "|    policy_gradient_loss | -0.00174      |\n",
            "|    value_loss           | 2.12e+04      |\n",
            "-------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 584        |\n",
            "|    iterations           | 919        |\n",
            "|    time_elapsed         | 3220       |\n",
            "|    total_timesteps      | 1882112    |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00417192 |\n",
            "|    clip_fraction        | 0.0328     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.571     |\n",
            "|    explained_variance   | 0          |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 9.94e+03   |\n",
            "|    n_updates            | 9180       |\n",
            "|    policy_gradient_loss | -0.00839   |\n",
            "|    value_loss           | 2.11e+04   |\n",
            "----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 584        |\n",
            "|    iterations           | 920        |\n",
            "|    time_elapsed         | 3224       |\n",
            "|    total_timesteps      | 1884160    |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00269834 |\n",
            "|    clip_fraction        | 0.0108     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.601     |\n",
            "|    explained_variance   | 0          |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 8.33e+03   |\n",
            "|    n_updates            | 9190       |\n",
            "|    policy_gradient_loss | -0.00357   |\n",
            "|    value_loss           | 1.86e+04   |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 921          |\n",
            "|    time_elapsed         | 3227         |\n",
            "|    total_timesteps      | 1886208      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0036192331 |\n",
            "|    clip_fraction        | 0.0271       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.608       |\n",
            "|    explained_variance   | -2.38e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.3e+04      |\n",
            "|    n_updates            | 9200         |\n",
            "|    policy_gradient_loss | -0.00281     |\n",
            "|    value_loss           | 2.16e+04     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 584         |\n",
            "|    iterations           | 922         |\n",
            "|    time_elapsed         | 3231        |\n",
            "|    total_timesteps      | 1888256     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.012306191 |\n",
            "|    clip_fraction        | 0.0544      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.619      |\n",
            "|    explained_variance   | -1.19e-07   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 9.12e+03    |\n",
            "|    n_updates            | 9210        |\n",
            "|    policy_gradient_loss | -0.00489    |\n",
            "|    value_loss           | 2.22e+04    |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 584        |\n",
            "|    iterations           | 923        |\n",
            "|    time_elapsed         | 3234       |\n",
            "|    total_timesteps      | 1890304    |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00709283 |\n",
            "|    clip_fraction        | 0.0655     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.64      |\n",
            "|    explained_variance   | 0          |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 1.15e+04   |\n",
            "|    n_updates            | 9220       |\n",
            "|    policy_gradient_loss | -0.00325   |\n",
            "|    value_loss           | 2.23e+04   |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 584         |\n",
            "|    iterations           | 924         |\n",
            "|    time_elapsed         | 3238        |\n",
            "|    total_timesteps      | 1892352     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005537887 |\n",
            "|    clip_fraction        | 0.0851      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.659      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 9.54e+03    |\n",
            "|    n_updates            | 9230        |\n",
            "|    policy_gradient_loss | -0.0024     |\n",
            "|    value_loss           | 1.99e+04    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 925          |\n",
            "|    time_elapsed         | 3241         |\n",
            "|    total_timesteps      | 1894400      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0022786225 |\n",
            "|    clip_fraction        | 0.0102       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.659       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.1e+04      |\n",
            "|    n_updates            | 9240         |\n",
            "|    policy_gradient_loss | -0.0049      |\n",
            "|    value_loss           | 2.15e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 926          |\n",
            "|    time_elapsed         | 3245         |\n",
            "|    total_timesteps      | 1896448      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0019599604 |\n",
            "|    clip_fraction        | 0.00479      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.603       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.06e+04     |\n",
            "|    n_updates            | 9250         |\n",
            "|    policy_gradient_loss | -0.00291     |\n",
            "|    value_loss           | 2.32e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 927          |\n",
            "|    time_elapsed         | 3248         |\n",
            "|    total_timesteps      | 1898496      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034981673 |\n",
            "|    clip_fraction        | 0.0298       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.612       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 9.63e+03     |\n",
            "|    n_updates            | 9260         |\n",
            "|    policy_gradient_loss | -0.00301     |\n",
            "|    value_loss           | 2.13e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 928          |\n",
            "|    time_elapsed         | 3252         |\n",
            "|    total_timesteps      | 1900544      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0023543178 |\n",
            "|    clip_fraction        | 0.00195      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.639       |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 9.61e+03     |\n",
            "|    n_updates            | 9270         |\n",
            "|    policy_gradient_loss | -0.00257     |\n",
            "|    value_loss           | 2.23e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 929          |\n",
            "|    time_elapsed         | 3255         |\n",
            "|    total_timesteps      | 1902592      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0024768612 |\n",
            "|    clip_fraction        | 0.0349       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.633       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.15e+04     |\n",
            "|    n_updates            | 9280         |\n",
            "|    policy_gradient_loss | -0.00148     |\n",
            "|    value_loss           | 2.25e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 930          |\n",
            "|    time_elapsed         | 3259         |\n",
            "|    total_timesteps      | 1904640      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035939512 |\n",
            "|    clip_fraction        | 0.0122       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.63        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.04e+04     |\n",
            "|    n_updates            | 9290         |\n",
            "|    policy_gradient_loss | -0.00525     |\n",
            "|    value_loss           | 2.06e+04     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 584         |\n",
            "|    iterations           | 931         |\n",
            "|    time_elapsed         | 3262        |\n",
            "|    total_timesteps      | 1906688     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004175498 |\n",
            "|    clip_fraction        | 0.0353      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.603      |\n",
            "|    explained_variance   | -1.19e-07   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.04e+04    |\n",
            "|    n_updates            | 9300        |\n",
            "|    policy_gradient_loss | -0.00264    |\n",
            "|    value_loss           | 2.29e+04    |\n",
            "-----------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 584        |\n",
            "|    iterations           | 932        |\n",
            "|    time_elapsed         | 3266       |\n",
            "|    total_timesteps      | 1908736    |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.02119669 |\n",
            "|    clip_fraction        | 0.0605     |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.611     |\n",
            "|    explained_variance   | 0          |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 1.1e+04    |\n",
            "|    n_updates            | 9310       |\n",
            "|    policy_gradient_loss | 0.00165    |\n",
            "|    value_loss           | 2.27e+04   |\n",
            "----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 933          |\n",
            "|    time_elapsed         | 3269         |\n",
            "|    total_timesteps      | 1910784      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0138860205 |\n",
            "|    clip_fraction        | 0.181        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.651       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 9.63e+03     |\n",
            "|    n_updates            | 9320         |\n",
            "|    policy_gradient_loss | 0.0104       |\n",
            "|    value_loss           | 2.12e+04     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 584         |\n",
            "|    iterations           | 934         |\n",
            "|    time_elapsed         | 3273        |\n",
            "|    total_timesteps      | 1912832     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004072859 |\n",
            "|    clip_fraction        | 0.0313      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.664      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.14e+04    |\n",
            "|    n_updates            | 9330        |\n",
            "|    policy_gradient_loss | -0.00395    |\n",
            "|    value_loss           | 2.09e+04    |\n",
            "-----------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 584           |\n",
            "|    iterations           | 935           |\n",
            "|    time_elapsed         | 3276          |\n",
            "|    total_timesteps      | 1914880       |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 5.5881945e-05 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.632        |\n",
            "|    explained_variance   | 0             |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 1.21e+04      |\n",
            "|    n_updates            | 9340          |\n",
            "|    policy_gradient_loss | -0.000433     |\n",
            "|    value_loss           | 2.27e+04      |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 936          |\n",
            "|    time_elapsed         | 3280         |\n",
            "|    total_timesteps      | 1916928      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0038589989 |\n",
            "|    clip_fraction        | 0.0118       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.676       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.02e+04     |\n",
            "|    n_updates            | 9350         |\n",
            "|    policy_gradient_loss | -0.00364     |\n",
            "|    value_loss           | 2.04e+04     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 584         |\n",
            "|    iterations           | 937         |\n",
            "|    time_elapsed         | 3283        |\n",
            "|    total_timesteps      | 1918976     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.022768475 |\n",
            "|    clip_fraction        | 0.0617      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.707      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.16e+04    |\n",
            "|    n_updates            | 9360        |\n",
            "|    policy_gradient_loss | 0.00187     |\n",
            "|    value_loss           | 2.24e+04    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 938          |\n",
            "|    time_elapsed         | 3287         |\n",
            "|    total_timesteps      | 1921024      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0041336026 |\n",
            "|    clip_fraction        | 0.0202       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.718       |\n",
            "|    explained_variance   | 1.79e-07     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.24e+04     |\n",
            "|    n_updates            | 9370         |\n",
            "|    policy_gradient_loss | -0.00441     |\n",
            "|    value_loss           | 2.28e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 939          |\n",
            "|    time_elapsed         | 3290         |\n",
            "|    total_timesteps      | 1923072      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031297426 |\n",
            "|    clip_fraction        | 0.0223       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.704       |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 9.39e+03     |\n",
            "|    n_updates            | 9380         |\n",
            "|    policy_gradient_loss | -0.00507     |\n",
            "|    value_loss           | 1.97e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 940          |\n",
            "|    time_elapsed         | 3294         |\n",
            "|    total_timesteps      | 1925120      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0027885307 |\n",
            "|    clip_fraction        | 0.00991      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.723       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 9.39e+03     |\n",
            "|    n_updates            | 9390         |\n",
            "|    policy_gradient_loss | -0.00343     |\n",
            "|    value_loss           | 2.07e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 941          |\n",
            "|    time_elapsed         | 3297         |\n",
            "|    total_timesteps      | 1927168      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0027167178 |\n",
            "|    clip_fraction        | 0.0763       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.71        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.34e+04     |\n",
            "|    n_updates            | 9400         |\n",
            "|    policy_gradient_loss | -0.000168    |\n",
            "|    value_loss           | 2.36e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 942          |\n",
            "|    time_elapsed         | 3301         |\n",
            "|    total_timesteps      | 1929216      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0028308465 |\n",
            "|    clip_fraction        | 0.00625      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.733       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 9.55e+03     |\n",
            "|    n_updates            | 9410         |\n",
            "|    policy_gradient_loss | -0.00371     |\n",
            "|    value_loss           | 2.2e+04      |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 584         |\n",
            "|    iterations           | 943         |\n",
            "|    time_elapsed         | 3304        |\n",
            "|    total_timesteps      | 1931264     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002920021 |\n",
            "|    clip_fraction        | 0.0331      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.691      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.11e+04    |\n",
            "|    n_updates            | 9420        |\n",
            "|    policy_gradient_loss | -0.00367    |\n",
            "|    value_loss           | 2.16e+04    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 584         |\n",
            "|    iterations           | 944         |\n",
            "|    time_elapsed         | 3308        |\n",
            "|    total_timesteps      | 1933312     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004195706 |\n",
            "|    clip_fraction        | 0.0412      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.689      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.11e+04    |\n",
            "|    n_updates            | 9430        |\n",
            "|    policy_gradient_loss | -0.00921    |\n",
            "|    value_loss           | 2.12e+04    |\n",
            "-----------------------------------------\n",
            "-------------------------------------------\n",
            "| time/                   |               |\n",
            "|    fps                  | 584           |\n",
            "|    iterations           | 945           |\n",
            "|    time_elapsed         | 3311          |\n",
            "|    total_timesteps      | 1935360       |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00035601293 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.2           |\n",
            "|    entropy_loss         | -0.734        |\n",
            "|    explained_variance   | 0             |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 9.93e+03      |\n",
            "|    n_updates            | 9440          |\n",
            "|    policy_gradient_loss | -0.00125      |\n",
            "|    value_loss           | 2.08e+04      |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 946          |\n",
            "|    time_elapsed         | 3315         |\n",
            "|    total_timesteps      | 1937408      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0039693965 |\n",
            "|    clip_fraction        | 0.0427       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.711       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.06e+04     |\n",
            "|    n_updates            | 9450         |\n",
            "|    policy_gradient_loss | -0.00441     |\n",
            "|    value_loss           | 2.22e+04     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 584         |\n",
            "|    iterations           | 947         |\n",
            "|    time_elapsed         | 3318        |\n",
            "|    total_timesteps      | 1939456     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.027742201 |\n",
            "|    clip_fraction        | 0.105       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.703      |\n",
            "|    explained_variance   | 5.96e-08    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 9.59e+03    |\n",
            "|    n_updates            | 9460        |\n",
            "|    policy_gradient_loss | 0.00242     |\n",
            "|    value_loss           | 2.25e+04    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 948          |\n",
            "|    time_elapsed         | 3322         |\n",
            "|    total_timesteps      | 1941504      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0020916476 |\n",
            "|    clip_fraction        | 0.00122      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.706       |\n",
            "|    explained_variance   | 5.96e-08     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.3e+04      |\n",
            "|    n_updates            | 9470         |\n",
            "|    policy_gradient_loss | -0.00243     |\n",
            "|    value_loss           | 2.38e+04     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 584         |\n",
            "|    iterations           | 949         |\n",
            "|    time_elapsed         | 3326        |\n",
            "|    total_timesteps      | 1943552     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011571038 |\n",
            "|    clip_fraction        | 0.0891      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.693      |\n",
            "|    explained_variance   | 1.19e-07    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.06e+04    |\n",
            "|    n_updates            | 9480        |\n",
            "|    policy_gradient_loss | 0.0027      |\n",
            "|    value_loss           | 2.07e+04    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 584         |\n",
            "|    iterations           | 950         |\n",
            "|    time_elapsed         | 3329        |\n",
            "|    total_timesteps      | 1945600     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005775258 |\n",
            "|    clip_fraction        | 0.0757      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.723      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.28e+04    |\n",
            "|    n_updates            | 9490        |\n",
            "|    policy_gradient_loss | -0.00882    |\n",
            "|    value_loss           | 2.08e+04    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 951          |\n",
            "|    time_elapsed         | 3333         |\n",
            "|    total_timesteps      | 1947648      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0022175196 |\n",
            "|    clip_fraction        | 0.00991      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.696       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.08e+04     |\n",
            "|    n_updates            | 9500         |\n",
            "|    policy_gradient_loss | -0.00466     |\n",
            "|    value_loss           | 2.12e+04     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 584         |\n",
            "|    iterations           | 952         |\n",
            "|    time_elapsed         | 3336        |\n",
            "|    total_timesteps      | 1949696     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004625907 |\n",
            "|    clip_fraction        | 0.0259      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.719      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.13e+04    |\n",
            "|    n_updates            | 9510        |\n",
            "|    policy_gradient_loss | -0.00337    |\n",
            "|    value_loss           | 2.07e+04    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 953          |\n",
            "|    time_elapsed         | 3340         |\n",
            "|    total_timesteps      | 1951744      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0037449754 |\n",
            "|    clip_fraction        | 0.0177       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.636       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 8.8e+03      |\n",
            "|    n_updates            | 9520         |\n",
            "|    policy_gradient_loss | -0.00644     |\n",
            "|    value_loss           | 2.19e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 954          |\n",
            "|    time_elapsed         | 3343         |\n",
            "|    total_timesteps      | 1953792      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0031808831 |\n",
            "|    clip_fraction        | 0.0507       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.631       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.44e+04     |\n",
            "|    n_updates            | 9530         |\n",
            "|    policy_gradient_loss | -0.0037      |\n",
            "|    value_loss           | 2.31e+04     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 584         |\n",
            "|    iterations           | 955         |\n",
            "|    time_elapsed         | 3347        |\n",
            "|    total_timesteps      | 1955840     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002209004 |\n",
            "|    clip_fraction        | 0.0127      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.635      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.19e+04    |\n",
            "|    n_updates            | 9540        |\n",
            "|    policy_gradient_loss | -0.0051     |\n",
            "|    value_loss           | 2.46e+04    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 584         |\n",
            "|    iterations           | 956         |\n",
            "|    time_elapsed         | 3350        |\n",
            "|    total_timesteps      | 1957888     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004099597 |\n",
            "|    clip_fraction        | 0.0385      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.642      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 9.57e+03    |\n",
            "|    n_updates            | 9550        |\n",
            "|    policy_gradient_loss | -0.00808    |\n",
            "|    value_loss           | 2.12e+04    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 957          |\n",
            "|    time_elapsed         | 3354         |\n",
            "|    total_timesteps      | 1959936      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0009776168 |\n",
            "|    clip_fraction        | 0.00186      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.696       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 9.44e+03     |\n",
            "|    n_updates            | 9560         |\n",
            "|    policy_gradient_loss | -0.00179     |\n",
            "|    value_loss           | 2.11e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 958          |\n",
            "|    time_elapsed         | 3357         |\n",
            "|    total_timesteps      | 1961984      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0027942066 |\n",
            "|    clip_fraction        | 0.0115       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.654       |\n",
            "|    explained_variance   | 5.96e-08     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.18e+04     |\n",
            "|    n_updates            | 9570         |\n",
            "|    policy_gradient_loss | -0.00507     |\n",
            "|    value_loss           | 2.3e+04      |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 959          |\n",
            "|    time_elapsed         | 3361         |\n",
            "|    total_timesteps      | 1964032      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0021771863 |\n",
            "|    clip_fraction        | 0.00156      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.621       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.18e+04     |\n",
            "|    n_updates            | 9580         |\n",
            "|    policy_gradient_loss | -0.00299     |\n",
            "|    value_loss           | 2.33e+04     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 584         |\n",
            "|    iterations           | 960         |\n",
            "|    time_elapsed         | 3364        |\n",
            "|    total_timesteps      | 1966080     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.007563484 |\n",
            "|    clip_fraction        | 0.0571      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.653      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.13e+04    |\n",
            "|    n_updates            | 9590        |\n",
            "|    policy_gradient_loss | -0.00278    |\n",
            "|    value_loss           | 2.19e+04    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 961          |\n",
            "|    time_elapsed         | 3368         |\n",
            "|    total_timesteps      | 1968128      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0011040458 |\n",
            "|    clip_fraction        | 0.00278      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.654       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1e+04        |\n",
            "|    n_updates            | 9600         |\n",
            "|    policy_gradient_loss | 0.0007       |\n",
            "|    value_loss           | 2.45e+04     |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| time/                   |            |\n",
            "|    fps                  | 584        |\n",
            "|    iterations           | 962        |\n",
            "|    time_elapsed         | 3371       |\n",
            "|    total_timesteps      | 1970176    |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00198807 |\n",
            "|    clip_fraction        | 0.00596    |\n",
            "|    clip_range           | 0.2        |\n",
            "|    entropy_loss         | -0.638     |\n",
            "|    explained_variance   | -1.19e-07  |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 1.26e+04   |\n",
            "|    n_updates            | 9610       |\n",
            "|    policy_gradient_loss | -0.00354   |\n",
            "|    value_loss           | 2.23e+04   |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 584         |\n",
            "|    iterations           | 963         |\n",
            "|    time_elapsed         | 3375        |\n",
            "|    total_timesteps      | 1972224     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.006286617 |\n",
            "|    clip_fraction        | 0.0336      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.653      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 9.77e+03    |\n",
            "|    n_updates            | 9620        |\n",
            "|    policy_gradient_loss | -0.00538    |\n",
            "|    value_loss           | 2.17e+04    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 964          |\n",
            "|    time_elapsed         | 3378         |\n",
            "|    total_timesteps      | 1974272      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0022261748 |\n",
            "|    clip_fraction        | 0.135        |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.652       |\n",
            "|    explained_variance   | 1.19e-07     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 9.36e+03     |\n",
            "|    n_updates            | 9630         |\n",
            "|    policy_gradient_loss | -0.000162    |\n",
            "|    value_loss           | 2.16e+04     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 584         |\n",
            "|    iterations           | 965         |\n",
            "|    time_elapsed         | 3382        |\n",
            "|    total_timesteps      | 1976320     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001969579 |\n",
            "|    clip_fraction        | 0.0224      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.639      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.17e+04    |\n",
            "|    n_updates            | 9640        |\n",
            "|    policy_gradient_loss | -0.00482    |\n",
            "|    value_loss           | 2.13e+04    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 966          |\n",
            "|    time_elapsed         | 3385         |\n",
            "|    total_timesteps      | 1978368      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0022698073 |\n",
            "|    clip_fraction        | 0.00542      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.666       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.11e+04     |\n",
            "|    n_updates            | 9650         |\n",
            "|    policy_gradient_loss | -0.0038      |\n",
            "|    value_loss           | 2.23e+04     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 584         |\n",
            "|    iterations           | 967         |\n",
            "|    time_elapsed         | 3389        |\n",
            "|    total_timesteps      | 1980416     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.011480248 |\n",
            "|    clip_fraction        | 0.121       |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.641      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.23e+04    |\n",
            "|    n_updates            | 9660        |\n",
            "|    policy_gradient_loss | 0.000427    |\n",
            "|    value_loss           | 2.27e+04    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 584         |\n",
            "|    iterations           | 968         |\n",
            "|    time_elapsed         | 3392        |\n",
            "|    total_timesteps      | 1982464     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.005219204 |\n",
            "|    clip_fraction        | 0.0232      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.653      |\n",
            "|    explained_variance   | 5.96e-08    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1e+04       |\n",
            "|    n_updates            | 9670        |\n",
            "|    policy_gradient_loss | -0.00576    |\n",
            "|    value_loss           | 2.33e+04    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 969          |\n",
            "|    time_elapsed         | 3396         |\n",
            "|    total_timesteps      | 1984512      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0039750105 |\n",
            "|    clip_fraction        | 0.00796      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.617       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.26e+04     |\n",
            "|    n_updates            | 9680         |\n",
            "|    policy_gradient_loss | -0.00251     |\n",
            "|    value_loss           | 2.36e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 970          |\n",
            "|    time_elapsed         | 3399         |\n",
            "|    total_timesteps      | 1986560      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018934038 |\n",
            "|    clip_fraction        | 0.00117      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.659       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.18e+04     |\n",
            "|    n_updates            | 9690         |\n",
            "|    policy_gradient_loss | -0.00309     |\n",
            "|    value_loss           | 2.19e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 971          |\n",
            "|    time_elapsed         | 3403         |\n",
            "|    total_timesteps      | 1988608      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0041618855 |\n",
            "|    clip_fraction        | 0.0326       |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.62        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.29e+04     |\n",
            "|    n_updates            | 9700         |\n",
            "|    policy_gradient_loss | -0.00507     |\n",
            "|    value_loss           | 2.25e+04     |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 584         |\n",
            "|    iterations           | 972         |\n",
            "|    time_elapsed         | 3406        |\n",
            "|    total_timesteps      | 1990656     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004200423 |\n",
            "|    clip_fraction        | 0.0841      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.655      |\n",
            "|    explained_variance   | -1.19e-07   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 9.66e+03    |\n",
            "|    n_updates            | 9710        |\n",
            "|    policy_gradient_loss | 0.00152     |\n",
            "|    value_loss           | 2.09e+04    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 584         |\n",
            "|    iterations           | 973         |\n",
            "|    time_elapsed         | 3410        |\n",
            "|    total_timesteps      | 1992704     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.004306098 |\n",
            "|    clip_fraction        | 0.0501      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.586      |\n",
            "|    explained_variance   | -1.19e-07   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 9.56e+03    |\n",
            "|    n_updates            | 9720        |\n",
            "|    policy_gradient_loss | -0.00602    |\n",
            "|    value_loss           | 2.21e+04    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 584         |\n",
            "|    iterations           | 974         |\n",
            "|    time_elapsed         | 3413        |\n",
            "|    total_timesteps      | 1994752     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.009469417 |\n",
            "|    clip_fraction        | 0.0691      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.623      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.09e+04    |\n",
            "|    n_updates            | 9730        |\n",
            "|    policy_gradient_loss | -0.00136    |\n",
            "|    value_loss           | 2.11e+04    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 584         |\n",
            "|    iterations           | 975         |\n",
            "|    time_elapsed         | 3417        |\n",
            "|    total_timesteps      | 1996800     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008755143 |\n",
            "|    clip_fraction        | 0.0337      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.668      |\n",
            "|    explained_variance   | -1.19e-07   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 8.75e+03    |\n",
            "|    n_updates            | 9740        |\n",
            "|    policy_gradient_loss | -0.00735    |\n",
            "|    value_loss           | 2.11e+04    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| time/                   |             |\n",
            "|    fps                  | 584         |\n",
            "|    iterations           | 976         |\n",
            "|    time_elapsed         | 3420        |\n",
            "|    total_timesteps      | 1998848     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.003265436 |\n",
            "|    clip_fraction        | 0.0214      |\n",
            "|    clip_range           | 0.2         |\n",
            "|    entropy_loss         | -0.671      |\n",
            "|    explained_variance   | 0           |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 1.44e+04    |\n",
            "|    n_updates            | 9750        |\n",
            "|    policy_gradient_loss | -0.00366    |\n",
            "|    value_loss           | 2.15e+04    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| time/                   |              |\n",
            "|    fps                  | 584          |\n",
            "|    iterations           | 977          |\n",
            "|    time_elapsed         | 3424         |\n",
            "|    total_timesteps      | 2000896      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0034227394 |\n",
            "|    clip_fraction        | 0.00991      |\n",
            "|    clip_range           | 0.2          |\n",
            "|    entropy_loss         | -0.694       |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 1.22e+04     |\n",
            "|    n_updates            | 9760         |\n",
            "|    policy_gradient_loss | -0.00435     |\n",
            "|    value_loss           | 2.28e+04     |\n",
            "------------------------------------------\n",
            "Model saved as ppo_2048.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from stable_baselines3 import PPO\n",
        "\n",
        "# Load model\n",
        "model = PPO.load(\"ppo_2048\")\n",
        "\n",
        "env = Game2048Env(render_mode=\"ansi\")\n",
        "\n",
        "obs, info = env.reset()\n",
        "done = False\n",
        "step = 0\n",
        "\n",
        "print(\"Initial board:\")\n",
        "print(env._board_to_string())\n",
        "\n",
        "while not done:\n",
        "    # stochastic actions so you can see exploration / variability\n",
        "    action, _ = model.predict(obs, deterministic=False)\n",
        "    obs, reward, terminated, truncated, info = env.step(action)\n",
        "    done = terminated or truncated\n",
        "\n",
        "    print(f\"\\nStep {step}, action={action}, reward={reward}, score={info['score']}\")\n",
        "    print(env._board_to_string())\n",
        "    time.sleep(0.1)\n",
        "    step += 1\n",
        "\n",
        "print(\"\\nEpisode finished.\")\n",
        "print(f\"Final score: {info['score']}, max tile: {info['max_tile']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iPhPC9Mdsp8z",
        "outputId": "d07d701e-a714-44ae-92b2-17f1beefa3fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial board:\n",
            ".\t.\t.\t.\n",
            "2\t.\t.\t2\n",
            ".\t.\t.\t.\n",
            ".\t.\t.\t.\n",
            "\n",
            "Step 0, action=0, reward=0, score=0\n",
            "2\t2\t.\t2\n",
            ".\t.\t.\t.\n",
            ".\t.\t.\t.\n",
            ".\t.\t.\t.\n",
            "\n",
            "Step 1, action=3, reward=4, score=4\n",
            ".\t.\t2\t4\n",
            ".\t.\t.\t.\n",
            ".\t.\t2\t.\n",
            ".\t.\t.\t.\n",
            "\n",
            "Step 2, action=1, reward=4, score=8\n",
            ".\t.\t.\t.\n",
            ".\t.\t.\t.\n",
            ".\t2\t.\t.\n",
            ".\t.\t4\t4\n",
            "\n",
            "Step 3, action=0, reward=0, score=8\n",
            ".\t2\t4\t4\n",
            ".\t.\t.\t.\n",
            ".\t2\t.\t.\n",
            ".\t.\t.\t.\n",
            "\n",
            "Step 4, action=3, reward=8, score=16\n",
            ".\t.\t2\t8\n",
            ".\t.\t.\t.\n",
            "2\t.\t.\t2\n",
            ".\t.\t.\t.\n",
            "\n",
            "Step 5, action=3, reward=4, score=20\n",
            ".\t.\t2\t8\n",
            "2\t.\t.\t.\n",
            ".\t.\t.\t4\n",
            ".\t.\t.\t.\n",
            "\n",
            "Step 6, action=1, reward=0, score=20\n",
            "4\t.\t.\t.\n",
            ".\t.\t.\t.\n",
            ".\t.\t.\t8\n",
            "2\t.\t2\t4\n",
            "\n",
            "Step 7, action=0, reward=0, score=20\n",
            "4\t.\t2\t8\n",
            "2\t.\t.\t4\n",
            ".\t.\t.\t.\n",
            "2\t.\t.\t.\n",
            "\n",
            "Step 8, action=1, reward=4, score=24\n",
            ".\t.\t.\t.\n",
            ".\t.\t.\t2\n",
            "4\t.\t.\t8\n",
            "4\t.\t2\t4\n",
            "\n",
            "Step 9, action=2, reward=0, score=24\n",
            ".\t.\t.\t.\n",
            "2\t2\t.\t.\n",
            "4\t8\t.\t.\n",
            "4\t2\t4\t.\n",
            "\n",
            "Step 10, action=0, reward=8, score=32\n",
            "2\t2\t4\t.\n",
            "8\t8\t.\t.\n",
            ".\t2\t.\t2\n",
            ".\t.\t.\t.\n",
            "\n",
            "Step 11, action=3, reward=24, score=56\n",
            ".\t.\t4\t4\n",
            ".\t.\t.\t16\n",
            ".\t.\t.\t4\n",
            "2\t.\t.\t.\n",
            "\n",
            "Step 12, action=1, reward=0, score=56\n",
            ".\t.\t.\t.\n",
            ".\t.\t.\t4\n",
            ".\t.\t2\t16\n",
            "2\t.\t4\t4\n",
            "\n",
            "Step 13, action=2, reward=8, score=64\n",
            "2\t.\t.\t.\n",
            "4\t.\t.\t.\n",
            "2\t16\t.\t.\n",
            "2\t8\t.\t.\n",
            "\n",
            "Step 14, action=0, reward=4, score=68\n",
            "2\t16\t.\t.\n",
            "4\t8\t.\t.\n",
            "4\t2\t.\t.\n",
            ".\t.\t.\t.\n",
            "\n",
            "Step 15, action=3, reward=0, score=68\n",
            ".\t.\t2\t16\n",
            ".\t.\t4\t8\n",
            ".\t.\t4\t2\n",
            "2\t.\t.\t.\n",
            "\n",
            "Step 16, action=1, reward=8, score=76\n",
            ".\t.\t.\t.\n",
            "4\t.\t.\t16\n",
            ".\t.\t2\t8\n",
            "2\t.\t8\t2\n",
            "\n",
            "Step 17, action=2, reward=0, score=76\n",
            ".\t.\t.\t.\n",
            "4\t16\t.\t.\n",
            "2\t8\t.\t.\n",
            "2\t8\t2\t2\n",
            "\n",
            "Step 18, action=0, reward=20, score=96\n",
            "4\t16\t2\t2\n",
            "4\t16\t.\t.\n",
            ".\t.\t2\t.\n",
            ".\t.\t.\t.\n",
            "\n",
            "Step 19, action=3, reward=4, score=100\n",
            ".\t4\t16\t4\n",
            ".\t.\t4\t16\n",
            ".\t.\t.\t2\n",
            "2\t.\t.\t.\n",
            "\n",
            "Step 20, action=1, reward=0, score=100\n",
            ".\t2\t.\t.\n",
            ".\t.\t.\t4\n",
            ".\t.\t16\t16\n",
            "2\t4\t4\t2\n",
            "\n",
            "Step 21, action=2, reward=40, score=140\n",
            "2\t.\t.\t.\n",
            "4\t.\t2\t.\n",
            "32\t.\t.\t.\n",
            "2\t8\t2\t.\n",
            "\n",
            "Step 22, action=2, reward=0, score=140\n",
            "2\t.\t.\t.\n",
            "4\t2\t.\t.\n",
            "32\t2\t.\t.\n",
            "2\t8\t2\t.\n",
            "\n",
            "Step 23, action=3, reward=0, score=140\n",
            ".\t.\t.\t2\n",
            ".\t.\t4\t2\n",
            ".\t.\t32\t2\n",
            "2\t2\t8\t2\n",
            "\n",
            "Step 24, action=2, reward=4, score=144\n",
            "2\t.\t.\t.\n",
            "4\t2\t.\t2\n",
            "32\t2\t.\t.\n",
            "4\t8\t2\t.\n",
            "\n",
            "Step 25, action=0, reward=4, score=148\n",
            "2\t4\t2\t2\n",
            "4\t8\t.\t.\n",
            "32\t.\t2\t.\n",
            "4\t.\t.\t.\n",
            "\n",
            "Step 26, action=3, reward=4, score=152\n",
            ".\t2\t4\t4\n",
            ".\t.\t4\t8\n",
            ".\t.\t32\t2\n",
            ".\t2\t.\t4\n",
            "\n",
            "Step 27, action=1, reward=12, score=164\n",
            ".\t.\t2\t4\n",
            ".\t.\t.\t8\n",
            ".\t.\t8\t2\n",
            ".\t4\t32\t4\n",
            "\n",
            "Step 28, action=2, reward=0, score=164\n",
            "2\t4\t.\t.\n",
            "8\t.\t.\t.\n",
            "8\t2\t.\t2\n",
            "4\t32\t4\t.\n",
            "\n",
            "Step 29, action=0, reward=16, score=180\n",
            "2\t4\t4\t2\n",
            "16\t2\t.\t.\n",
            "4\t32\t.\t.\n",
            ".\t2\t.\t.\n",
            "\n",
            "Step 30, action=3, reward=8, score=188\n",
            "2\t2\t8\t2\n",
            ".\t.\t16\t2\n",
            ".\t.\t4\t32\n",
            ".\t.\t.\t2\n",
            "\n",
            "Step 31, action=1, reward=4, score=192\n",
            ".\t.\t.\t.\n",
            ".\t.\t8\t4\n",
            "2\t.\t16\t32\n",
            "2\t2\t4\t2\n",
            "\n",
            "Step 32, action=2, reward=4, score=196\n",
            ".\t.\t2\t.\n",
            "8\t4\t.\t.\n",
            "2\t16\t32\t.\n",
            "4\t4\t2\t.\n",
            "\n",
            "Step 33, action=0, reward=0, score=196\n",
            "8\t4\t2\t.\n",
            "2\t16\t32\t.\n",
            "4\t4\t2\t.\n",
            ".\t2\t.\t.\n",
            "\n",
            "Step 34, action=3, reward=8, score=204\n",
            ".\t8\t4\t2\n",
            ".\t2\t16\t32\n",
            ".\t.\t8\t2\n",
            ".\t.\t2\t2\n",
            "\n",
            "Step 35, action=1, reward=4, score=208\n",
            ".\t.\t4\t2\n",
            ".\t.\t16\t2\n",
            ".\t8\t8\t32\n",
            ".\t2\t2\t4\n",
            "\n",
            "Step 36, action=2, reward=20, score=228\n",
            "4\t2\t.\t.\n",
            "16\t2\t.\t.\n",
            "16\t32\t.\t.\n",
            "4\t4\t4\t.\n",
            "\n",
            "Step 37, action=0, reward=36, score=264\n",
            "4\t4\t4\t.\n",
            "32\t32\t.\t.\n",
            "4\t4\t.\t.\n",
            ".\t.\t2\t.\n",
            "\n",
            "Step 38, action=3, reward=80, score=344\n",
            ".\t.\t4\t8\n",
            ".\t.\t.\t64\n",
            "2\t.\t.\t8\n",
            ".\t.\t.\t2\n",
            "\n",
            "Step 39, action=1, reward=0, score=344\n",
            ".\t.\t.\t8\n",
            ".\t.\t2\t64\n",
            ".\t.\t.\t8\n",
            "2\t.\t4\t2\n",
            "\n",
            "Step 40, action=2, reward=0, score=344\n",
            "8\t.\t2\t.\n",
            "2\t64\t.\t.\n",
            "8\t.\t.\t.\n",
            "2\t4\t2\t.\n",
            "\n",
            "Step 41, action=0, reward=4, score=348\n",
            "8\t64\t4\t.\n",
            "2\t4\t.\t.\n",
            "8\t.\t.\t.\n",
            "2\t2\t.\t.\n",
            "\n",
            "Step 42, action=3, reward=4, score=352\n",
            ".\t8\t64\t4\n",
            ".\t2\t2\t4\n",
            ".\t.\t.\t8\n",
            ".\t.\t.\t4\n",
            "\n",
            "Step 43, action=1, reward=8, score=360\n",
            ".\t.\t.\t2\n",
            ".\t.\t.\t8\n",
            ".\t8\t64\t8\n",
            ".\t2\t2\t4\n",
            "\n",
            "Step 44, action=1, reward=16, score=376\n",
            ".\t.\t.\t.\n",
            ".\t.\t2\t2\n",
            ".\t8\t64\t16\n",
            ".\t2\t2\t4\n",
            "\n",
            "Step 45, action=2, reward=8, score=384\n",
            ".\t.\t.\t.\n",
            "4\t.\t.\t.\n",
            "8\t64\t16\t.\n",
            "4\t4\t.\t2\n",
            "\n",
            "Step 46, action=0, reward=0, score=384\n",
            "4\t64\t16\t2\n",
            "8\t4\t.\t.\n",
            "4\t.\t.\t.\n",
            "2\t.\t.\t.\n",
            "\n",
            "Step 47, action=3, reward=0, score=384\n",
            "4\t64\t16\t2\n",
            ".\t.\t8\t4\n",
            ".\t2\t.\t4\n",
            ".\t.\t.\t2\n",
            "\n",
            "Step 48, action=1, reward=8, score=392\n",
            ".\t2\t.\t.\n",
            ".\t.\t.\t2\n",
            ".\t64\t16\t8\n",
            "4\t2\t8\t2\n",
            "\n",
            "Step 49, action=2, reward=0, score=392\n",
            "2\t.\t.\t4\n",
            "2\t.\t.\t.\n",
            "64\t16\t8\t.\n",
            "4\t2\t8\t2\n",
            "\n",
            "Step 50, action=0, reward=20, score=412\n",
            "4\t16\t16\t4\n",
            "64\t2\t.\t2\n",
            "4\t.\t.\t.\n",
            ".\t.\t.\t2\n",
            "\n",
            "Step 51, action=3, reward=36, score=448\n",
            ".\t4\t32\t4\n",
            ".\t.\t64\t4\n",
            ".\t.\t2\t4\n",
            ".\t.\t.\t2\n",
            "\n",
            "Step 52, action=1, reward=8, score=456\n",
            ".\t.\t.\t2\n",
            ".\t.\t32\t4\n",
            ".\t.\t64\t8\n",
            ".\t4\t2\t2\n",
            "\n",
            "Step 53, action=1, reward=-1.0, score=455.0\n",
            ".\t.\t.\t2\n",
            ".\t.\t32\t4\n",
            ".\t.\t64\t8\n",
            ".\t4\t2\t2\n",
            "\n",
            "Step 54, action=1, reward=-1.0, score=454.0\n",
            ".\t.\t.\t2\n",
            ".\t.\t32\t4\n",
            ".\t.\t64\t8\n",
            ".\t4\t2\t2\n",
            "\n",
            "Step 55, action=3, reward=4, score=458.0\n",
            ".\t2\t.\t2\n",
            ".\t.\t32\t4\n",
            ".\t.\t64\t8\n",
            ".\t.\t4\t4\n",
            "\n",
            "Step 56, action=1, reward=0, score=458.0\n",
            ".\t.\t.\t2\n",
            "2\t.\t32\t4\n",
            ".\t.\t64\t8\n",
            ".\t2\t4\t4\n",
            "\n",
            "Step 57, action=1, reward=0, score=458.0\n",
            ".\t.\t.\t2\n",
            ".\t.\t32\t4\n",
            ".\t2\t64\t8\n",
            "2\t2\t4\t4\n",
            "\n",
            "Step 58, action=2, reward=12, score=470.0\n",
            "2\t.\t2\t.\n",
            "32\t4\t.\t.\n",
            "2\t64\t8\t.\n",
            "4\t8\t.\t.\n",
            "\n",
            "Step 59, action=0, reward=0, score=470.0\n",
            "2\t4\t2\t.\n",
            "32\t64\t8\t2\n",
            "2\t8\t.\t.\n",
            "4\t.\t.\t.\n",
            "\n",
            "Step 60, action=3, reward=0, score=470.0\n",
            ".\t2\t4\t2\n",
            "32\t64\t8\t2\n",
            "2\t.\t2\t8\n",
            ".\t.\t.\t4\n",
            "\n",
            "Step 61, action=1, reward=4, score=474.0\n",
            ".\t.\t.\t.\n",
            ".\t4\t4\t4\n",
            "32\t2\t8\t8\n",
            "2\t64\t2\t4\n",
            "\n",
            "Step 62, action=2, reward=24, score=498.0\n",
            ".\t.\t.\t.\n",
            "8\t4\t.\t2\n",
            "32\t2\t16\t.\n",
            "2\t64\t2\t4\n",
            "\n",
            "Step 63, action=0, reward=0, score=498.0\n",
            "8\t4\t16\t2\n",
            "32\t2\t2\t4\n",
            "2\t64\t.\t.\n",
            ".\t.\t2\t.\n",
            "\n",
            "Step 64, action=3, reward=4, score=502.0\n",
            "8\t4\t16\t2\n",
            "2\t32\t4\t4\n",
            ".\t.\t2\t64\n",
            ".\t.\t.\t2\n",
            "\n",
            "Step 65, action=1, reward=0, score=502.0\n",
            "2\t.\t.\t2\n",
            ".\t.\t16\t4\n",
            "8\t4\t4\t64\n",
            "2\t32\t2\t2\n",
            "\n",
            "Step 66, action=2, reward=16, score=518.0\n",
            "4\t.\t.\t.\n",
            "16\t4\t.\t.\n",
            "8\t8\t64\t.\n",
            "2\t32\t4\t2\n",
            "\n",
            "Step 67, action=0, reward=0, score=518.0\n",
            "4\t4\t64\t2\n",
            "16\t8\t4\t.\n",
            "8\t32\t.\t2\n",
            "2\t.\t.\t.\n",
            "\n",
            "Step 68, action=3, reward=8, score=526.0\n",
            ".\t8\t64\t2\n",
            "4\t16\t8\t4\n",
            ".\t8\t32\t2\n",
            ".\t.\t.\t2\n",
            "\n",
            "Step 69, action=1, reward=4, score=530.0\n",
            "2\t.\t.\t.\n",
            ".\t8\t64\t2\n",
            ".\t16\t8\t4\n",
            "4\t8\t32\t4\n",
            "\n",
            "Step 70, action=2, reward=0, score=530.0\n",
            "2\t.\t.\t2\n",
            "8\t64\t2\t.\n",
            "16\t8\t4\t.\n",
            "4\t8\t32\t4\n",
            "\n",
            "Step 71, action=0, reward=16, score=546.0\n",
            "2\t64\t2\t2\n",
            "8\t16\t4\t4\n",
            "16\t.\t32\t.\n",
            "4\t2\t.\t.\n",
            "\n",
            "Step 72, action=3, reward=12, score=558.0\n",
            ".\t2\t64\t4\n",
            ".\t8\t16\t8\n",
            ".\t.\t16\t32\n",
            ".\t2\t4\t2\n",
            "\n",
            "Step 73, action=1, reward=32, score=590.0\n",
            ".\t.\t.\t4\n",
            ".\t2\t64\t8\n",
            "2\t8\t32\t32\n",
            ".\t2\t4\t2\n",
            "\n",
            "Step 74, action=2, reward=64, score=654.0\n",
            "4\t2\t.\t.\n",
            "2\t64\t8\t.\n",
            "2\t8\t64\t.\n",
            "2\t4\t2\t.\n",
            "\n",
            "Step 75, action=0, reward=4, score=658.0\n",
            "4\t2\t8\t.\n",
            "4\t64\t64\t.\n",
            "2\t8\t2\t.\n",
            ".\t4\t.\t2\n",
            "\n",
            "Step 76, action=3, reward=128, score=786.0\n",
            ".\t4\t2\t8\n",
            ".\t.\t4\t128\n",
            ".\t2\t8\t2\n",
            ".\t2\t4\t2\n",
            "\n",
            "Step 77, action=1, reward=8, score=794.0\n",
            ".\t.\t2\t.\n",
            ".\t.\t4\t8\n",
            ".\t4\t8\t128\n",
            "2\t4\t4\t4\n",
            "\n",
            "Step 78, action=2, reward=8, score=802.0\n",
            "2\t.\t.\t.\n",
            "4\t8\t.\t.\n",
            "4\t8\t128\t.\n",
            "2\t8\t4\t2\n",
            "\n",
            "Step 79, action=0, reward=24, score=826.0\n",
            "2\t16\t128\t2\n",
            "8\t8\t4\t.\n",
            "2\t.\t.\t2\n",
            ".\t.\t.\t.\n",
            "\n",
            "Step 80, action=1, reward=4, score=830.0\n",
            "2\t.\t.\t.\n",
            "2\t.\t.\t.\n",
            "8\t16\t128\t.\n",
            "2\t8\t4\t4\n",
            "\n",
            "Step 81, action=2, reward=8, score=838.0\n",
            "2\t.\t.\t.\n",
            "2\t.\t2\t.\n",
            "8\t16\t128\t.\n",
            "2\t8\t8\t.\n",
            "\n",
            "Step 82, action=0, reward=4, score=842.0\n",
            "4\t16\t2\t.\n",
            "8\t8\t128\t.\n",
            "2\t.\t8\t2\n",
            ".\t.\t.\t.\n",
            "\n",
            "Step 83, action=3, reward=16, score=858.0\n",
            ".\t4\t16\t2\n",
            ".\t2\t16\t128\n",
            ".\t2\t8\t2\n",
            ".\t.\t.\t.\n",
            "\n",
            "Step 84, action=1, reward=36, score=894.0\n",
            ".\t.\t.\t4\n",
            ".\t.\t.\t2\n",
            ".\t4\t32\t128\n",
            ".\t4\t8\t2\n",
            "\n",
            "Step 85, action=2, reward=0, score=894.0\n",
            "4\t.\t.\t.\n",
            "2\t.\t.\t.\n",
            "4\t32\t128\t4\n",
            "4\t8\t2\t.\n",
            "\n",
            "Step 86, action=0, reward=8, score=902.0\n",
            "4\t32\t128\t4\n",
            "2\t8\t2\t.\n",
            "8\t.\t.\t.\n",
            ".\t2\t.\t.\n",
            "\n",
            "Step 87, action=3, reward=0, score=902.0\n",
            "4\t32\t128\t4\n",
            ".\t2\t8\t2\n",
            ".\t.\t.\t8\n",
            "2\t.\t.\t2\n",
            "\n",
            "Step 88, action=1, reward=0, score=902.0\n",
            ".\t.\t2\t4\n",
            ".\t.\t.\t2\n",
            "4\t32\t128\t8\n",
            "2\t2\t8\t2\n",
            "\n",
            "Step 89, action=2, reward=4, score=906.0\n",
            "2\t4\t2\t.\n",
            "2\t.\t.\t.\n",
            "4\t32\t128\t8\n",
            "4\t8\t2\t.\n",
            "\n",
            "Step 90, action=0, reward=12, score=918.0\n",
            "4\t4\t2\t8\n",
            "8\t32\t128\t.\n",
            ".\t8\t2\t2\n",
            ".\t.\t.\t.\n",
            "\n",
            "Step 91, action=3, reward=12, score=930.0\n",
            ".\t8\t2\t8\n",
            "2\t8\t32\t128\n",
            ".\t.\t8\t4\n",
            ".\t.\t.\t.\n",
            "\n",
            "Step 92, action=1, reward=16, score=946.0\n",
            ".\t.\t.\t.\n",
            ".\t.\t2\t8\n",
            "2\t.\t32\t128\n",
            "2\t16\t8\t4\n",
            "\n",
            "Step 93, action=2, reward=0, score=946.0\n",
            ".\t.\t2\t.\n",
            "2\t8\t.\t.\n",
            "2\t32\t128\t.\n",
            "2\t16\t8\t4\n",
            "\n",
            "Step 94, action=0, reward=4, score=950.0\n",
            "4\t8\t2\t4\n",
            "2\t32\t128\t.\n",
            ".\t16\t8\t.\n",
            ".\t.\t.\t2\n",
            "\n",
            "Step 95, action=3, reward=0, score=950.0\n",
            "4\t8\t2\t4\n",
            ".\t2\t32\t128\n",
            ".\t2\t16\t8\n",
            ".\t.\t.\t2\n",
            "\n",
            "Step 96, action=1, reward=4, score=954.0\n",
            "2\t.\t.\t4\n",
            ".\t.\t2\t128\n",
            ".\t8\t32\t8\n",
            "4\t4\t16\t2\n",
            "\n",
            "Step 97, action=2, reward=8, score=962.0\n",
            "2\t4\t.\t.\n",
            "2\t128\t2\t.\n",
            "8\t32\t8\t.\n",
            "8\t16\t2\t.\n",
            "\n",
            "Step 98, action=0, reward=20, score=982.0\n",
            "4\t4\t2\t.\n",
            "16\t128\t8\t.\n",
            ".\t32\t2\t.\n",
            ".\t16\t.\t2\n",
            "\n",
            "Step 99, action=0, reward=0, score=982.0\n",
            "4\t4\t2\t2\n",
            "16\t128\t8\t.\n",
            ".\t32\t2\t.\n",
            ".\t16\t.\t2\n",
            "\n",
            "Step 100, action=3, reward=12, score=994.0\n",
            ".\t2\t8\t4\n",
            ".\t16\t128\t8\n",
            ".\t.\t32\t2\n",
            ".\t.\t16\t2\n",
            "\n",
            "Step 101, action=1, reward=4, score=998.0\n",
            "2\t.\t8\t.\n",
            ".\t.\t128\t4\n",
            ".\t2\t32\t8\n",
            ".\t16\t16\t4\n",
            "\n",
            "Step 102, action=2, reward=32, score=1030.0\n",
            "2\t8\t.\t2\n",
            "128\t4\t.\t.\n",
            "2\t32\t8\t.\n",
            "32\t4\t.\t.\n",
            "\n",
            "Step 103, action=0, reward=0, score=1030.0\n",
            "2\t8\t8\t2\n",
            "128\t4\t2\t.\n",
            "2\t32\t.\t.\n",
            "32\t4\t.\t.\n",
            "\n",
            "Step 104, action=3, reward=16, score=1046.0\n",
            ".\t2\t16\t2\n",
            ".\t128\t4\t2\n",
            "2\t.\t2\t32\n",
            ".\t.\t32\t4\n",
            "\n",
            "Step 105, action=1, reward=4, score=1050.0\n",
            ".\t2\t16\t.\n",
            ".\t.\t4\t4\n",
            ".\t2\t2\t32\n",
            "2\t128\t32\t4\n",
            "\n",
            "Step 106, action=2, reward=12, score=1062.0\n",
            "2\t16\t.\t.\n",
            "8\t2\t.\t.\n",
            "4\t32\t.\t.\n",
            "2\t128\t32\t4\n",
            "\n",
            "Step 107, action=0, reward=0, score=1062.0\n",
            "2\t16\t32\t4\n",
            "8\t2\t2\t.\n",
            "4\t32\t.\t.\n",
            "2\t128\t.\t.\n",
            "\n",
            "Step 108, action=3, reward=4, score=1066.0\n",
            "2\t16\t32\t4\n",
            ".\t.\t8\t4\n",
            "2\t.\t4\t32\n",
            ".\t.\t2\t128\n",
            "\n",
            "Step 109, action=1, reward=12, score=1078.0\n",
            ".\t.\t32\t.\n",
            ".\t2\t8\t8\n",
            ".\t.\t4\t32\n",
            "4\t16\t2\t128\n",
            "\n",
            "Step 110, action=2, reward=16, score=1094.0\n",
            "32\t.\t.\t.\n",
            "2\t16\t.\t.\n",
            "4\t32\t2\t.\n",
            "4\t16\t2\t128\n",
            "\n",
            "Step 111, action=0, reward=12, score=1106.0\n",
            "32\t16\t4\t128\n",
            "2\t32\t.\t2\n",
            "8\t16\t.\t.\n",
            ".\t.\t.\t.\n",
            "\n",
            "Step 112, action=3, reward=0, score=1106.0\n",
            "32\t16\t4\t128\n",
            ".\t2\t32\t2\n",
            ".\t.\t8\t16\n",
            ".\t.\t4\t.\n",
            "\n",
            "Step 113, action=1, reward=0, score=1106.0\n",
            ".\t2\t4\t.\n",
            ".\t.\t32\t128\n",
            ".\t16\t8\t2\n",
            "32\t2\t4\t16\n",
            "\n",
            "Step 114, action=2, reward=0, score=1106.0\n",
            "2\t4\t2\t.\n",
            "32\t128\t.\t.\n",
            "16\t8\t2\t.\n",
            "32\t2\t4\t16\n",
            "\n",
            "Step 115, action=0, reward=4, score=1110.0\n",
            "2\t4\t4\t16\n",
            "32\t128\t4\t2\n",
            "16\t8\t.\t.\n",
            "32\t2\t.\t.\n",
            "\n",
            "Step 116, action=3, reward=8, score=1118.0\n",
            ".\t2\t8\t16\n",
            "32\t128\t4\t2\n",
            ".\t.\t16\t8\n",
            "2\t.\t32\t2\n",
            "\n",
            "Step 117, action=2, reward=0, score=1118.0\n",
            "2\t8\t16\t2\n",
            "32\t128\t4\t2\n",
            "16\t8\t.\t.\n",
            "2\t32\t2\t.\n",
            "\n",
            "Step 118, action=3, reward=0, score=1118.0\n",
            "2\t8\t16\t2\n",
            "32\t128\t4\t2\n",
            ".\t2\t16\t8\n",
            ".\t2\t32\t2\n",
            "\n",
            "Step 119, action=1, reward=8, score=1126.0\n",
            ".\t2\t16\t.\n",
            ".\t8\t4\t4\n",
            "2\t128\t16\t8\n",
            "32\t4\t32\t2\n",
            "\n",
            "Step 120, action=1, reward=-1.0, score=1125.0\n",
            ".\t2\t16\t.\n",
            ".\t8\t4\t4\n",
            "2\t128\t16\t8\n",
            "32\t4\t32\t2\n",
            "\n",
            "Step 121, action=2, reward=8, score=1133.0\n",
            "2\t16\t2\t.\n",
            "8\t8\t.\t.\n",
            "2\t128\t16\t8\n",
            "32\t4\t32\t2\n",
            "\n",
            "Step 122, action=2, reward=16, score=1149.0\n",
            "2\t16\t2\t.\n",
            "16\t2\t.\t.\n",
            "2\t128\t16\t8\n",
            "32\t4\t32\t2\n",
            "\n",
            "Step 123, action=2, reward=-1.0, score=1148.0\n",
            "2\t16\t2\t.\n",
            "16\t2\t.\t.\n",
            "2\t128\t16\t8\n",
            "32\t4\t32\t2\n",
            "\n",
            "Step 124, action=0, reward=0, score=1148.0\n",
            "2\t16\t2\t8\n",
            "16\t2\t16\t2\n",
            "2\t128\t32\t.\n",
            "32\t4\t.\t4\n",
            "\n",
            "Step 125, action=3, reward=8, score=1156.0\n",
            "2\t16\t2\t8\n",
            "16\t2\t16\t2\n",
            ".\t2\t128\t32\n",
            "2\t.\t32\t8\n",
            "\n",
            "Step 126, action=1, reward=4, score=1160.0\n",
            ".\t2\t2\t8\n",
            "2\t.\t16\t2\n",
            "16\t16\t128\t32\n",
            "2\t4\t32\t8\n",
            "\n",
            "Step 127, action=3, reward=36, score=1196.0\n",
            ".\t2\t4\t8\n",
            ".\t2\t16\t2\n",
            ".\t32\t128\t32\n",
            "2\t4\t32\t8\n",
            "\n",
            "Step 128, action=2, reward=0, score=1196.0\n",
            "2\t4\t8\t.\n",
            "2\t16\t2\t.\n",
            "32\t128\t32\t2\n",
            "2\t4\t32\t8\n",
            "\n",
            "Step 129, action=0, reward=68, score=1264.0\n",
            "4\t4\t8\t2\n",
            "32\t16\t2\t8\n",
            "2\t128\t64\t2\n",
            ".\t4\t.\t.\n",
            "\n",
            "Step 130, action=3, reward=8, score=1272.0\n",
            ".\t8\t8\t2\n",
            "32\t16\t2\t8\n",
            "2\t128\t64\t2\n",
            ".\t2\t.\t4\n",
            "\n",
            "Step 131, action=1, reward=0, score=1272.0\n",
            ".\t8\t2\t2\n",
            ".\t16\t8\t8\n",
            "32\t128\t2\t2\n",
            "2\t2\t64\t4\n",
            "\n",
            "Step 132, action=3, reward=28, score=1300.0\n",
            ".\t.\t8\t4\n",
            ".\t2\t16\t16\n",
            ".\t32\t128\t4\n",
            ".\t4\t64\t4\n",
            "\n",
            "Step 133, action=2, reward=32, score=1332.0\n",
            "8\t4\t.\t.\n",
            "2\t32\t2\t.\n",
            "32\t128\t4\t.\n",
            "4\t64\t4\t.\n",
            "\n",
            "Step 134, action=0, reward=8, score=1340.0\n",
            "8\t4\t2\t.\n",
            "2\t32\t8\t.\n",
            "32\t128\t.\t.\n",
            "4\t64\t.\t2\n",
            "\n",
            "Step 135, action=0, reward=0, score=1340.0\n",
            "8\t4\t2\t2\n",
            "2\t32\t8\t.\n",
            "32\t128\t2\t.\n",
            "4\t64\t.\t.\n",
            "\n",
            "Step 136, action=3, reward=4, score=1344.0\n",
            ".\t8\t4\t4\n",
            ".\t2\t32\t8\n",
            ".\t32\t128\t2\n",
            "4\t.\t4\t64\n",
            "\n",
            "Step 137, action=2, reward=16, score=1360.0\n",
            "8\t8\t2\t.\n",
            "2\t32\t8\t.\n",
            "32\t128\t2\t.\n",
            "8\t64\t.\t.\n",
            "\n",
            "Step 138, action=2, reward=16, score=1376.0\n",
            "16\t2\t.\t.\n",
            "2\t32\t8\t.\n",
            "32\t128\t2\t.\n",
            "8\t64\t2\t.\n",
            "\n",
            "Step 139, action=0, reward=4, score=1380.0\n",
            "16\t2\t8\t.\n",
            "2\t32\t4\t.\n",
            "32\t128\t2\t.\n",
            "8\t64\t.\t.\n",
            "\n",
            "Step 140, action=2, reward=-1.0, score=1379.0\n",
            "16\t2\t8\t.\n",
            "2\t32\t4\t.\n",
            "32\t128\t2\t.\n",
            "8\t64\t.\t.\n",
            "\n",
            "Step 141, action=0, reward=-1.0, score=1378.0\n",
            "16\t2\t8\t.\n",
            "2\t32\t4\t.\n",
            "32\t128\t2\t.\n",
            "8\t64\t.\t.\n",
            "\n",
            "Step 142, action=3, reward=0, score=1378.0\n",
            ".\t16\t2\t8\n",
            ".\t2\t32\t4\n",
            ".\t32\t128\t2\n",
            "2\t.\t8\t64\n",
            "\n",
            "Step 143, action=2, reward=0, score=1378.0\n",
            "16\t2\t8\t.\n",
            "2\t32\t4\t2\n",
            "32\t128\t2\t.\n",
            "2\t8\t64\t.\n",
            "\n",
            "Step 144, action=0, reward=0, score=1378.0\n",
            "16\t2\t8\t2\n",
            "2\t32\t4\t.\n",
            "32\t128\t2\t2\n",
            "2\t8\t64\t.\n",
            "\n",
            "Step 145, action=0, reward=4, score=1382.0\n",
            "16\t2\t8\t4\n",
            "2\t32\t4\t2\n",
            "32\t128\t2\t.\n",
            "2\t8\t64\t.\n",
            "\n",
            "Step 146, action=0, reward=-1.0, score=1381.0\n",
            "16\t2\t8\t4\n",
            "2\t32\t4\t2\n",
            "32\t128\t2\t.\n",
            "2\t8\t64\t.\n",
            "\n",
            "Step 147, action=3, reward=0, score=1381.0\n",
            "16\t2\t8\t4\n",
            "2\t32\t4\t2\n",
            "2\t32\t128\t2\n",
            ".\t2\t8\t64\n",
            "\n",
            "Step 148, action=1, reward=72, score=1453.0\n",
            ".\t2\t8\t.\n",
            ".\t2\t4\t4\n",
            "16\t64\t128\t4\n",
            "4\t2\t8\t64\n",
            "\n",
            "Step 149, action=2, reward=8, score=1461.0\n",
            "2\t8\t.\t.\n",
            "2\t8\t.\t4\n",
            "16\t64\t128\t4\n",
            "4\t2\t8\t64\n",
            "\n",
            "Step 150, action=2, reward=0, score=1461.0\n",
            "2\t8\t.\t.\n",
            "2\t8\t4\t2\n",
            "16\t64\t128\t4\n",
            "4\t2\t8\t64\n",
            "\n",
            "Step 151, action=2, reward=-1.0, score=1460.0\n",
            "2\t8\t.\t.\n",
            "2\t8\t4\t2\n",
            "16\t64\t128\t4\n",
            "4\t2\t8\t64\n",
            "\n",
            "Step 152, action=2, reward=-1.0, score=1459.0\n",
            "2\t8\t.\t.\n",
            "2\t8\t4\t2\n",
            "16\t64\t128\t4\n",
            "4\t2\t8\t64\n",
            "\n",
            "Step 153, action=2, reward=-1.0, score=1458.0\n",
            "2\t8\t.\t.\n",
            "2\t8\t4\t2\n",
            "16\t64\t128\t4\n",
            "4\t2\t8\t64\n",
            "\n",
            "Step 154, action=2, reward=-1.0, score=1457.0\n",
            "2\t8\t.\t.\n",
            "2\t8\t4\t2\n",
            "16\t64\t128\t4\n",
            "4\t2\t8\t64\n",
            "\n",
            "Step 155, action=2, reward=-1.0, score=1456.0\n",
            "2\t8\t.\t.\n",
            "2\t8\t4\t2\n",
            "16\t64\t128\t4\n",
            "4\t2\t8\t64\n",
            "\n",
            "Step 156, action=2, reward=-1.0, score=1455.0\n",
            "2\t8\t.\t.\n",
            "2\t8\t4\t2\n",
            "16\t64\t128\t4\n",
            "4\t2\t8\t64\n",
            "\n",
            "Step 157, action=2, reward=-1.0, score=1454.0\n",
            "2\t8\t.\t.\n",
            "2\t8\t4\t2\n",
            "16\t64\t128\t4\n",
            "4\t2\t8\t64\n",
            "\n",
            "Step 158, action=2, reward=-1.0, score=1453.0\n",
            "2\t8\t.\t.\n",
            "2\t8\t4\t2\n",
            "16\t64\t128\t4\n",
            "4\t2\t8\t64\n",
            "\n",
            "Step 159, action=2, reward=-1.0, score=1452.0\n",
            "2\t8\t.\t.\n",
            "2\t8\t4\t2\n",
            "16\t64\t128\t4\n",
            "4\t2\t8\t64\n",
            "\n",
            "Step 160, action=2, reward=-1.0, score=1451.0\n",
            "2\t8\t.\t.\n",
            "2\t8\t4\t2\n",
            "16\t64\t128\t4\n",
            "4\t2\t8\t64\n",
            "\n",
            "Step 161, action=2, reward=-1.0, score=1450.0\n",
            "2\t8\t.\t.\n",
            "2\t8\t4\t2\n",
            "16\t64\t128\t4\n",
            "4\t2\t8\t64\n",
            "\n",
            "Step 162, action=2, reward=-1.0, score=1449.0\n",
            "2\t8\t.\t.\n",
            "2\t8\t4\t2\n",
            "16\t64\t128\t4\n",
            "4\t2\t8\t64\n",
            "\n",
            "Step 163, action=2, reward=-1.0, score=1448.0\n",
            "2\t8\t.\t.\n",
            "2\t8\t4\t2\n",
            "16\t64\t128\t4\n",
            "4\t2\t8\t64\n",
            "\n",
            "Step 164, action=2, reward=-1.0, score=1447.0\n",
            "2\t8\t.\t.\n",
            "2\t8\t4\t2\n",
            "16\t64\t128\t4\n",
            "4\t2\t8\t64\n",
            "\n",
            "Step 165, action=2, reward=-1.0, score=1446.0\n",
            "2\t8\t.\t.\n",
            "2\t8\t4\t2\n",
            "16\t64\t128\t4\n",
            "4\t2\t8\t64\n",
            "\n",
            "Step 166, action=2, reward=-1.0, score=1445.0\n",
            "2\t8\t.\t.\n",
            "2\t8\t4\t2\n",
            "16\t64\t128\t4\n",
            "4\t2\t8\t64\n",
            "\n",
            "Step 167, action=0, reward=20, score=1465.0\n",
            "4\t16\t4\t2\n",
            "16\t64\t128\t4\n",
            "4\t2\t8\t64\n",
            ".\t4\t.\t.\n",
            "\n",
            "Step 168, action=1, reward=0, score=1465.0\n",
            ".\t16\t2\t.\n",
            "4\t64\t4\t2\n",
            "16\t2\t128\t4\n",
            "4\t4\t8\t64\n",
            "\n",
            "Step 169, action=3, reward=8, score=1473.0\n",
            "4\t.\t16\t2\n",
            "4\t64\t4\t2\n",
            "16\t2\t128\t4\n",
            ".\t8\t8\t64\n",
            "\n",
            "Step 170, action=0, reward=12, score=1485.0\n",
            "8\t64\t16\t4\n",
            "16\t2\t4\t4\n",
            ".\t8\t128\t64\n",
            ".\t.\t8\t2\n",
            "\n",
            "Step 171, action=1, reward=8, score=1493.0\n",
            ".\t.\t16\t2\n",
            ".\t64\t4\t8\n",
            "8\t2\t128\t64\n",
            "16\t8\t8\t2\n",
            "\n",
            "Step 172, action=2, reward=16, score=1509.0\n",
            "16\t2\t2\t.\n",
            "64\t4\t8\t.\n",
            "8\t2\t128\t64\n",
            "16\t16\t2\t.\n",
            "\n",
            "Step 173, action=0, reward=0, score=1509.0\n",
            "16\t2\t2\t64\n",
            "64\t4\t8\t2\n",
            "8\t2\t128\t.\n",
            "16\t16\t2\t.\n",
            "\n",
            "Step 174, action=3, reward=36, score=1545.0\n",
            ".\t16\t4\t64\n",
            "64\t4\t8\t2\n",
            ".\t8\t2\t128\n",
            ".\t2\t32\t2\n",
            "\n",
            "Step 175, action=1, reward=0, score=1545.0\n",
            "2\t16\t4\t64\n",
            ".\t4\t8\t2\n",
            ".\t8\t2\t128\n",
            "64\t2\t32\t2\n",
            "\n",
            "Step 176, action=2, reward=0, score=1545.0\n",
            "2\t16\t4\t64\n",
            "4\t8\t2\t2\n",
            "8\t2\t128\t.\n",
            "64\t2\t32\t2\n",
            "\n",
            "Step 177, action=2, reward=4, score=1549.0\n",
            "2\t16\t4\t64\n",
            "4\t8\t4\t.\n",
            "8\t2\t128\t2\n",
            "64\t2\t32\t2\n",
            "\n",
            "Step 178, action=2, reward=-1.0, score=1548.0\n",
            "2\t16\t4\t64\n",
            "4\t8\t4\t.\n",
            "8\t2\t128\t2\n",
            "64\t2\t32\t2\n",
            "\n",
            "Step 179, action=2, reward=-1.0, score=1547.0\n",
            "2\t16\t4\t64\n",
            "4\t8\t4\t.\n",
            "8\t2\t128\t2\n",
            "64\t2\t32\t2\n",
            "\n",
            "Step 180, action=2, reward=-1.0, score=1546.0\n",
            "2\t16\t4\t64\n",
            "4\t8\t4\t.\n",
            "8\t2\t128\t2\n",
            "64\t2\t32\t2\n",
            "\n",
            "Step 181, action=2, reward=-1.0, score=1545.0\n",
            "2\t16\t4\t64\n",
            "4\t8\t4\t.\n",
            "8\t2\t128\t2\n",
            "64\t2\t32\t2\n",
            "\n",
            "Step 182, action=2, reward=-1.0, score=1544.0\n",
            "2\t16\t4\t64\n",
            "4\t8\t4\t.\n",
            "8\t2\t128\t2\n",
            "64\t2\t32\t2\n",
            "\n",
            "Step 183, action=2, reward=-1.0, score=1543.0\n",
            "2\t16\t4\t64\n",
            "4\t8\t4\t.\n",
            "8\t2\t128\t2\n",
            "64\t2\t32\t2\n",
            "\n",
            "Step 184, action=3, reward=0, score=1543.0\n",
            "2\t16\t4\t64\n",
            "2\t4\t8\t4\n",
            "8\t2\t128\t2\n",
            "64\t2\t32\t2\n",
            "\n",
            "Step 185, action=2, reward=-1.0, score=1542.0\n",
            "2\t16\t4\t64\n",
            "2\t4\t8\t4\n",
            "8\t2\t128\t2\n",
            "64\t2\t32\t2\n",
            "\n",
            "Step 186, action=3, reward=-1.0, score=1541.0\n",
            "2\t16\t4\t64\n",
            "2\t4\t8\t4\n",
            "8\t2\t128\t2\n",
            "64\t2\t32\t2\n",
            "\n",
            "Step 187, action=3, reward=-1.0, score=1540.0\n",
            "2\t16\t4\t64\n",
            "2\t4\t8\t4\n",
            "8\t2\t128\t2\n",
            "64\t2\t32\t2\n",
            "\n",
            "Step 188, action=2, reward=-1.0, score=1539.0\n",
            "2\t16\t4\t64\n",
            "2\t4\t8\t4\n",
            "8\t2\t128\t2\n",
            "64\t2\t32\t2\n",
            "\n",
            "Step 189, action=1, reward=12, score=1551.0\n",
            ".\t.\t4\t2\n",
            "4\t16\t8\t64\n",
            "8\t4\t128\t4\n",
            "64\t4\t32\t4\n",
            "\n",
            "Step 190, action=2, reward=0, score=1551.0\n",
            "4\t2\t.\t2\n",
            "4\t16\t8\t64\n",
            "8\t4\t128\t4\n",
            "64\t4\t32\t4\n",
            "\n",
            "Step 191, action=0, reward=24, score=1575.0\n",
            "8\t2\t8\t2\n",
            "8\t16\t128\t64\n",
            "64\t8\t32\t8\n",
            "4\t.\t.\t.\n",
            "\n",
            "Step 192, action=3, reward=0, score=1575.0\n",
            "8\t2\t8\t2\n",
            "8\t16\t128\t64\n",
            "64\t8\t32\t8\n",
            "2\t.\t.\t4\n",
            "\n",
            "Step 193, action=1, reward=16, score=1591.0\n",
            ".\t2\t.\t2\n",
            "16\t2\t8\t64\n",
            "64\t16\t128\t8\n",
            "2\t8\t32\t4\n",
            "\n",
            "Step 194, action=1, reward=4, score=1595.0\n",
            "2\t.\t.\t2\n",
            "16\t4\t8\t64\n",
            "64\t16\t128\t8\n",
            "2\t8\t32\t4\n",
            "\n",
            "Step 195, action=1, reward=-1.0, score=1594.0\n",
            "2\t.\t.\t2\n",
            "16\t4\t8\t64\n",
            "64\t16\t128\t8\n",
            "2\t8\t32\t4\n",
            "\n",
            "Step 196, action=3, reward=4, score=1598.0\n",
            "2\t.\t.\t4\n",
            "16\t4\t8\t64\n",
            "64\t16\t128\t8\n",
            "2\t8\t32\t4\n",
            "\n",
            "Step 197, action=2, reward=0, score=1598.0\n",
            "2\t4\t2\t.\n",
            "16\t4\t8\t64\n",
            "64\t16\t128\t8\n",
            "2\t8\t32\t4\n",
            "\n",
            "Step 198, action=2, reward=-1.0, score=1597.0\n",
            "2\t4\t2\t.\n",
            "16\t4\t8\t64\n",
            "64\t16\t128\t8\n",
            "2\t8\t32\t4\n",
            "\n",
            "Step 199, action=0, reward=8, score=1605.0\n",
            "2\t8\t2\t64\n",
            "16\t16\t8\t8\n",
            "64\t8\t128\t4\n",
            "2\t.\t32\t2\n",
            "\n",
            "Step 200, action=1, reward=0, score=1605.0\n",
            "2\t2\t2\t64\n",
            "16\t8\t8\t8\n",
            "64\t16\t128\t4\n",
            "2\t8\t32\t2\n",
            "\n",
            "Step 201, action=2, reward=20, score=1625.0\n",
            "4\t2\t64\t.\n",
            "16\t16\t8\t2\n",
            "64\t16\t128\t4\n",
            "2\t8\t32\t2\n",
            "\n",
            "Step 202, action=1, reward=32, score=1657.0\n",
            "4\t2\t64\t.\n",
            "16\t2\t8\t2\n",
            "64\t32\t128\t4\n",
            "2\t8\t32\t2\n",
            "\n",
            "Step 203, action=2, reward=-1.0, score=1656.0\n",
            "4\t2\t64\t.\n",
            "16\t2\t8\t2\n",
            "64\t32\t128\t4\n",
            "2\t8\t32\t2\n",
            "\n",
            "Step 204, action=1, reward=4, score=1660.0\n",
            "4\t4\t64\t.\n",
            "16\t4\t8\t2\n",
            "64\t32\t128\t4\n",
            "2\t8\t32\t2\n",
            "\n",
            "Step 205, action=3, reward=8, score=1668.0\n",
            ".\t2\t8\t64\n",
            "16\t4\t8\t2\n",
            "64\t32\t128\t4\n",
            "2\t8\t32\t2\n",
            "\n",
            "Step 206, action=2, reward=0, score=1668.0\n",
            "2\t8\t64\t2\n",
            "16\t4\t8\t2\n",
            "64\t32\t128\t4\n",
            "2\t8\t32\t2\n",
            "\n",
            "Step 207, action=2, reward=-1.0, score=1667.0\n",
            "2\t8\t64\t2\n",
            "16\t4\t8\t2\n",
            "64\t32\t128\t4\n",
            "2\t8\t32\t2\n",
            "\n",
            "Step 208, action=1, reward=4, score=1671.0\n",
            "2\t8\t64\t2\n",
            "16\t4\t8\t4\n",
            "64\t32\t128\t4\n",
            "2\t8\t32\t2\n",
            "\n",
            "Step 209, action=3, reward=-1.0, score=1670.0\n",
            "2\t8\t64\t2\n",
            "16\t4\t8\t4\n",
            "64\t32\t128\t4\n",
            "2\t8\t32\t2\n",
            "\n",
            "Step 210, action=2, reward=-1.0, score=1669.0\n",
            "2\t8\t64\t2\n",
            "16\t4\t8\t4\n",
            "64\t32\t128\t4\n",
            "2\t8\t32\t2\n",
            "\n",
            "Step 211, action=1, reward=8, score=1677.0\n",
            "2\t8\t64\t2\n",
            "16\t4\t8\t2\n",
            "64\t32\t128\t8\n",
            "2\t8\t32\t2\n",
            "\n",
            "Step 212, action=1, reward=4, score=1681.0\n",
            "2\t8\t64\t2\n",
            "16\t4\t8\t4\n",
            "64\t32\t128\t8\n",
            "2\t8\t32\t2\n",
            "\n",
            "Episode finished.\n",
            "Final score: 1681.0, max tile: 128\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git config --global user.email \"sarah04@mit.edu\"\n",
        "!git config --global user.name \"sarah-mokhtar\"\n"
      ],
      "metadata": {
        "id": "KeXlm3vb86nX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/sarah-mokhtar/RL-Project-2048.git\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RWV9bXcNaGZ",
        "outputId": "ec09ae98-8514-44bb-f6a6-2e4280726ac5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'RL-Project-2048' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "!cp 2048\\ RL.ipynb /content/RL-Project-2048/\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "whfNYGcfPrK6",
        "outputId": "eb41e37f-5197-415e-ce7c-7e93be8f0af2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot stat '2048 RL.ipynb': No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd RL-Project-2048\n",
        "\n",
        "!git add .\n",
        "!git commit -m \"PPO\"\n",
        "!git push\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5432T8BPM9d",
        "outputId": "aa2e925f-b3fe-42bd-bae9-35cacaf73c8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'RL-Project-2048'\n",
            "/content/RL-Project-2048\n",
            "On branch main\n",
            "Your branch is up to date with 'origin/main'.\n",
            "\n",
            "nothing to commit, working tree clean\n",
            "fatal: could not read Username for 'https://github.com': No such device or address\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Clone a team/organization repo\n",
        "\n",
        "from getpass import getpass\n",
        "\n",
        "# Get your Personal Access Token\n",
        "print(\"Get token from: https://github.com/settings/tokens\")\n",
        "print(\"Make sure 'repo' scope is checked!\")\n",
        "token = getpass('Paste your GitHub Personal Access Token: ')\n",
        "\n",
        "# Team/Organization repo details\n",
        "org_or_username = \"team-name-or-org\"  # The organization/team name\n",
        "repo_name = \"repo-name\"  # The repository name\n",
        "\n",
        "# Clone with authentication\n",
        "!git clone https://{token}@github.com/{org_or_username}/{repo_name}.git\n",
        "\n",
        "# Navigate into repo\n",
        "%cd {repo_name}\n",
        "\n",
        "# Configure your git identity (important for team repos)\n",
        "!git config user.email \"your-email@example.com\"\n",
        "!git config user.name \"Your Name\"\n",
        "\n",
        "print(\"‚úÖ Team repo cloned successfully!\")"
      ],
      "metadata": {
        "id": "o6JjYhRe80ka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/Ali-Backour/2048_RL.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZxxAXmtb9EzT",
        "outputId": "7cda8cc5-e39c-4de9-b191-4b712d3960ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into '2048_RL'...\n",
            "fatal: could not read Username for 'https://github.com': No such device or address\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "\n",
        "\n",
        "class Game2048EnvV2(gym.Env):\n",
        "    \"\"\"\n",
        "    Version 2 of the 2048 environment.\n",
        "    Same logic as V1, but you can modify reward shaping etc. later.\n",
        "\n",
        "    Normalized observation: exponents / 15.0 ‚Üí float32 in [0,1]\n",
        "    \"\"\"\n",
        "\n",
        "    metadata = {\"render_modes\": [\"ansi\"], \"render_fps\": 60}\n",
        "\n",
        "    def __init__(self, render_mode=None, target_tile=2048):\n",
        "        super().__init__()\n",
        "        self.board_size = 4\n",
        "        self.target_tile = target_tile\n",
        "\n",
        "        self.observation_space = spaces.Box(\n",
        "            low=0.0,\n",
        "            high=1.0,\n",
        "            shape=(4, 4),\n",
        "            dtype=np.float32\n",
        "        )\n",
        "        self.action_space = spaces.Discrete(4)\n",
        "\n",
        "        self.render_mode = render_mode\n",
        "        self.board = np.zeros((4, 4), dtype=np.int32)\n",
        "        self.score = 0.0\n",
        "        self.prev_max_tile = 0\n",
        "        self.rng = np.random.default_rng()\n",
        "\n",
        "    # ---------- Helpers ----------\n",
        "    def _get_obs(self):\n",
        "        return self.board.astype(np.float32) / 15.0\n",
        "\n",
        "    def _slide_and_merge_line(self, line):\n",
        "        non_zero = line[line != 0].tolist()\n",
        "        new = []\n",
        "        reward = 0\n",
        "        i = 0\n",
        "        while i < len(non_zero):\n",
        "            if i+1 < len(non_zero) and non_zero[i] == non_zero[i+1]:\n",
        "                exp = non_zero[i] + 1\n",
        "                new.append(exp)\n",
        "                reward += 2**exp\n",
        "                i += 2\n",
        "            else:\n",
        "                new.append(non_zero[i])\n",
        "                i += 1\n",
        "        new += [0]*(len(line)-len(new))\n",
        "        return np.array(new, dtype=np.int32), reward\n",
        "\n",
        "    def _add_random_tile(self):\n",
        "        empty = list(zip(*np.where(self.board == 0)))\n",
        "        if not empty:\n",
        "            return\n",
        "        r, c = empty[self.rng.integers(len(empty))]\n",
        "        self.board[r,c] = 1 if self.rng.random()<0.9 else 2\n",
        "\n",
        "    def _can_move(self):\n",
        "        if np.any(self.board==0): return True\n",
        "        for r in range(4):\n",
        "            for c in range(3):\n",
        "                if self.board[r,c]==self.board[r,c+1]:\n",
        "                    return True\n",
        "        for c in range(4):\n",
        "            for r in range(3):\n",
        "                if self.board[r,c]==self.board[r+1,c]:\n",
        "                    return True\n",
        "        return False\n",
        "\n",
        "    def _get_max_tile(self):\n",
        "        return 0 if self.board.max()==0 else 2**int(self.board.max())\n",
        "\n",
        "    # ---------- Gym API ----------\n",
        "    def reset(self, seed=None, options=None):\n",
        "        super().reset(seed=seed)\n",
        "        if seed is not None:\n",
        "            self.rng = np.random.default_rng(seed)\n",
        "\n",
        "        self.board[:] = 0\n",
        "        self.score = 0.0\n",
        "        self.prev_max_tile = 0\n",
        "\n",
        "        self._add_random_tile()\n",
        "        self._add_random_tile()\n",
        "\n",
        "        return self._get_obs(), {\"score\":0, \"max_tile\":self._get_max_tile()}\n",
        "\n",
        "    def step(self, action):\n",
        "        old_board = self.board.copy()\n",
        "        reward = 0\n",
        "\n",
        "        if action == 0:\n",
        "            for c in range(4):\n",
        "                new_line, r = self._slide_and_merge_line(self.board[:,c])\n",
        "                self.board[:,c] = new_line\n",
        "                reward += r\n",
        "        elif action == 1:\n",
        "            for c in range(4):\n",
        "                new_line, r = self._slide_and_merge_line(self.board[:,c][::-1])\n",
        "                self.board[:,c] = new_line[::-1]\n",
        "                reward += r\n",
        "        elif action == 2:\n",
        "            for r in range(4):\n",
        "                new_line, rwd = self._slide_and_merge_line(self.board[r])\n",
        "                self.board[r] = new_line\n",
        "                reward += rwd\n",
        "        elif action == 3:\n",
        "            for r in range(4):\n",
        "                new_line, rwd = self._slide_and_merge_line(self.board[r][::-1])\n",
        "                self.board[r] = new_line[::-1]\n",
        "                reward += rwd\n",
        "\n",
        "        moved = not np.array_equal(old_board, self.board)\n",
        "\n",
        "        if not moved:\n",
        "            reward -= 2.0\n",
        "        else:\n",
        "            self._add_random_tile()\n",
        "\n",
        "        max_tile = self._get_max_tile()\n",
        "\n",
        "        # reward shaping\n",
        "        if max_tile > self.prev_max_tile:\n",
        "            reward += 0.5\n",
        "        self.prev_max_tile = max_tile\n",
        "\n",
        "        reward += 0.01 * np.sum(self.board==0)\n",
        "        self.score += reward\n",
        "\n",
        "        terminated = (not self._can_move()) or (max_tile >= self.target_tile)\n",
        "        truncated = False\n",
        "\n",
        "        return self._get_obs(), reward, terminated, truncated, {\n",
        "            \"score\": self.score,\n",
        "            \"max_tile\": max_tile\n",
        "        }\n",
        "\n",
        "    def _board_to_string(self):\n",
        "        rows = []\n",
        "        for row in self.board:\n",
        "            r = []\n",
        "            for exp in row:\n",
        "                r.append(\".\" if exp==0 else str(2**exp))\n",
        "            rows.append(\"\\t\".join(r))\n",
        "        return \"\\n\".join(rows)\n"
      ],
      "metadata": {
        "id": "PSQhMFcB9osr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3 import PPO\n",
        "\n",
        "env_v2 = Game2048EnvV2()\n",
        "\n",
        "policy_kwargs_v2 = dict(\n",
        "    net_arch=[dict(pi=[256, 256, 256],\n",
        "                   vf=[256, 256, 256])]\n",
        ")\n",
        "\n",
        "model_v2 = PPO(\n",
        "    \"MlpPolicy\",\n",
        "    env_v2,\n",
        "    policy_kwargs=policy_kwargs_v2,\n",
        "    learning_rate=3e-4,\n",
        "    n_steps=2048,\n",
        "    batch_size=512,\n",
        "    n_epochs=10,\n",
        "    gamma=0.99,\n",
        "    clip_range=0.15,\n",
        "    ent_coef=0.05,      # üîº higher entropy ‚Üí more stochastic policy\n",
        "    target_kl=0.02,\n",
        "    verbose=1,\n",
        ")\n",
        "\n",
        "model_v2.learn(total_timesteps=300_000)\n",
        "\n",
        "model_v2.save(\"ppo_2048_v2_simple\")\n",
        "print(\"Saved model ppo_2048_v2_simple.zip\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v4IkIb7P9oap",
        "outputId": "9d62130c-1f51-4747-e8f3-3792e08c14fe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/stable_baselines3/common/policies.py:486: UserWarning: As shared layers in the mlp_extractor are removed since SB3 v1.8.0, you should now pass directly a dictionary and not a list (net_arch=dict(pi=..., vf=...) instead of net_arch=[dict(pi=..., vf=...)])\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "---------------------------------\n",
            "| rollout/           |          |\n",
            "|    ep_len_mean     | 149      |\n",
            "|    ep_rew_mean     | 1.16e+03 |\n",
            "| time/              |          |\n",
            "|    fps             | 608      |\n",
            "|    iterations      | 1        |\n",
            "|    time_elapsed    | 3        |\n",
            "|    total_timesteps | 2048     |\n",
            "---------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 147           |\n",
            "|    ep_rew_mean          | 1.13e+03      |\n",
            "| time/                   |               |\n",
            "|    fps                  | 592           |\n",
            "|    iterations           | 2             |\n",
            "|    time_elapsed         | 6             |\n",
            "|    total_timesteps      | 4096          |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00044112414 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.15          |\n",
            "|    entropy_loss         | -1.39         |\n",
            "|    explained_variance   | -5.89e-05     |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 8.36e+03      |\n",
            "|    n_updates            | 10            |\n",
            "|    policy_gradient_loss | -0.0014       |\n",
            "|    value_loss           | 1.84e+04      |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 147           |\n",
            "|    ep_rew_mean          | 1.14e+03      |\n",
            "| time/                   |               |\n",
            "|    fps                  | 585           |\n",
            "|    iterations           | 3             |\n",
            "|    time_elapsed         | 10            |\n",
            "|    total_timesteps      | 6144          |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 3.2115495e-06 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.15          |\n",
            "|    entropy_loss         | -1.39         |\n",
            "|    explained_variance   | 0.00256       |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 7.82e+03      |\n",
            "|    n_updates            | 20            |\n",
            "|    policy_gradient_loss | -3.96e-05     |\n",
            "|    value_loss           | 1.58e+04      |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 144           |\n",
            "|    ep_rew_mean          | 1.11e+03      |\n",
            "| time/                   |               |\n",
            "|    fps                  | 581           |\n",
            "|    iterations           | 4             |\n",
            "|    time_elapsed         | 14            |\n",
            "|    total_timesteps      | 8192          |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 4.9768918e-05 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.15          |\n",
            "|    entropy_loss         | -1.39         |\n",
            "|    explained_variance   | 0.00561       |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 9.32e+03      |\n",
            "|    n_updates            | 30            |\n",
            "|    policy_gradient_loss | -0.000338     |\n",
            "|    value_loss           | 1.95e+04      |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 145           |\n",
            "|    ep_rew_mean          | 1.12e+03      |\n",
            "| time/                   |               |\n",
            "|    fps                  | 579           |\n",
            "|    iterations           | 5             |\n",
            "|    time_elapsed         | 17            |\n",
            "|    total_timesteps      | 10240         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 1.9867352e-05 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.15          |\n",
            "|    entropy_loss         | -1.39         |\n",
            "|    explained_variance   | 0.00413       |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 8.49e+03      |\n",
            "|    n_updates            | 40            |\n",
            "|    policy_gradient_loss | -0.000162     |\n",
            "|    value_loss           | 1.67e+04      |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 144           |\n",
            "|    ep_rew_mean          | 1.08e+03      |\n",
            "| time/                   |               |\n",
            "|    fps                  | 578           |\n",
            "|    iterations           | 6             |\n",
            "|    time_elapsed         | 21            |\n",
            "|    total_timesteps      | 12288         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 2.1527376e-05 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.15          |\n",
            "|    entropy_loss         | -1.39         |\n",
            "|    explained_variance   | 0.00204       |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 8.06e+03      |\n",
            "|    n_updates            | 50            |\n",
            "|    policy_gradient_loss | -0.00019      |\n",
            "|    value_loss           | 1.61e+04      |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 147           |\n",
            "|    ep_rew_mean          | 1.12e+03      |\n",
            "| time/                   |               |\n",
            "|    fps                  | 577           |\n",
            "|    iterations           | 7             |\n",
            "|    time_elapsed         | 24            |\n",
            "|    total_timesteps      | 14336         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 4.5848778e-05 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.15          |\n",
            "|    entropy_loss         | -1.39         |\n",
            "|    explained_variance   | 0.00193       |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 5.77e+03      |\n",
            "|    n_updates            | 60            |\n",
            "|    policy_gradient_loss | -0.000263     |\n",
            "|    value_loss           | 1.28e+04      |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 146          |\n",
            "|    ep_rew_mean          | 1.11e+03     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 576          |\n",
            "|    iterations           | 8            |\n",
            "|    time_elapsed         | 28           |\n",
            "|    total_timesteps      | 16384        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 4.356829e-05 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.15         |\n",
            "|    entropy_loss         | -1.39        |\n",
            "|    explained_variance   | 0.000923     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 9.48e+03     |\n",
            "|    n_updates            | 70           |\n",
            "|    policy_gradient_loss | -0.000264    |\n",
            "|    value_loss           | 1.98e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 143          |\n",
            "|    ep_rew_mean          | 1.08e+03     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 575          |\n",
            "|    iterations           | 9            |\n",
            "|    time_elapsed         | 32           |\n",
            "|    total_timesteps      | 18432        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 1.819749e-05 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.15         |\n",
            "|    entropy_loss         | -1.39        |\n",
            "|    explained_variance   | 0.000839     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 8.75e+03     |\n",
            "|    n_updates            | 80           |\n",
            "|    policy_gradient_loss | -0.000117    |\n",
            "|    value_loss           | 1.69e+04     |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 143           |\n",
            "|    ep_rew_mean          | 1.07e+03      |\n",
            "| time/                   |               |\n",
            "|    fps                  | 575           |\n",
            "|    iterations           | 10            |\n",
            "|    time_elapsed         | 35            |\n",
            "|    total_timesteps      | 20480         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 7.5931603e-06 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.15          |\n",
            "|    entropy_loss         | -1.39         |\n",
            "|    explained_variance   | 0.000915      |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 8.21e+03      |\n",
            "|    n_updates            | 90            |\n",
            "|    policy_gradient_loss | -9.93e-05     |\n",
            "|    value_loss           | 1.56e+04      |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 140          |\n",
            "|    ep_rew_mean          | 1.03e+03     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 575          |\n",
            "|    iterations           | 11           |\n",
            "|    time_elapsed         | 39           |\n",
            "|    total_timesteps      | 22528        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 2.521809e-05 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.15         |\n",
            "|    entropy_loss         | -1.39        |\n",
            "|    explained_variance   | 0.000606     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 8.4e+03      |\n",
            "|    n_updates            | 100          |\n",
            "|    policy_gradient_loss | -0.000157    |\n",
            "|    value_loss           | 1.55e+04     |\n",
            "------------------------------------------\n",
            "--------------------------------------------\n",
            "| rollout/                |                |\n",
            "|    ep_len_mean          | 138            |\n",
            "|    ep_rew_mean          | 1.02e+03       |\n",
            "| time/                   |                |\n",
            "|    fps                  | 573            |\n",
            "|    iterations           | 12             |\n",
            "|    time_elapsed         | 42             |\n",
            "|    total_timesteps      | 24576          |\n",
            "| train/                  |                |\n",
            "|    approx_kl            | 1.11446425e-05 |\n",
            "|    clip_fraction        | 0              |\n",
            "|    clip_range           | 0.15           |\n",
            "|    entropy_loss         | -1.39          |\n",
            "|    explained_variance   | 0.000319       |\n",
            "|    learning_rate        | 0.0003         |\n",
            "|    loss                 | 6.62e+03       |\n",
            "|    n_updates            | 110            |\n",
            "|    policy_gradient_loss | -9.85e-05      |\n",
            "|    value_loss           | 1.3e+04        |\n",
            "--------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 139          |\n",
            "|    ep_rew_mean          | 1.04e+03     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 573          |\n",
            "|    iterations           | 13           |\n",
            "|    time_elapsed         | 46           |\n",
            "|    total_timesteps      | 26624        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 9.209325e-06 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.15         |\n",
            "|    entropy_loss         | -1.39        |\n",
            "|    explained_variance   | 0.000327     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.21e+03     |\n",
            "|    n_updates            | 120          |\n",
            "|    policy_gradient_loss | -7.77e-05    |\n",
            "|    value_loss           | 1.28e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 134          |\n",
            "|    ep_rew_mean          | 984          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 573          |\n",
            "|    iterations           | 14           |\n",
            "|    time_elapsed         | 50           |\n",
            "|    total_timesteps      | 28672        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 9.687318e-05 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.15         |\n",
            "|    entropy_loss         | -1.39        |\n",
            "|    explained_variance   | 0.000289     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 7.98e+03     |\n",
            "|    n_updates            | 130          |\n",
            "|    policy_gradient_loss | -0.000566    |\n",
            "|    value_loss           | 1.71e+04     |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 134           |\n",
            "|    ep_rew_mean          | 976           |\n",
            "| time/                   |               |\n",
            "|    fps                  | 572           |\n",
            "|    iterations           | 15            |\n",
            "|    time_elapsed         | 53            |\n",
            "|    total_timesteps      | 30720         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 4.5635912e-05 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.15          |\n",
            "|    entropy_loss         | -1.39         |\n",
            "|    explained_variance   | 0.000194      |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 6.91e+03      |\n",
            "|    n_updates            | 140           |\n",
            "|    policy_gradient_loss | -0.000198     |\n",
            "|    value_loss           | 1.4e+04       |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 134          |\n",
            "|    ep_rew_mean          | 985          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 572          |\n",
            "|    iterations           | 16           |\n",
            "|    time_elapsed         | 57           |\n",
            "|    total_timesteps      | 32768        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 1.338881e-05 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.15         |\n",
            "|    entropy_loss         | -1.39        |\n",
            "|    explained_variance   | 0.000171     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.48e+03     |\n",
            "|    n_updates            | 150          |\n",
            "|    policy_gradient_loss | -0.00011     |\n",
            "|    value_loss           | 1.38e+04     |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 135           |\n",
            "|    ep_rew_mean          | 1e+03         |\n",
            "| time/                   |               |\n",
            "|    fps                  | 572           |\n",
            "|    iterations           | 17            |\n",
            "|    time_elapsed         | 60            |\n",
            "|    total_timesteps      | 34816         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 1.6000064e-05 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.15          |\n",
            "|    entropy_loss         | -1.39         |\n",
            "|    explained_variance   | 0.00017       |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 8.93e+03      |\n",
            "|    n_updates            | 160           |\n",
            "|    policy_gradient_loss | -0.000128     |\n",
            "|    value_loss           | 1.72e+04      |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 134           |\n",
            "|    ep_rew_mean          | 995           |\n",
            "| time/                   |               |\n",
            "|    fps                  | 572           |\n",
            "|    iterations           | 18            |\n",
            "|    time_elapsed         | 64            |\n",
            "|    total_timesteps      | 36864         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 4.5501103e-05 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.15          |\n",
            "|    entropy_loss         | -1.39         |\n",
            "|    explained_variance   | 0.000157      |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 7.38e+03      |\n",
            "|    n_updates            | 170           |\n",
            "|    policy_gradient_loss | -0.000292     |\n",
            "|    value_loss           | 1.57e+04      |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 131           |\n",
            "|    ep_rew_mean          | 962           |\n",
            "| time/                   |               |\n",
            "|    fps                  | 572           |\n",
            "|    iterations           | 19            |\n",
            "|    time_elapsed         | 67            |\n",
            "|    total_timesteps      | 38912         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 3.0287949e-05 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.15          |\n",
            "|    entropy_loss         | -1.39         |\n",
            "|    explained_variance   | 0.000124      |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 7.26e+03      |\n",
            "|    n_updates            | 180           |\n",
            "|    policy_gradient_loss | -0.000168     |\n",
            "|    value_loss           | 1.38e+04      |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 131           |\n",
            "|    ep_rew_mean          | 968           |\n",
            "| time/                   |               |\n",
            "|    fps                  | 572           |\n",
            "|    iterations           | 20            |\n",
            "|    time_elapsed         | 71            |\n",
            "|    total_timesteps      | 40960         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 1.8174236e-05 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.15          |\n",
            "|    entropy_loss         | -1.39         |\n",
            "|    explained_variance   | 9.14e-05      |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 5.1e+03       |\n",
            "|    n_updates            | 190           |\n",
            "|    policy_gradient_loss | -0.000134     |\n",
            "|    value_loss           | 1.12e+04      |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 132           |\n",
            "|    ep_rew_mean          | 996           |\n",
            "| time/                   |               |\n",
            "|    fps                  | 572           |\n",
            "|    iterations           | 21            |\n",
            "|    time_elapsed         | 75            |\n",
            "|    total_timesteps      | 43008         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 3.9021077e-05 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.15          |\n",
            "|    entropy_loss         | -1.39         |\n",
            "|    explained_variance   | 9.02e-05      |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 8.07e+03      |\n",
            "|    n_updates            | 200           |\n",
            "|    policy_gradient_loss | -0.000224     |\n",
            "|    value_loss           | 1.6e+04       |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 135         |\n",
            "|    ep_rew_mean          | 1.03e+03    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 572         |\n",
            "|    iterations           | 22          |\n",
            "|    time_elapsed         | 78          |\n",
            "|    total_timesteps      | 45056       |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 6.42488e-05 |\n",
            "|    clip_fraction        | 0           |\n",
            "|    clip_range           | 0.15        |\n",
            "|    entropy_loss         | -1.39       |\n",
            "|    explained_variance   | 0.000101    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 8.03e+03    |\n",
            "|    n_updates            | 210         |\n",
            "|    policy_gradient_loss | -0.000364   |\n",
            "|    value_loss           | 1.72e+04    |\n",
            "-----------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 135           |\n",
            "|    ep_rew_mean          | 1.01e+03      |\n",
            "| time/                   |               |\n",
            "|    fps                  | 571           |\n",
            "|    iterations           | 23            |\n",
            "|    time_elapsed         | 82            |\n",
            "|    total_timesteps      | 47104         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 3.7040765e-05 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.15          |\n",
            "|    entropy_loss         | -1.39         |\n",
            "|    explained_variance   | 8.06e-05      |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 7.59e+03      |\n",
            "|    n_updates            | 220           |\n",
            "|    policy_gradient_loss | -0.00021      |\n",
            "|    value_loss           | 1.6e+04       |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 133           |\n",
            "|    ep_rew_mean          | 988           |\n",
            "| time/                   |               |\n",
            "|    fps                  | 571           |\n",
            "|    iterations           | 24            |\n",
            "|    time_elapsed         | 85            |\n",
            "|    total_timesteps      | 49152         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 1.4638645e-05 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.15          |\n",
            "|    entropy_loss         | -1.39         |\n",
            "|    explained_variance   | 8.49e-05      |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 7.1e+03       |\n",
            "|    n_updates            | 230           |\n",
            "|    policy_gradient_loss | -0.000109     |\n",
            "|    value_loss           | 1.36e+04      |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 138          |\n",
            "|    ep_rew_mean          | 1.03e+03     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 571          |\n",
            "|    iterations           | 25           |\n",
            "|    time_elapsed         | 89           |\n",
            "|    total_timesteps      | 51200        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 1.540652e-05 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.15         |\n",
            "|    entropy_loss         | -1.39        |\n",
            "|    explained_variance   | 7.9e-05      |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 7.01e+03     |\n",
            "|    n_updates            | 240          |\n",
            "|    policy_gradient_loss | -0.000123    |\n",
            "|    value_loss           | 1.48e+04     |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 141           |\n",
            "|    ep_rew_mean          | 1.06e+03      |\n",
            "| time/                   |               |\n",
            "|    fps                  | 571           |\n",
            "|    iterations           | 26            |\n",
            "|    time_elapsed         | 93            |\n",
            "|    total_timesteps      | 53248         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 1.8145452e-05 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.15          |\n",
            "|    entropy_loss         | -1.39         |\n",
            "|    explained_variance   | 4.94e-05      |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 7.26e+03      |\n",
            "|    n_updates            | 250           |\n",
            "|    policy_gradient_loss | -0.000134     |\n",
            "|    value_loss           | 1.36e+04      |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 142           |\n",
            "|    ep_rew_mean          | 1.08e+03      |\n",
            "| time/                   |               |\n",
            "|    fps                  | 571           |\n",
            "|    iterations           | 27            |\n",
            "|    time_elapsed         | 96            |\n",
            "|    total_timesteps      | 55296         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 3.8019556e-05 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.15          |\n",
            "|    entropy_loss         | -1.39         |\n",
            "|    explained_variance   | 4.88e-05      |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 6.4e+03       |\n",
            "|    n_updates            | 260           |\n",
            "|    policy_gradient_loss | -0.000221     |\n",
            "|    value_loss           | 1.25e+04      |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 141           |\n",
            "|    ep_rew_mean          | 1.07e+03      |\n",
            "| time/                   |               |\n",
            "|    fps                  | 571           |\n",
            "|    iterations           | 28            |\n",
            "|    time_elapsed         | 100           |\n",
            "|    total_timesteps      | 57344         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 1.5230675e-05 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.15          |\n",
            "|    entropy_loss         | -1.39         |\n",
            "|    explained_variance   | 7.96e-05      |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 7.61e+03      |\n",
            "|    n_updates            | 270           |\n",
            "|    policy_gradient_loss | -0.000108     |\n",
            "|    value_loss           | 1.48e+04      |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 137           |\n",
            "|    ep_rew_mean          | 1.03e+03      |\n",
            "| time/                   |               |\n",
            "|    fps                  | 571           |\n",
            "|    iterations           | 29            |\n",
            "|    time_elapsed         | 103           |\n",
            "|    total_timesteps      | 59392         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 4.3969136e-05 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.15          |\n",
            "|    entropy_loss         | -1.39         |\n",
            "|    explained_variance   | 5.47e-05      |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 6.18e+03      |\n",
            "|    n_updates            | 280           |\n",
            "|    policy_gradient_loss | -0.000243     |\n",
            "|    value_loss           | 1.36e+04      |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 138           |\n",
            "|    ep_rew_mean          | 1.04e+03      |\n",
            "| time/                   |               |\n",
            "|    fps                  | 571           |\n",
            "|    iterations           | 30            |\n",
            "|    time_elapsed         | 107           |\n",
            "|    total_timesteps      | 61440         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 2.5437272e-05 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.15          |\n",
            "|    entropy_loss         | -1.39         |\n",
            "|    explained_variance   | 6.15e-05      |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 5.12e+03      |\n",
            "|    n_updates            | 290           |\n",
            "|    policy_gradient_loss | -0.000147     |\n",
            "|    value_loss           | 1.15e+04      |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 139           |\n",
            "|    ep_rew_mean          | 1.04e+03      |\n",
            "| time/                   |               |\n",
            "|    fps                  | 571           |\n",
            "|    iterations           | 31            |\n",
            "|    time_elapsed         | 111           |\n",
            "|    total_timesteps      | 63488         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00010038057 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.15          |\n",
            "|    entropy_loss         | -1.39         |\n",
            "|    explained_variance   | 3e-05         |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 5.92e+03      |\n",
            "|    n_updates            | 300           |\n",
            "|    policy_gradient_loss | -0.000478     |\n",
            "|    value_loss           | 1.29e+04      |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 135          |\n",
            "|    ep_rew_mean          | 1.02e+03     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 571          |\n",
            "|    iterations           | 32           |\n",
            "|    time_elapsed         | 114          |\n",
            "|    total_timesteps      | 65536        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 6.966802e-05 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.15         |\n",
            "|    entropy_loss         | -1.39        |\n",
            "|    explained_variance   | 3.43e-05     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.37e+03     |\n",
            "|    n_updates            | 310          |\n",
            "|    policy_gradient_loss | -0.000343    |\n",
            "|    value_loss           | 1.38e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 137          |\n",
            "|    ep_rew_mean          | 1.04e+03     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 571          |\n",
            "|    iterations           | 33           |\n",
            "|    time_elapsed         | 118          |\n",
            "|    total_timesteps      | 67584        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 5.824372e-05 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.15         |\n",
            "|    entropy_loss         | -1.39        |\n",
            "|    explained_variance   | 4.41e-05     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 8.32e+03     |\n",
            "|    n_updates            | 320          |\n",
            "|    policy_gradient_loss | -0.000293    |\n",
            "|    value_loss           | 1.62e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 137          |\n",
            "|    ep_rew_mean          | 1.04e+03     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 571          |\n",
            "|    iterations           | 34           |\n",
            "|    time_elapsed         | 121          |\n",
            "|    total_timesteps      | 69632        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 3.790841e-05 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.15         |\n",
            "|    entropy_loss         | -1.39        |\n",
            "|    explained_variance   | 3.74e-05     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 7e+03        |\n",
            "|    n_updates            | 330          |\n",
            "|    policy_gradient_loss | -0.000207    |\n",
            "|    value_loss           | 1.38e+04     |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 139           |\n",
            "|    ep_rew_mean          | 1.07e+03      |\n",
            "| time/                   |               |\n",
            "|    fps                  | 571           |\n",
            "|    iterations           | 35            |\n",
            "|    time_elapsed         | 125           |\n",
            "|    total_timesteps      | 71680         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 5.0959556e-05 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.15          |\n",
            "|    entropy_loss         | -1.39         |\n",
            "|    explained_variance   | 2.73e-05      |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 8.77e+03      |\n",
            "|    n_updates            | 340           |\n",
            "|    policy_gradient_loss | -0.000236     |\n",
            "|    value_loss           | 1.57e+04      |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 143          |\n",
            "|    ep_rew_mean          | 1.11e+03     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 571          |\n",
            "|    iterations           | 36           |\n",
            "|    time_elapsed         | 129          |\n",
            "|    total_timesteps      | 73728        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 6.246532e-05 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.15         |\n",
            "|    entropy_loss         | -1.39        |\n",
            "|    explained_variance   | 3.15e-05     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 8.37e+03     |\n",
            "|    n_updates            | 350          |\n",
            "|    policy_gradient_loss | -0.000316    |\n",
            "|    value_loss           | 1.56e+04     |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 143           |\n",
            "|    ep_rew_mean          | 1.1e+03       |\n",
            "| time/                   |               |\n",
            "|    fps                  | 571           |\n",
            "|    iterations           | 37            |\n",
            "|    time_elapsed         | 132           |\n",
            "|    total_timesteps      | 75776         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 4.1424297e-05 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.15          |\n",
            "|    entropy_loss         | -1.39         |\n",
            "|    explained_variance   | 3.9e-05       |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 6.37e+03      |\n",
            "|    n_updates            | 360           |\n",
            "|    policy_gradient_loss | -0.000241     |\n",
            "|    value_loss           | 1.22e+04      |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 143          |\n",
            "|    ep_rew_mean          | 1.1e+03      |\n",
            "| time/                   |              |\n",
            "|    fps                  | 571          |\n",
            "|    iterations           | 38           |\n",
            "|    time_elapsed         | 136          |\n",
            "|    total_timesteps      | 77824        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 7.712067e-05 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.15         |\n",
            "|    entropy_loss         | -1.39        |\n",
            "|    explained_variance   | 8.64e-06     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.29e+03     |\n",
            "|    n_updates            | 370          |\n",
            "|    policy_gradient_loss | -0.000342    |\n",
            "|    value_loss           | 1.02e+04     |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 144           |\n",
            "|    ep_rew_mean          | 1.1e+03       |\n",
            "| time/                   |               |\n",
            "|    fps                  | 571           |\n",
            "|    iterations           | 39            |\n",
            "|    time_elapsed         | 139           |\n",
            "|    total_timesteps      | 79872         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 2.5120302e-05 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.15          |\n",
            "|    entropy_loss         | -1.39         |\n",
            "|    explained_variance   | 1.79e-05      |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 5.39e+03      |\n",
            "|    n_updates            | 380           |\n",
            "|    policy_gradient_loss | -0.000105     |\n",
            "|    value_loss           | 1.22e+04      |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 143           |\n",
            "|    ep_rew_mean          | 1.09e+03      |\n",
            "| time/                   |               |\n",
            "|    fps                  | 571           |\n",
            "|    iterations           | 40            |\n",
            "|    time_elapsed         | 143           |\n",
            "|    total_timesteps      | 81920         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 2.8877199e-05 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.15          |\n",
            "|    entropy_loss         | -1.39         |\n",
            "|    explained_variance   | 3.22e-05      |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 7.61e+03      |\n",
            "|    n_updates            | 390           |\n",
            "|    policy_gradient_loss | -0.000187     |\n",
            "|    value_loss           | 1.56e+04      |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 143          |\n",
            "|    ep_rew_mean          | 1.09e+03     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 571          |\n",
            "|    iterations           | 41           |\n",
            "|    time_elapsed         | 146          |\n",
            "|    total_timesteps      | 83968        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 4.071067e-05 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.15         |\n",
            "|    entropy_loss         | -1.39        |\n",
            "|    explained_variance   | 2.25e-05     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.37e+03     |\n",
            "|    n_updates            | 400          |\n",
            "|    policy_gradient_loss | -0.00023     |\n",
            "|    value_loss           | 1.28e+04     |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 143           |\n",
            "|    ep_rew_mean          | 1.09e+03      |\n",
            "| time/                   |               |\n",
            "|    fps                  | 571           |\n",
            "|    iterations           | 42            |\n",
            "|    time_elapsed         | 150           |\n",
            "|    total_timesteps      | 86016         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00010959321 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.15          |\n",
            "|    entropy_loss         | -1.39         |\n",
            "|    explained_variance   | 2.55e-05      |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 7.87e+03      |\n",
            "|    n_updates            | 410           |\n",
            "|    policy_gradient_loss | -0.000549     |\n",
            "|    value_loss           | 1.68e+04      |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 140           |\n",
            "|    ep_rew_mean          | 1.06e+03      |\n",
            "| time/                   |               |\n",
            "|    fps                  | 571           |\n",
            "|    iterations           | 43            |\n",
            "|    time_elapsed         | 154           |\n",
            "|    total_timesteps      | 88064         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00013863557 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.15          |\n",
            "|    entropy_loss         | -1.39         |\n",
            "|    explained_variance   | 1.44e-05      |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 5.86e+03      |\n",
            "|    n_updates            | 420           |\n",
            "|    policy_gradient_loss | -0.000567     |\n",
            "|    value_loss           | 1.24e+04      |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 139          |\n",
            "|    ep_rew_mean          | 1.06e+03     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 571          |\n",
            "|    iterations           | 44           |\n",
            "|    time_elapsed         | 157          |\n",
            "|    total_timesteps      | 90112        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 5.424142e-05 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.15         |\n",
            "|    entropy_loss         | -1.39        |\n",
            "|    explained_variance   | 1.14e-05     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.63e+03     |\n",
            "|    n_updates            | 430          |\n",
            "|    policy_gradient_loss | -0.000241    |\n",
            "|    value_loss           | 1.23e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 135          |\n",
            "|    ep_rew_mean          | 1.01e+03     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 571          |\n",
            "|    iterations           | 45           |\n",
            "|    time_elapsed         | 161          |\n",
            "|    total_timesteps      | 92160        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 4.812106e-05 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.15         |\n",
            "|    entropy_loss         | -1.39        |\n",
            "|    explained_variance   | 5.54e-06     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.03e+03     |\n",
            "|    n_updates            | 440          |\n",
            "|    policy_gradient_loss | -0.000259    |\n",
            "|    value_loss           | 1.01e+04     |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 136           |\n",
            "|    ep_rew_mean          | 1.02e+03      |\n",
            "| time/                   |               |\n",
            "|    fps                  | 571           |\n",
            "|    iterations           | 46            |\n",
            "|    time_elapsed         | 164           |\n",
            "|    total_timesteps      | 94208         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 3.4306548e-05 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.15          |\n",
            "|    entropy_loss         | -1.39         |\n",
            "|    explained_variance   | 8.4e-06       |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 4.71e+03      |\n",
            "|    n_updates            | 450           |\n",
            "|    policy_gradient_loss | -0.000161     |\n",
            "|    value_loss           | 9.76e+03      |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 135           |\n",
            "|    ep_rew_mean          | 1.01e+03      |\n",
            "| time/                   |               |\n",
            "|    fps                  | 571           |\n",
            "|    iterations           | 47            |\n",
            "|    time_elapsed         | 168           |\n",
            "|    total_timesteps      | 96256         |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 3.4429075e-05 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.15          |\n",
            "|    entropy_loss         | -1.39         |\n",
            "|    explained_variance   | 1.29e-05      |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 6.65e+03      |\n",
            "|    n_updates            | 460           |\n",
            "|    policy_gradient_loss | -0.000197     |\n",
            "|    value_loss           | 1.36e+04      |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 135          |\n",
            "|    ep_rew_mean          | 1.01e+03     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 571          |\n",
            "|    iterations           | 48           |\n",
            "|    time_elapsed         | 172          |\n",
            "|    total_timesteps      | 98304        |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 2.989429e-05 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.15         |\n",
            "|    entropy_loss         | -1.39        |\n",
            "|    explained_variance   | 1.55e-05     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.28e+03     |\n",
            "|    n_updates            | 470          |\n",
            "|    policy_gradient_loss | -0.000177    |\n",
            "|    value_loss           | 1.26e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 136          |\n",
            "|    ep_rew_mean          | 1e+03        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 571          |\n",
            "|    iterations           | 49           |\n",
            "|    time_elapsed         | 175          |\n",
            "|    total_timesteps      | 100352       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 7.729948e-06 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.15         |\n",
            "|    entropy_loss         | -1.39        |\n",
            "|    explained_variance   | 1.12e-05     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6e+03        |\n",
            "|    n_updates            | 480          |\n",
            "|    policy_gradient_loss | -7.96e-05    |\n",
            "|    value_loss           | 1.31e+04     |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 136           |\n",
            "|    ep_rew_mean          | 1.01e+03      |\n",
            "| time/                   |               |\n",
            "|    fps                  | 571           |\n",
            "|    iterations           | 50            |\n",
            "|    time_elapsed         | 179           |\n",
            "|    total_timesteps      | 102400        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00016349673 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.15          |\n",
            "|    entropy_loss         | -1.39         |\n",
            "|    explained_variance   | 1.04e-05      |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 6.34e+03      |\n",
            "|    n_updates            | 490           |\n",
            "|    policy_gradient_loss | -0.000645     |\n",
            "|    value_loss           | 1.18e+04      |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 137           |\n",
            "|    ep_rew_mean          | 1.03e+03      |\n",
            "| time/                   |               |\n",
            "|    fps                  | 571           |\n",
            "|    iterations           | 51            |\n",
            "|    time_elapsed         | 182           |\n",
            "|    total_timesteps      | 104448        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 1.9565574e-05 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.15          |\n",
            "|    entropy_loss         | -1.39         |\n",
            "|    explained_variance   | 9.3e-06       |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 6.12e+03      |\n",
            "|    n_updates            | 500           |\n",
            "|    policy_gradient_loss | -8.82e-05     |\n",
            "|    value_loss           | 1.17e+04      |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 139           |\n",
            "|    ep_rew_mean          | 1.04e+03      |\n",
            "| time/                   |               |\n",
            "|    fps                  | 571           |\n",
            "|    iterations           | 52            |\n",
            "|    time_elapsed         | 186           |\n",
            "|    total_timesteps      | 106496        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 2.5834714e-05 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.15          |\n",
            "|    entropy_loss         | -1.39         |\n",
            "|    explained_variance   | 8.23e-06      |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 5.26e+03      |\n",
            "|    n_updates            | 510           |\n",
            "|    policy_gradient_loss | -0.000136     |\n",
            "|    value_loss           | 1.05e+04      |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 138           |\n",
            "|    ep_rew_mean          | 1.03e+03      |\n",
            "| time/                   |               |\n",
            "|    fps                  | 571           |\n",
            "|    iterations           | 53            |\n",
            "|    time_elapsed         | 189           |\n",
            "|    total_timesteps      | 108544        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00020912514 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.15          |\n",
            "|    entropy_loss         | -1.39         |\n",
            "|    explained_variance   | 5.48e-06      |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 5.43e+03      |\n",
            "|    n_updates            | 520           |\n",
            "|    policy_gradient_loss | -0.000756     |\n",
            "|    value_loss           | 1.04e+04      |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 137          |\n",
            "|    ep_rew_mean          | 1.01e+03     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 571          |\n",
            "|    iterations           | 54           |\n",
            "|    time_elapsed         | 193          |\n",
            "|    total_timesteps      | 110592       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 9.784658e-05 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.15         |\n",
            "|    entropy_loss         | -1.39        |\n",
            "|    explained_variance   | 7.75e-06     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.69e+03     |\n",
            "|    n_updates            | 530          |\n",
            "|    policy_gradient_loss | -0.000373    |\n",
            "|    value_loss           | 1.35e+04     |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 136           |\n",
            "|    ep_rew_mean          | 997           |\n",
            "| time/                   |               |\n",
            "|    fps                  | 571           |\n",
            "|    iterations           | 55            |\n",
            "|    time_elapsed         | 197           |\n",
            "|    total_timesteps      | 112640        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00015890066 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.15          |\n",
            "|    entropy_loss         | -1.39         |\n",
            "|    explained_variance   | 8.88e-06      |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 6e+03         |\n",
            "|    n_updates            | 540           |\n",
            "|    policy_gradient_loss | -0.000588     |\n",
            "|    value_loss           | 1.2e+04       |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 135          |\n",
            "|    ep_rew_mean          | 981          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 571          |\n",
            "|    iterations           | 56           |\n",
            "|    time_elapsed         | 200          |\n",
            "|    total_timesteps      | 114688       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0001807391 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.15         |\n",
            "|    entropy_loss         | -1.39        |\n",
            "|    explained_variance   | 4.05e-06     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.36e+03     |\n",
            "|    n_updates            | 550          |\n",
            "|    policy_gradient_loss | -0.000562    |\n",
            "|    value_loss           | 1.07e+04     |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 138           |\n",
            "|    ep_rew_mean          | 1.02e+03      |\n",
            "| time/                   |               |\n",
            "|    fps                  | 571           |\n",
            "|    iterations           | 57            |\n",
            "|    time_elapsed         | 204           |\n",
            "|    total_timesteps      | 116736        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00015381968 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.15          |\n",
            "|    entropy_loss         | -1.39         |\n",
            "|    explained_variance   | 4.23e-06      |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 5.45e+03      |\n",
            "|    n_updates            | 560           |\n",
            "|    policy_gradient_loss | -0.000532     |\n",
            "|    value_loss           | 1.08e+04      |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 139          |\n",
            "|    ep_rew_mean          | 1.03e+03     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 571          |\n",
            "|    iterations           | 58           |\n",
            "|    time_elapsed         | 207          |\n",
            "|    total_timesteps      | 118784       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 7.450124e-05 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.15         |\n",
            "|    entropy_loss         | -1.39        |\n",
            "|    explained_variance   | 7.45e-06     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.5e+03      |\n",
            "|    n_updates            | 570          |\n",
            "|    policy_gradient_loss | -0.000258    |\n",
            "|    value_loss           | 1.35e+04     |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 139           |\n",
            "|    ep_rew_mean          | 1.04e+03      |\n",
            "| time/                   |               |\n",
            "|    fps                  | 571           |\n",
            "|    iterations           | 59            |\n",
            "|    time_elapsed         | 211           |\n",
            "|    total_timesteps      | 120832        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 5.3437194e-05 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.15          |\n",
            "|    entropy_loss         | -1.39         |\n",
            "|    explained_variance   | 6.26e-06      |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 5.82e+03      |\n",
            "|    n_updates            | 580           |\n",
            "|    policy_gradient_loss | -0.000237     |\n",
            "|    value_loss           | 1.15e+04      |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 134           |\n",
            "|    ep_rew_mean          | 983           |\n",
            "| time/                   |               |\n",
            "|    fps                  | 571           |\n",
            "|    iterations           | 60            |\n",
            "|    time_elapsed         | 215           |\n",
            "|    total_timesteps      | 122880        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00016943036 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.15          |\n",
            "|    entropy_loss         | -1.39         |\n",
            "|    explained_variance   | 4.89e-06      |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 5.24e+03      |\n",
            "|    n_updates            | 590           |\n",
            "|    policy_gradient_loss | -0.000612     |\n",
            "|    value_loss           | 1.16e+04      |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 132           |\n",
            "|    ep_rew_mean          | 967           |\n",
            "| time/                   |               |\n",
            "|    fps                  | 571           |\n",
            "|    iterations           | 61            |\n",
            "|    time_elapsed         | 218           |\n",
            "|    total_timesteps      | 124928        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00015558756 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.15          |\n",
            "|    entropy_loss         | -1.39         |\n",
            "|    explained_variance   | -5.96e-07     |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 4.52e+03      |\n",
            "|    n_updates            | 600           |\n",
            "|    policy_gradient_loss | -0.000465     |\n",
            "|    value_loss           | 9.72e+03      |\n",
            "-------------------------------------------\n",
            "--------------------------------------------\n",
            "| rollout/                |                |\n",
            "|    ep_len_mean          | 136            |\n",
            "|    ep_rew_mean          | 1.01e+03       |\n",
            "| time/                   |                |\n",
            "|    fps                  | 571            |\n",
            "|    iterations           | 62             |\n",
            "|    time_elapsed         | 222            |\n",
            "|    total_timesteps      | 126976         |\n",
            "| train/                  |                |\n",
            "|    approx_kl            | 0.000110119436 |\n",
            "|    clip_fraction        | 0              |\n",
            "|    clip_range           | 0.15           |\n",
            "|    entropy_loss         | -1.39          |\n",
            "|    explained_variance   | 5.72e-06       |\n",
            "|    learning_rate        | 0.0003         |\n",
            "|    loss                 | 5.71e+03       |\n",
            "|    n_updates            | 610            |\n",
            "|    policy_gradient_loss | -0.000352      |\n",
            "|    value_loss           | 1.06e+04       |\n",
            "--------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 139           |\n",
            "|    ep_rew_mean          | 1.05e+03      |\n",
            "| time/                   |               |\n",
            "|    fps                  | 571           |\n",
            "|    iterations           | 63            |\n",
            "|    time_elapsed         | 225           |\n",
            "|    total_timesteps      | 129024        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00012997576 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.15          |\n",
            "|    entropy_loss         | -1.39         |\n",
            "|    explained_variance   | 5.54e-06      |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 7.35e+03      |\n",
            "|    n_updates            | 620           |\n",
            "|    policy_gradient_loss | -0.000465     |\n",
            "|    value_loss           | 1.48e+04      |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 142          |\n",
            "|    ep_rew_mean          | 1.09e+03     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 571          |\n",
            "|    iterations           | 64           |\n",
            "|    time_elapsed         | 229          |\n",
            "|    total_timesteps      | 131072       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0001223839 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.15         |\n",
            "|    entropy_loss         | -1.39        |\n",
            "|    explained_variance   | 5.36e-06     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.97e+03     |\n",
            "|    n_updates            | 630          |\n",
            "|    policy_gradient_loss | -0.000468    |\n",
            "|    value_loss           | 1.35e+04     |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 145           |\n",
            "|    ep_rew_mean          | 1.13e+03      |\n",
            "| time/                   |               |\n",
            "|    fps                  | 571           |\n",
            "|    iterations           | 65            |\n",
            "|    time_elapsed         | 232           |\n",
            "|    total_timesteps      | 133120        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 8.1433565e-05 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.15          |\n",
            "|    entropy_loss         | -1.39         |\n",
            "|    explained_variance   | 7.45e-06      |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 8.29e+03      |\n",
            "|    n_updates            | 640           |\n",
            "|    policy_gradient_loss | -0.000346     |\n",
            "|    value_loss           | 1.7e+04       |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 149           |\n",
            "|    ep_rew_mean          | 1.17e+03      |\n",
            "| time/                   |               |\n",
            "|    fps                  | 571           |\n",
            "|    iterations           | 66            |\n",
            "|    time_elapsed         | 236           |\n",
            "|    total_timesteps      | 135168        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 2.3070956e-05 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.15          |\n",
            "|    entropy_loss         | -1.39         |\n",
            "|    explained_variance   | 7.15e-06      |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 7.64e+03      |\n",
            "|    n_updates            | 650           |\n",
            "|    policy_gradient_loss | -0.000138     |\n",
            "|    value_loss           | 1.43e+04      |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 148           |\n",
            "|    ep_rew_mean          | 1.16e+03      |\n",
            "| time/                   |               |\n",
            "|    fps                  | 571           |\n",
            "|    iterations           | 67            |\n",
            "|    time_elapsed         | 240           |\n",
            "|    total_timesteps      | 137216        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00013266032 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.15          |\n",
            "|    entropy_loss         | -1.39         |\n",
            "|    explained_variance   | 5.13e-06      |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 5.95e+03      |\n",
            "|    n_updates            | 660           |\n",
            "|    policy_gradient_loss | -0.000421     |\n",
            "|    value_loss           | 1.27e+04      |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 145           |\n",
            "|    ep_rew_mean          | 1.14e+03      |\n",
            "| time/                   |               |\n",
            "|    fps                  | 571           |\n",
            "|    iterations           | 68            |\n",
            "|    time_elapsed         | 243           |\n",
            "|    total_timesteps      | 139264        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00014120634 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.15          |\n",
            "|    entropy_loss         | -1.39         |\n",
            "|    explained_variance   | 2.92e-06      |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 5.9e+03       |\n",
            "|    n_updates            | 670           |\n",
            "|    policy_gradient_loss | -0.00051      |\n",
            "|    value_loss           | 1.19e+04      |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 147          |\n",
            "|    ep_rew_mean          | 1.16e+03     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 571          |\n",
            "|    iterations           | 69           |\n",
            "|    time_elapsed         | 247          |\n",
            "|    total_timesteps      | 141312       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 5.199999e-05 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.15         |\n",
            "|    entropy_loss         | -1.39        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.65e+03     |\n",
            "|    n_updates            | 680          |\n",
            "|    policy_gradient_loss | -0.000244    |\n",
            "|    value_loss           | 9.09e+03     |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 147           |\n",
            "|    ep_rew_mean          | 1.16e+03      |\n",
            "| time/                   |               |\n",
            "|    fps                  | 571           |\n",
            "|    iterations           | 70            |\n",
            "|    time_elapsed         | 250           |\n",
            "|    total_timesteps      | 143360        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 5.3379103e-05 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.15          |\n",
            "|    entropy_loss         | -1.39         |\n",
            "|    explained_variance   | 6.02e-06      |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 8.6e+03       |\n",
            "|    n_updates            | 690           |\n",
            "|    policy_gradient_loss | -0.00023      |\n",
            "|    value_loss           | 1.63e+04      |\n",
            "-------------------------------------------\n",
            "--------------------------------------------\n",
            "| rollout/                |                |\n",
            "|    ep_len_mean          | 139            |\n",
            "|    ep_rew_mean          | 1.06e+03       |\n",
            "| time/                   |                |\n",
            "|    fps                  | 571            |\n",
            "|    iterations           | 71             |\n",
            "|    time_elapsed         | 254            |\n",
            "|    total_timesteps      | 145408         |\n",
            "| train/                  |                |\n",
            "|    approx_kl            | 0.000117861404 |\n",
            "|    clip_fraction        | 0              |\n",
            "|    clip_range           | 0.15           |\n",
            "|    entropy_loss         | -1.39          |\n",
            "|    explained_variance   | 4.59e-06       |\n",
            "|    learning_rate        | 0.0003         |\n",
            "|    loss                 | 7.36e+03       |\n",
            "|    n_updates            | 700            |\n",
            "|    policy_gradient_loss | -0.000423      |\n",
            "|    value_loss           | 1.39e+04       |\n",
            "--------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 138          |\n",
            "|    ep_rew_mean          | 1.06e+03     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 571          |\n",
            "|    iterations           | 72           |\n",
            "|    time_elapsed         | 258          |\n",
            "|    total_timesteps      | 147456       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 5.076098e-05 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.15         |\n",
            "|    entropy_loss         | -1.39        |\n",
            "|    explained_variance   | 2.8e-06      |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.16e+03     |\n",
            "|    n_updates            | 710          |\n",
            "|    policy_gradient_loss | -0.000239    |\n",
            "|    value_loss           | 1.17e+04     |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 137           |\n",
            "|    ep_rew_mean          | 1.05e+03      |\n",
            "| time/                   |               |\n",
            "|    fps                  | 571           |\n",
            "|    iterations           | 73            |\n",
            "|    time_elapsed         | 261           |\n",
            "|    total_timesteps      | 149504        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 5.1550276e-05 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.15          |\n",
            "|    entropy_loss         | -1.38         |\n",
            "|    explained_variance   | 3.7e-06       |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 7.7e+03       |\n",
            "|    n_updates            | 720           |\n",
            "|    policy_gradient_loss | -0.000262     |\n",
            "|    value_loss           | 1.38e+04      |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 138           |\n",
            "|    ep_rew_mean          | 1.06e+03      |\n",
            "| time/                   |               |\n",
            "|    fps                  | 571           |\n",
            "|    iterations           | 74            |\n",
            "|    time_elapsed         | 265           |\n",
            "|    total_timesteps      | 151552        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00023746118 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.15          |\n",
            "|    entropy_loss         | -1.38         |\n",
            "|    explained_variance   | 1.37e-06      |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 5.43e+03      |\n",
            "|    n_updates            | 730           |\n",
            "|    policy_gradient_loss | -0.000756     |\n",
            "|    value_loss           | 1.08e+04      |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 138           |\n",
            "|    ep_rew_mean          | 1.06e+03      |\n",
            "| time/                   |               |\n",
            "|    fps                  | 571           |\n",
            "|    iterations           | 75            |\n",
            "|    time_elapsed         | 268           |\n",
            "|    total_timesteps      | 153600        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00020389276 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.15          |\n",
            "|    entropy_loss         | -1.39         |\n",
            "|    explained_variance   | 1.97e-06      |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 6.58e+03      |\n",
            "|    n_updates            | 740           |\n",
            "|    policy_gradient_loss | -0.000559     |\n",
            "|    value_loss           | 1.4e+04       |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 137         |\n",
            "|    ep_rew_mean          | 1.04e+03    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 571         |\n",
            "|    iterations           | 76          |\n",
            "|    time_elapsed         | 272         |\n",
            "|    total_timesteps      | 155648      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.000336607 |\n",
            "|    clip_fraction        | 0           |\n",
            "|    clip_range           | 0.15        |\n",
            "|    entropy_loss         | -1.39       |\n",
            "|    explained_variance   | 8.94e-07    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 5.6e+03     |\n",
            "|    n_updates            | 750         |\n",
            "|    policy_gradient_loss | -0.000954   |\n",
            "|    value_loss           | 1.11e+04    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 138          |\n",
            "|    ep_rew_mean          | 1.05e+03     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 571          |\n",
            "|    iterations           | 77           |\n",
            "|    time_elapsed         | 276          |\n",
            "|    total_timesteps      | 157696       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 8.210595e-05 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.15         |\n",
            "|    entropy_loss         | -1.39        |\n",
            "|    explained_variance   | 1.13e-06     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 4.74e+03     |\n",
            "|    n_updates            | 760          |\n",
            "|    policy_gradient_loss | -0.000226    |\n",
            "|    value_loss           | 1.07e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 140          |\n",
            "|    ep_rew_mean          | 1.06e+03     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 571          |\n",
            "|    iterations           | 78           |\n",
            "|    time_elapsed         | 279          |\n",
            "|    total_timesteps      | 159744       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0003113499 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.15         |\n",
            "|    entropy_loss         | -1.39        |\n",
            "|    explained_variance   | 2.5e-06      |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.4e+03      |\n",
            "|    n_updates            | 770          |\n",
            "|    policy_gradient_loss | -0.000922    |\n",
            "|    value_loss           | 1.13e+04     |\n",
            "------------------------------------------\n",
            "--------------------------------------------\n",
            "| rollout/                |                |\n",
            "|    ep_len_mean          | 139            |\n",
            "|    ep_rew_mean          | 1.05e+03       |\n",
            "| time/                   |                |\n",
            "|    fps                  | 571            |\n",
            "|    iterations           | 79             |\n",
            "|    time_elapsed         | 283            |\n",
            "|    total_timesteps      | 161792         |\n",
            "| train/                  |                |\n",
            "|    approx_kl            | 0.000111210364 |\n",
            "|    clip_fraction        | 0              |\n",
            "|    clip_range           | 0.15           |\n",
            "|    entropy_loss         | -1.38          |\n",
            "|    explained_variance   | 2.92e-06       |\n",
            "|    learning_rate        | 0.0003         |\n",
            "|    loss                 | 7.53e+03       |\n",
            "|    n_updates            | 780            |\n",
            "|    policy_gradient_loss | -0.000355      |\n",
            "|    value_loss           | 1.48e+04       |\n",
            "--------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 139          |\n",
            "|    ep_rew_mean          | 1.05e+03     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 571          |\n",
            "|    iterations           | 80           |\n",
            "|    time_elapsed         | 286          |\n",
            "|    total_timesteps      | 163840       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 7.154656e-05 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.15         |\n",
            "|    entropy_loss         | -1.39        |\n",
            "|    explained_variance   | 3.58e-07     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.07e+03     |\n",
            "|    n_updates            | 790          |\n",
            "|    policy_gradient_loss | -0.000325    |\n",
            "|    value_loss           | 1.01e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 141          |\n",
            "|    ep_rew_mean          | 1.06e+03     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 571          |\n",
            "|    iterations           | 81           |\n",
            "|    time_elapsed         | 290          |\n",
            "|    total_timesteps      | 165888       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 8.930231e-05 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.15         |\n",
            "|    entropy_loss         | -1.39        |\n",
            "|    explained_variance   | 2.44e-06     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.69e+03     |\n",
            "|    n_updates            | 800          |\n",
            "|    policy_gradient_loss | -0.000285    |\n",
            "|    value_loss           | 1.28e+04     |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 141           |\n",
            "|    ep_rew_mean          | 1.06e+03      |\n",
            "| time/                   |               |\n",
            "|    fps                  | 571           |\n",
            "|    iterations           | 82            |\n",
            "|    time_elapsed         | 294           |\n",
            "|    total_timesteps      | 167936        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00039177155 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.15          |\n",
            "|    entropy_loss         | -1.39         |\n",
            "|    explained_variance   | 7.75e-07      |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 6.18e+03      |\n",
            "|    n_updates            | 810           |\n",
            "|    policy_gradient_loss | -0.00117      |\n",
            "|    value_loss           | 1.23e+04      |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 141           |\n",
            "|    ep_rew_mean          | 1.07e+03      |\n",
            "| time/                   |               |\n",
            "|    fps                  | 571           |\n",
            "|    iterations           | 83            |\n",
            "|    time_elapsed         | 297           |\n",
            "|    total_timesteps      | 169984        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00029415215 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.15          |\n",
            "|    entropy_loss         | -1.39         |\n",
            "|    explained_variance   | 8.34e-07      |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 6.22e+03      |\n",
            "|    n_updates            | 820           |\n",
            "|    policy_gradient_loss | -0.000791     |\n",
            "|    value_loss           | 1.22e+04      |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 138          |\n",
            "|    ep_rew_mean          | 1.04e+03     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 571          |\n",
            "|    iterations           | 84           |\n",
            "|    time_elapsed         | 301          |\n",
            "|    total_timesteps      | 172032       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 4.053107e-05 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.15         |\n",
            "|    entropy_loss         | -1.38        |\n",
            "|    explained_variance   | 1.67e-06     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.49e+03     |\n",
            "|    n_updates            | 830          |\n",
            "|    policy_gradient_loss | -0.000152    |\n",
            "|    value_loss           | 1.15e+04     |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 136           |\n",
            "|    ep_rew_mean          | 1.01e+03      |\n",
            "| time/                   |               |\n",
            "|    fps                  | 571           |\n",
            "|    iterations           | 85            |\n",
            "|    time_elapsed         | 304           |\n",
            "|    total_timesteps      | 174080        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 3.8963393e-05 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.15          |\n",
            "|    entropy_loss         | -1.38         |\n",
            "|    explained_variance   | 1.79e-07      |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 5.24e+03      |\n",
            "|    n_updates            | 840           |\n",
            "|    policy_gradient_loss | -0.000181     |\n",
            "|    value_loss           | 1.06e+04      |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 139           |\n",
            "|    ep_rew_mean          | 1.05e+03      |\n",
            "| time/                   |               |\n",
            "|    fps                  | 571           |\n",
            "|    iterations           | 86            |\n",
            "|    time_elapsed         | 308           |\n",
            "|    total_timesteps      | 176128        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 3.8475468e-05 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.15          |\n",
            "|    entropy_loss         | -1.38         |\n",
            "|    explained_variance   | 9.54e-07      |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 5.98e+03      |\n",
            "|    n_updates            | 850           |\n",
            "|    policy_gradient_loss | -0.000231     |\n",
            "|    value_loss           | 1.2e+04       |\n",
            "-------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 137         |\n",
            "|    ep_rew_mean          | 1.02e+03    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 571         |\n",
            "|    iterations           | 87          |\n",
            "|    time_elapsed         | 311         |\n",
            "|    total_timesteps      | 178176      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 9.89089e-05 |\n",
            "|    clip_fraction        | 0           |\n",
            "|    clip_range           | 0.15        |\n",
            "|    entropy_loss         | -1.39       |\n",
            "|    explained_variance   | 4.17e-07    |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 5.57e+03    |\n",
            "|    n_updates            | 860         |\n",
            "|    policy_gradient_loss | -0.000332   |\n",
            "|    value_loss           | 1.14e+04    |\n",
            "-----------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 137           |\n",
            "|    ep_rew_mean          | 1.03e+03      |\n",
            "| time/                   |               |\n",
            "|    fps                  | 571           |\n",
            "|    iterations           | 88            |\n",
            "|    time_elapsed         | 315           |\n",
            "|    total_timesteps      | 180224        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00029705293 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.15          |\n",
            "|    entropy_loss         | -1.39         |\n",
            "|    explained_variance   | 8.34e-07      |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 5.87e+03      |\n",
            "|    n_updates            | 870           |\n",
            "|    policy_gradient_loss | -0.000735     |\n",
            "|    value_loss           | 1.23e+04      |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 140           |\n",
            "|    ep_rew_mean          | 1.06e+03      |\n",
            "| time/                   |               |\n",
            "|    fps                  | 571           |\n",
            "|    iterations           | 89            |\n",
            "|    time_elapsed         | 319           |\n",
            "|    total_timesteps      | 182272        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00016473897 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.15          |\n",
            "|    entropy_loss         | -1.39         |\n",
            "|    explained_variance   | 1.01e-06      |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 6.32e+03      |\n",
            "|    n_updates            | 880           |\n",
            "|    policy_gradient_loss | -0.000455     |\n",
            "|    value_loss           | 1.22e+04      |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 140           |\n",
            "|    ep_rew_mean          | 1.05e+03      |\n",
            "| time/                   |               |\n",
            "|    fps                  | 571           |\n",
            "|    iterations           | 90            |\n",
            "|    time_elapsed         | 322           |\n",
            "|    total_timesteps      | 184320        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00015737841 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.15          |\n",
            "|    entropy_loss         | -1.39         |\n",
            "|    explained_variance   | 1.25e-06      |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 5.76e+03      |\n",
            "|    n_updates            | 890           |\n",
            "|    policy_gradient_loss | -0.00039      |\n",
            "|    value_loss           | 1.27e+04      |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 142           |\n",
            "|    ep_rew_mean          | 1.07e+03      |\n",
            "| time/                   |               |\n",
            "|    fps                  | 571           |\n",
            "|    iterations           | 91            |\n",
            "|    time_elapsed         | 326           |\n",
            "|    total_timesteps      | 186368        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00018781915 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.15          |\n",
            "|    entropy_loss         | -1.39         |\n",
            "|    explained_variance   | 5.36e-07      |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 6.02e+03      |\n",
            "|    n_updates            | 900           |\n",
            "|    policy_gradient_loss | -0.000506     |\n",
            "|    value_loss           | 1.23e+04      |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 143          |\n",
            "|    ep_rew_mean          | 1.08e+03     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 571          |\n",
            "|    iterations           | 92           |\n",
            "|    time_elapsed         | 329          |\n",
            "|    total_timesteps      | 188416       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0005898593 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.15         |\n",
            "|    entropy_loss         | -1.38        |\n",
            "|    explained_variance   | -2.38e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 5.43e+03     |\n",
            "|    n_updates            | 910          |\n",
            "|    policy_gradient_loss | -0.00125     |\n",
            "|    value_loss           | 1.08e+04     |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 141           |\n",
            "|    ep_rew_mean          | 1.07e+03      |\n",
            "| time/                   |               |\n",
            "|    fps                  | 571           |\n",
            "|    iterations           | 93            |\n",
            "|    time_elapsed         | 333           |\n",
            "|    total_timesteps      | 190464        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00015712166 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.15          |\n",
            "|    entropy_loss         | -1.38         |\n",
            "|    explained_variance   | 5.36e-07      |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 5.85e+03      |\n",
            "|    n_updates            | 920           |\n",
            "|    policy_gradient_loss | -0.000328     |\n",
            "|    value_loss           | 1.22e+04      |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 140           |\n",
            "|    ep_rew_mean          | 1.06e+03      |\n",
            "| time/                   |               |\n",
            "|    fps                  | 571           |\n",
            "|    iterations           | 94            |\n",
            "|    time_elapsed         | 336           |\n",
            "|    total_timesteps      | 192512        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00012614051 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.15          |\n",
            "|    entropy_loss         | -1.38         |\n",
            "|    explained_variance   | 6.56e-07      |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 5.36e+03      |\n",
            "|    n_updates            | 930           |\n",
            "|    policy_gradient_loss | -0.000358     |\n",
            "|    value_loss           | 1.18e+04      |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 138          |\n",
            "|    ep_rew_mean          | 1.04e+03     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 571          |\n",
            "|    iterations           | 95           |\n",
            "|    time_elapsed         | 340          |\n",
            "|    total_timesteps      | 194560       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 6.961945e-05 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.15         |\n",
            "|    entropy_loss         | -1.38        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.27e+03     |\n",
            "|    n_updates            | 940          |\n",
            "|    policy_gradient_loss | -0.000221    |\n",
            "|    value_loss           | 1.25e+04     |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 139           |\n",
            "|    ep_rew_mean          | 1.06e+03      |\n",
            "| time/                   |               |\n",
            "|    fps                  | 571           |\n",
            "|    iterations           | 96            |\n",
            "|    time_elapsed         | 344           |\n",
            "|    total_timesteps      | 196608        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00021155269 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.15          |\n",
            "|    entropy_loss         | -1.38         |\n",
            "|    explained_variance   | 2.98e-07      |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 6.57e+03      |\n",
            "|    n_updates            | 950           |\n",
            "|    policy_gradient_loss | -0.000555     |\n",
            "|    value_loss           | 1.4e+04       |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 136           |\n",
            "|    ep_rew_mean          | 1.02e+03      |\n",
            "| time/                   |               |\n",
            "|    fps                  | 571           |\n",
            "|    iterations           | 97            |\n",
            "|    time_elapsed         | 347           |\n",
            "|    total_timesteps      | 198656        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00022060581 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.15          |\n",
            "|    entropy_loss         | -1.38         |\n",
            "|    explained_variance   | 7.75e-07      |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 7e+03         |\n",
            "|    n_updates            | 960           |\n",
            "|    policy_gradient_loss | -0.000498     |\n",
            "|    value_loss           | 1.31e+04      |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 135          |\n",
            "|    ep_rew_mean          | 1e+03        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 571          |\n",
            "|    iterations           | 98           |\n",
            "|    time_elapsed         | 351          |\n",
            "|    total_timesteps      | 200704       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0008901984 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.15         |\n",
            "|    entropy_loss         | -1.38        |\n",
            "|    explained_variance   | -3.58e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.16e+03     |\n",
            "|    n_updates            | 970          |\n",
            "|    policy_gradient_loss | -0.00109     |\n",
            "|    value_loss           | 1.21e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 137          |\n",
            "|    ep_rew_mean          | 1.02e+03     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 571          |\n",
            "|    iterations           | 99           |\n",
            "|    time_elapsed         | 354          |\n",
            "|    total_timesteps      | 202752       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0005604662 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.15         |\n",
            "|    entropy_loss         | -1.38        |\n",
            "|    explained_variance   | 1.79e-07     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.77e+03     |\n",
            "|    n_updates            | 980          |\n",
            "|    policy_gradient_loss | -0.00105     |\n",
            "|    value_loss           | 1.33e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 137          |\n",
            "|    ep_rew_mean          | 1.02e+03     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 571          |\n",
            "|    iterations           | 100          |\n",
            "|    time_elapsed         | 358          |\n",
            "|    total_timesteps      | 204800       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 6.932614e-05 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.15         |\n",
            "|    entropy_loss         | -1.38        |\n",
            "|    explained_variance   | 5.36e-07     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 7.33e+03     |\n",
            "|    n_updates            | 990          |\n",
            "|    policy_gradient_loss | -0.000215    |\n",
            "|    value_loss           | 1.36e+04     |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 143           |\n",
            "|    ep_rew_mean          | 1.07e+03      |\n",
            "| time/                   |               |\n",
            "|    fps                  | 571           |\n",
            "|    iterations           | 101           |\n",
            "|    time_elapsed         | 361           |\n",
            "|    total_timesteps      | 206848        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00012315315 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.15          |\n",
            "|    entropy_loss         | -1.38         |\n",
            "|    explained_variance   | 2.38e-07      |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 5.72e+03      |\n",
            "|    n_updates            | 1000          |\n",
            "|    policy_gradient_loss | -0.00032      |\n",
            "|    value_loss           | 1.26e+04      |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 145           |\n",
            "|    ep_rew_mean          | 1.09e+03      |\n",
            "| time/                   |               |\n",
            "|    fps                  | 571           |\n",
            "|    iterations           | 102           |\n",
            "|    time_elapsed         | 365           |\n",
            "|    total_timesteps      | 208896        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00021055908 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.15          |\n",
            "|    entropy_loss         | -1.38         |\n",
            "|    explained_variance   | 1.19e-06      |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 7.87e+03      |\n",
            "|    n_updates            | 1010          |\n",
            "|    policy_gradient_loss | -0.000633     |\n",
            "|    value_loss           | 1.45e+04      |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 144          |\n",
            "|    ep_rew_mean          | 1.08e+03     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 571          |\n",
            "|    iterations           | 103          |\n",
            "|    time_elapsed         | 369          |\n",
            "|    total_timesteps      | 210944       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0003731753 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.15         |\n",
            "|    entropy_loss         | -1.38        |\n",
            "|    explained_variance   | -2.38e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.64e+03     |\n",
            "|    n_updates            | 1020         |\n",
            "|    policy_gradient_loss | -0.000624    |\n",
            "|    value_loss           | 1.22e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 147          |\n",
            "|    ep_rew_mean          | 1.12e+03     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 571          |\n",
            "|    iterations           | 104          |\n",
            "|    time_elapsed         | 372          |\n",
            "|    total_timesteps      | 212992       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0005931078 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.15         |\n",
            "|    entropy_loss         | -1.38        |\n",
            "|    explained_variance   | 2.38e-07     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.7e+03      |\n",
            "|    n_updates            | 1030         |\n",
            "|    policy_gradient_loss | -0.0012      |\n",
            "|    value_loss           | 1.32e+04     |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 146           |\n",
            "|    ep_rew_mean          | 1.11e+03      |\n",
            "| time/                   |               |\n",
            "|    fps                  | 571           |\n",
            "|    iterations           | 105           |\n",
            "|    time_elapsed         | 376           |\n",
            "|    total_timesteps      | 215040        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 4.7450303e-05 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.15          |\n",
            "|    entropy_loss         | -1.38         |\n",
            "|    explained_variance   | 3.58e-07      |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 6.73e+03      |\n",
            "|    n_updates            | 1040          |\n",
            "|    policy_gradient_loss | -0.00018      |\n",
            "|    value_loss           | 1.39e+04      |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 144          |\n",
            "|    ep_rew_mean          | 1.08e+03     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 571          |\n",
            "|    iterations           | 106          |\n",
            "|    time_elapsed         | 379          |\n",
            "|    total_timesteps      | 217088       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0041915434 |\n",
            "|    clip_fraction        | 0.041        |\n",
            "|    clip_range           | 0.15         |\n",
            "|    entropy_loss         | -1.38        |\n",
            "|    explained_variance   | -1.31e-06    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.15e+03     |\n",
            "|    n_updates            | 1050         |\n",
            "|    policy_gradient_loss | -0.00222     |\n",
            "|    value_loss           | 1.17e+04     |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 144           |\n",
            "|    ep_rew_mean          | 1.09e+03      |\n",
            "| time/                   |               |\n",
            "|    fps                  | 571           |\n",
            "|    iterations           | 107           |\n",
            "|    time_elapsed         | 383           |\n",
            "|    total_timesteps      | 219136        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00048199925 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.15          |\n",
            "|    entropy_loss         | -1.38         |\n",
            "|    explained_variance   | 1.79e-07      |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 5.91e+03      |\n",
            "|    n_updates            | 1060          |\n",
            "|    policy_gradient_loss | -3.16e-06     |\n",
            "|    value_loss           | 1.39e+04      |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 140          |\n",
            "|    ep_rew_mean          | 1.06e+03     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 571          |\n",
            "|    iterations           | 108          |\n",
            "|    time_elapsed         | 387          |\n",
            "|    total_timesteps      | 221184       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 3.324033e-05 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.15         |\n",
            "|    entropy_loss         | -1.38        |\n",
            "|    explained_variance   | 5.96e-08     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 7.37e+03     |\n",
            "|    n_updates            | 1070         |\n",
            "|    policy_gradient_loss | -0.000237    |\n",
            "|    value_loss           | 1.46e+04     |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 137           |\n",
            "|    ep_rew_mean          | 1.03e+03      |\n",
            "| time/                   |               |\n",
            "|    fps                  | 571           |\n",
            "|    iterations           | 109           |\n",
            "|    time_elapsed         | 390           |\n",
            "|    total_timesteps      | 223232        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 2.6963913e-05 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.15          |\n",
            "|    entropy_loss         | -1.38         |\n",
            "|    explained_variance   | 2.98e-07      |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 6.93e+03      |\n",
            "|    n_updates            | 1080          |\n",
            "|    policy_gradient_loss | -0.000178     |\n",
            "|    value_loss           | 1.33e+04      |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 134          |\n",
            "|    ep_rew_mean          | 1e+03        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 571          |\n",
            "|    iterations           | 110          |\n",
            "|    time_elapsed         | 394          |\n",
            "|    total_timesteps      | 225280       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 9.467403e-05 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.15         |\n",
            "|    entropy_loss         | -1.38        |\n",
            "|    explained_variance   | -2.38e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.23e+03     |\n",
            "|    n_updates            | 1090         |\n",
            "|    policy_gradient_loss | -0.00044     |\n",
            "|    value_loss           | 1.32e+04     |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 137           |\n",
            "|    ep_rew_mean          | 1.03e+03      |\n",
            "| time/                   |               |\n",
            "|    fps                  | 571           |\n",
            "|    iterations           | 111           |\n",
            "|    time_elapsed         | 397           |\n",
            "|    total_timesteps      | 227328        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 2.3774948e-05 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.15          |\n",
            "|    entropy_loss         | -1.38         |\n",
            "|    explained_variance   | -1.19e-07     |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 6.15e+03      |\n",
            "|    n_updates            | 1100          |\n",
            "|    policy_gradient_loss | -9.06e-05     |\n",
            "|    value_loss           | 1.23e+04      |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 137           |\n",
            "|    ep_rew_mean          | 1.04e+03      |\n",
            "| time/                   |               |\n",
            "|    fps                  | 571           |\n",
            "|    iterations           | 112           |\n",
            "|    time_elapsed         | 401           |\n",
            "|    total_timesteps      | 229376        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 4.8705784e-05 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.15          |\n",
            "|    entropy_loss         | -1.38         |\n",
            "|    explained_variance   | 0             |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 7.71e+03      |\n",
            "|    n_updates            | 1110          |\n",
            "|    policy_gradient_loss | -0.000231     |\n",
            "|    value_loss           | 1.42e+04      |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 138           |\n",
            "|    ep_rew_mean          | 1.05e+03      |\n",
            "| time/                   |               |\n",
            "|    fps                  | 571           |\n",
            "|    iterations           | 113           |\n",
            "|    time_elapsed         | 404           |\n",
            "|    total_timesteps      | 231424        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 1.9934261e-05 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.15          |\n",
            "|    entropy_loss         | -1.38         |\n",
            "|    explained_variance   | -1.19e-07     |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 6.54e+03      |\n",
            "|    n_updates            | 1120          |\n",
            "|    policy_gradient_loss | -0.000192     |\n",
            "|    value_loss           | 1.31e+04      |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 135          |\n",
            "|    ep_rew_mean          | 1.01e+03     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 571          |\n",
            "|    iterations           | 114          |\n",
            "|    time_elapsed         | 408          |\n",
            "|    total_timesteps      | 233472       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 9.196578e-06 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.15         |\n",
            "|    entropy_loss         | -1.38        |\n",
            "|    explained_variance   | 1.19e-07     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 8.37e+03     |\n",
            "|    n_updates            | 1130         |\n",
            "|    policy_gradient_loss | -0.000155    |\n",
            "|    value_loss           | 1.45e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 132          |\n",
            "|    ep_rew_mean          | 988          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 571          |\n",
            "|    iterations           | 115          |\n",
            "|    time_elapsed         | 411          |\n",
            "|    total_timesteps      | 235520       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0035296506 |\n",
            "|    clip_fraction        | 0.024        |\n",
            "|    clip_range           | 0.15         |\n",
            "|    entropy_loss         | -1.38        |\n",
            "|    explained_variance   | -7.15e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.75e+03     |\n",
            "|    n_updates            | 1140         |\n",
            "|    policy_gradient_loss | -0.000434    |\n",
            "|    value_loss           | 1.26e+04     |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 131           |\n",
            "|    ep_rew_mean          | 982           |\n",
            "| time/                   |               |\n",
            "|    fps                  | 571           |\n",
            "|    iterations           | 116           |\n",
            "|    time_elapsed         | 415           |\n",
            "|    total_timesteps      | 237568        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00038467225 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.15          |\n",
            "|    entropy_loss         | -1.38         |\n",
            "|    explained_variance   | -3.58e-07     |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 6.22e+03      |\n",
            "|    n_updates            | 1150          |\n",
            "|    policy_gradient_loss | 0.000213      |\n",
            "|    value_loss           | 1.3e+04       |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 131          |\n",
            "|    ep_rew_mean          | 981          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 571          |\n",
            "|    iterations           | 117          |\n",
            "|    time_elapsed         | 419          |\n",
            "|    total_timesteps      | 239616       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0014763912 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.15         |\n",
            "|    entropy_loss         | -1.38        |\n",
            "|    explained_variance   | -4.77e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 7.21e+03     |\n",
            "|    n_updates            | 1160         |\n",
            "|    policy_gradient_loss | -0.00105     |\n",
            "|    value_loss           | 1.31e+04     |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 129           |\n",
            "|    ep_rew_mean          | 961           |\n",
            "| time/                   |               |\n",
            "|    fps                  | 571           |\n",
            "|    iterations           | 118           |\n",
            "|    time_elapsed         | 422           |\n",
            "|    total_timesteps      | 241664        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 7.1834074e-05 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.15          |\n",
            "|    entropy_loss         | -1.38         |\n",
            "|    explained_variance   | -1.19e-07     |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 6.06e+03      |\n",
            "|    n_updates            | 1170          |\n",
            "|    policy_gradient_loss | -0.000242     |\n",
            "|    value_loss           | 1.42e+04      |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 129          |\n",
            "|    ep_rew_mean          | 962          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 571          |\n",
            "|    iterations           | 119          |\n",
            "|    time_elapsed         | 426          |\n",
            "|    total_timesteps      | 243712       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 3.018073e-05 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.15         |\n",
            "|    entropy_loss         | -1.38        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.95e+03     |\n",
            "|    n_updates            | 1180         |\n",
            "|    policy_gradient_loss | -0.000194    |\n",
            "|    value_loss           | 1.32e+04     |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 131           |\n",
            "|    ep_rew_mean          | 983           |\n",
            "| time/                   |               |\n",
            "|    fps                  | 571           |\n",
            "|    iterations           | 120           |\n",
            "|    time_elapsed         | 429           |\n",
            "|    total_timesteps      | 245760        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 1.7926825e-05 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.15          |\n",
            "|    entropy_loss         | -1.38         |\n",
            "|    explained_variance   | 0             |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 7.63e+03      |\n",
            "|    n_updates            | 1190          |\n",
            "|    policy_gradient_loss | -0.000159     |\n",
            "|    value_loss           | 1.39e+04      |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 133          |\n",
            "|    ep_rew_mean          | 996          |\n",
            "| time/                   |              |\n",
            "|    fps                  | 571          |\n",
            "|    iterations           | 121          |\n",
            "|    time_elapsed         | 433          |\n",
            "|    total_timesteps      | 247808       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0013811891 |\n",
            "|    clip_fraction        | 4.88e-05     |\n",
            "|    clip_range           | 0.15         |\n",
            "|    entropy_loss         | -1.38        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 7.48e+03     |\n",
            "|    n_updates            | 1200         |\n",
            "|    policy_gradient_loss | -0.000803    |\n",
            "|    value_loss           | 1.38e+04     |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 137           |\n",
            "|    ep_rew_mean          | 1.03e+03      |\n",
            "| time/                   |               |\n",
            "|    fps                  | 571           |\n",
            "|    iterations           | 122           |\n",
            "|    time_elapsed         | 436           |\n",
            "|    total_timesteps      | 249856        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 5.5811513e-05 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.15          |\n",
            "|    entropy_loss         | -1.38         |\n",
            "|    explained_variance   | -1.19e-07     |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 7.2e+03       |\n",
            "|    n_updates            | 1210          |\n",
            "|    policy_gradient_loss | 2.03e-05      |\n",
            "|    value_loss           | 1.47e+04      |\n",
            "-------------------------------------------\n",
            "--------------------------------------------\n",
            "| rollout/                |                |\n",
            "|    ep_len_mean          | 138            |\n",
            "|    ep_rew_mean          | 1.04e+03       |\n",
            "| time/                   |                |\n",
            "|    fps                  | 572            |\n",
            "|    iterations           | 123            |\n",
            "|    time_elapsed         | 440            |\n",
            "|    total_timesteps      | 251904         |\n",
            "| train/                  |                |\n",
            "|    approx_kl            | 0.000109488145 |\n",
            "|    clip_fraction        | 0              |\n",
            "|    clip_range           | 0.15           |\n",
            "|    entropy_loss         | -1.38          |\n",
            "|    explained_variance   | -1.19e-07      |\n",
            "|    learning_rate        | 0.0003         |\n",
            "|    loss                 | 6.8e+03        |\n",
            "|    n_updates            | 1220           |\n",
            "|    policy_gradient_loss | -0.000402      |\n",
            "|    value_loss           | 1.28e+04       |\n",
            "--------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 141           |\n",
            "|    ep_rew_mean          | 1.07e+03      |\n",
            "| time/                   |               |\n",
            "|    fps                  | 571           |\n",
            "|    iterations           | 124           |\n",
            "|    time_elapsed         | 443           |\n",
            "|    total_timesteps      | 253952        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 2.6619964e-05 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.15          |\n",
            "|    entropy_loss         | -1.38         |\n",
            "|    explained_variance   | 5.96e-08      |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 8.01e+03      |\n",
            "|    n_updates            | 1230          |\n",
            "|    policy_gradient_loss | -0.000189     |\n",
            "|    value_loss           | 1.45e+04      |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 139           |\n",
            "|    ep_rew_mean          | 1.05e+03      |\n",
            "| time/                   |               |\n",
            "|    fps                  | 572           |\n",
            "|    iterations           | 125           |\n",
            "|    time_elapsed         | 447           |\n",
            "|    total_timesteps      | 256000        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 1.1378055e-05 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.15          |\n",
            "|    entropy_loss         | -1.38         |\n",
            "|    explained_variance   | 0             |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 7.28e+03      |\n",
            "|    n_updates            | 1240          |\n",
            "|    policy_gradient_loss | -0.000104     |\n",
            "|    value_loss           | 1.37e+04      |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 139          |\n",
            "|    ep_rew_mean          | 1.03e+03     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 572          |\n",
            "|    iterations           | 126          |\n",
            "|    time_elapsed         | 451          |\n",
            "|    total_timesteps      | 258048       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0026607034 |\n",
            "|    clip_fraction        | 0.0219       |\n",
            "|    clip_range           | 0.15         |\n",
            "|    entropy_loss         | -1.38        |\n",
            "|    explained_variance   | -2.38e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 8.02e+03     |\n",
            "|    n_updates            | 1250         |\n",
            "|    policy_gradient_loss | -0.00282     |\n",
            "|    value_loss           | 1.42e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 138          |\n",
            "|    ep_rew_mean          | 1.01e+03     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 572          |\n",
            "|    iterations           | 127          |\n",
            "|    time_elapsed         | 454          |\n",
            "|    total_timesteps      | 260096       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0012350171 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.15         |\n",
            "|    entropy_loss         | -1.38        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.78e+03     |\n",
            "|    n_updates            | 1260         |\n",
            "|    policy_gradient_loss | 0.000242     |\n",
            "|    value_loss           | 1.42e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 137          |\n",
            "|    ep_rew_mean          | 1.01e+03     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 572          |\n",
            "|    iterations           | 128          |\n",
            "|    time_elapsed         | 458          |\n",
            "|    total_timesteps      | 262144       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0006536473 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.15         |\n",
            "|    entropy_loss         | -1.38        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.25e+03     |\n",
            "|    n_updates            | 1270         |\n",
            "|    policy_gradient_loss | -0.00111     |\n",
            "|    value_loss           | 1.36e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 137          |\n",
            "|    ep_rew_mean          | 1e+03        |\n",
            "| time/                   |              |\n",
            "|    fps                  | 572          |\n",
            "|    iterations           | 129          |\n",
            "|    time_elapsed         | 461          |\n",
            "|    total_timesteps      | 264192       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0002875535 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.15         |\n",
            "|    entropy_loss         | -1.38        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.98e+03     |\n",
            "|    n_updates            | 1280         |\n",
            "|    policy_gradient_loss | -0.000617    |\n",
            "|    value_loss           | 1.39e+04     |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 140          |\n",
            "|    ep_rew_mean          | 1.03e+03     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 572          |\n",
            "|    iterations           | 130          |\n",
            "|    time_elapsed         | 465          |\n",
            "|    total_timesteps      | 266240       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 4.922709e-06 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.15         |\n",
            "|    entropy_loss         | -1.38        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.5e+03      |\n",
            "|    n_updates            | 1290         |\n",
            "|    policy_gradient_loss | -9.15e-06    |\n",
            "|    value_loss           | 1.42e+04     |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 137           |\n",
            "|    ep_rew_mean          | 1.01e+03      |\n",
            "| time/                   |               |\n",
            "|    fps                  | 572           |\n",
            "|    iterations           | 131           |\n",
            "|    time_elapsed         | 468           |\n",
            "|    total_timesteps      | 268288        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00016341516 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.15          |\n",
            "|    entropy_loss         | -1.38         |\n",
            "|    explained_variance   | 0             |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 6.45e+03      |\n",
            "|    n_updates            | 1300          |\n",
            "|    policy_gradient_loss | -0.000421     |\n",
            "|    value_loss           | 1.49e+04      |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 139           |\n",
            "|    ep_rew_mean          | 1.03e+03      |\n",
            "| time/                   |               |\n",
            "|    fps                  | 572           |\n",
            "|    iterations           | 132           |\n",
            "|    time_elapsed         | 472           |\n",
            "|    total_timesteps      | 270336        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00055983517 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.15          |\n",
            "|    entropy_loss         | -1.38         |\n",
            "|    explained_variance   | -1.19e-07     |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 6.97e+03      |\n",
            "|    n_updates            | 1310          |\n",
            "|    policy_gradient_loss | -0.00134      |\n",
            "|    value_loss           | 1.42e+04      |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 139          |\n",
            "|    ep_rew_mean          | 1.04e+03     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 572          |\n",
            "|    iterations           | 133          |\n",
            "|    time_elapsed         | 475          |\n",
            "|    total_timesteps      | 272384       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0012203441 |\n",
            "|    clip_fraction        | 0.00781      |\n",
            "|    clip_range           | 0.15         |\n",
            "|    entropy_loss         | -1.38        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 6.64e+03     |\n",
            "|    n_updates            | 1320         |\n",
            "|    policy_gradient_loss | -0.00102     |\n",
            "|    value_loss           | 1.39e+04     |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 141           |\n",
            "|    ep_rew_mean          | 1.06e+03      |\n",
            "| time/                   |               |\n",
            "|    fps                  | 572           |\n",
            "|    iterations           | 134           |\n",
            "|    time_elapsed         | 479           |\n",
            "|    total_timesteps      | 274432        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00038184988 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.15          |\n",
            "|    entropy_loss         | -1.38         |\n",
            "|    explained_variance   | 0             |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 7.34e+03      |\n",
            "|    n_updates            | 1330          |\n",
            "|    policy_gradient_loss | 0.000564      |\n",
            "|    value_loss           | 1.49e+04      |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 144          |\n",
            "|    ep_rew_mean          | 1.09e+03     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 572          |\n",
            "|    iterations           | 135          |\n",
            "|    time_elapsed         | 482          |\n",
            "|    total_timesteps      | 276480       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0014762256 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.15         |\n",
            "|    entropy_loss         | -1.38        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 7.46e+03     |\n",
            "|    n_updates            | 1340         |\n",
            "|    policy_gradient_loss | -0.00113     |\n",
            "|    value_loss           | 1.51e+04     |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 142           |\n",
            "|    ep_rew_mean          | 1.08e+03      |\n",
            "| time/                   |               |\n",
            "|    fps                  | 572           |\n",
            "|    iterations           | 136           |\n",
            "|    time_elapsed         | 486           |\n",
            "|    total_timesteps      | 278528        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00015108651 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.15          |\n",
            "|    entropy_loss         | -1.38         |\n",
            "|    explained_variance   | 1.19e-07      |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 8.82e+03      |\n",
            "|    n_updates            | 1350          |\n",
            "|    policy_gradient_loss | -0.000195     |\n",
            "|    value_loss           | 1.66e+04      |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 140           |\n",
            "|    ep_rew_mean          | 1.05e+03      |\n",
            "| time/                   |               |\n",
            "|    fps                  | 572           |\n",
            "|    iterations           | 137           |\n",
            "|    time_elapsed         | 490           |\n",
            "|    total_timesteps      | 280576        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00029934806 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.15          |\n",
            "|    entropy_loss         | -1.38         |\n",
            "|    explained_variance   | 0             |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 7.46e+03      |\n",
            "|    n_updates            | 1360          |\n",
            "|    policy_gradient_loss | -0.000767     |\n",
            "|    value_loss           | 1.42e+04      |\n",
            "-------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 143           |\n",
            "|    ep_rew_mean          | 1.09e+03      |\n",
            "| time/                   |               |\n",
            "|    fps                  | 572           |\n",
            "|    iterations           | 138           |\n",
            "|    time_elapsed         | 493           |\n",
            "|    total_timesteps      | 282624        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00016134785 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.15          |\n",
            "|    entropy_loss         | -1.38         |\n",
            "|    explained_variance   | -1.19e-07     |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 8.02e+03      |\n",
            "|    n_updates            | 1370          |\n",
            "|    policy_gradient_loss | -0.000467     |\n",
            "|    value_loss           | 1.64e+04      |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 145          |\n",
            "|    ep_rew_mean          | 1.12e+03     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 572          |\n",
            "|    iterations           | 139          |\n",
            "|    time_elapsed         | 497          |\n",
            "|    total_timesteps      | 284672       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0023832812 |\n",
            "|    clip_fraction        | 0.000244     |\n",
            "|    clip_range           | 0.15         |\n",
            "|    entropy_loss         | -1.38        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 9.33e+03     |\n",
            "|    n_updates            | 1380         |\n",
            "|    policy_gradient_loss | -0.00232     |\n",
            "|    value_loss           | 1.58e+04     |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 145           |\n",
            "|    ep_rew_mean          | 1.12e+03      |\n",
            "| time/                   |               |\n",
            "|    fps                  | 572           |\n",
            "|    iterations           | 140           |\n",
            "|    time_elapsed         | 500           |\n",
            "|    total_timesteps      | 286720        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00015718231 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.15          |\n",
            "|    entropy_loss         | -1.38         |\n",
            "|    explained_variance   | 0             |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 8.97e+03      |\n",
            "|    n_updates            | 1390          |\n",
            "|    policy_gradient_loss | -0.000348     |\n",
            "|    value_loss           | 1.57e+04      |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 144          |\n",
            "|    ep_rew_mean          | 1.11e+03     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 572          |\n",
            "|    iterations           | 141          |\n",
            "|    time_elapsed         | 504          |\n",
            "|    total_timesteps      | 288768       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0032121784 |\n",
            "|    clip_fraction        | 0.0758       |\n",
            "|    clip_range           | 0.15         |\n",
            "|    entropy_loss         | -1.37        |\n",
            "|    explained_variance   | 0            |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 7.78e+03     |\n",
            "|    n_updates            | 1400         |\n",
            "|    policy_gradient_loss | -0.004       |\n",
            "|    value_loss           | 1.5e+04      |\n",
            "------------------------------------------\n",
            "----------------------------------------\n",
            "| rollout/                |            |\n",
            "|    ep_len_mean          | 143        |\n",
            "|    ep_rew_mean          | 1.1e+03    |\n",
            "| time/                   |            |\n",
            "|    fps                  | 572        |\n",
            "|    iterations           | 142        |\n",
            "|    time_elapsed         | 507        |\n",
            "|    total_timesteps      | 290816     |\n",
            "| train/                  |            |\n",
            "|    approx_kl            | 0.00333516 |\n",
            "|    clip_fraction        | 0.0452     |\n",
            "|    clip_range           | 0.15       |\n",
            "|    entropy_loss         | -1.37      |\n",
            "|    explained_variance   | -1.19e-07  |\n",
            "|    learning_rate        | 0.0003     |\n",
            "|    loss                 | 7.38e+03   |\n",
            "|    n_updates            | 1410       |\n",
            "|    policy_gradient_loss | -0.0035    |\n",
            "|    value_loss           | 1.56e+04   |\n",
            "----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 142         |\n",
            "|    ep_rew_mean          | 1.07e+03    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 572         |\n",
            "|    iterations           | 143         |\n",
            "|    time_elapsed         | 511         |\n",
            "|    total_timesteps      | 292864      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002996153 |\n",
            "|    clip_fraction        | 0.00332     |\n",
            "|    clip_range           | 0.15        |\n",
            "|    entropy_loss         | -1.36       |\n",
            "|    explained_variance   | -1.19e-07   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 6.41e+03    |\n",
            "|    n_updates            | 1420        |\n",
            "|    policy_gradient_loss | -0.00248    |\n",
            "|    value_loss           | 1.46e+04    |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 140         |\n",
            "|    ep_rew_mean          | 1.05e+03    |\n",
            "| time/                   |             |\n",
            "|    fps                  | 572         |\n",
            "|    iterations           | 144         |\n",
            "|    time_elapsed         | 515         |\n",
            "|    total_timesteps      | 294912      |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.008744746 |\n",
            "|    clip_fraction        | 0.0361      |\n",
            "|    clip_range           | 0.15        |\n",
            "|    entropy_loss         | -1.35       |\n",
            "|    explained_variance   | -1.19e-07   |\n",
            "|    learning_rate        | 0.0003      |\n",
            "|    loss                 | 8.84e+03    |\n",
            "|    n_updates            | 1430        |\n",
            "|    policy_gradient_loss | -0.000814   |\n",
            "|    value_loss           | 1.62e+04    |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 142          |\n",
            "|    ep_rew_mean          | 1.07e+03     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 572          |\n",
            "|    iterations           | 145          |\n",
            "|    time_elapsed         | 518          |\n",
            "|    total_timesteps      | 296960       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0033835701 |\n",
            "|    clip_fraction        | 0.0699       |\n",
            "|    clip_range           | 0.15         |\n",
            "|    entropy_loss         | -1.35        |\n",
            "|    explained_variance   | -1.19e-07    |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 7.61e+03     |\n",
            "|    n_updates            | 1440         |\n",
            "|    policy_gradient_loss | -0.00155     |\n",
            "|    value_loss           | 1.64e+04     |\n",
            "------------------------------------------\n",
            "-------------------------------------------\n",
            "| rollout/                |               |\n",
            "|    ep_len_mean          | 144           |\n",
            "|    ep_rew_mean          | 1.09e+03      |\n",
            "| time/                   |               |\n",
            "|    fps                  | 572           |\n",
            "|    iterations           | 146           |\n",
            "|    time_elapsed         | 522           |\n",
            "|    total_timesteps      | 299008        |\n",
            "| train/                  |               |\n",
            "|    approx_kl            | 0.00044724985 |\n",
            "|    clip_fraction        | 0             |\n",
            "|    clip_range           | 0.15          |\n",
            "|    entropy_loss         | -1.35         |\n",
            "|    explained_variance   | 5.96e-08      |\n",
            "|    learning_rate        | 0.0003        |\n",
            "|    loss                 | 8.17e+03      |\n",
            "|    n_updates            | 1450          |\n",
            "|    policy_gradient_loss | -2.93e-05     |\n",
            "|    value_loss           | 1.57e+04      |\n",
            "-------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 143          |\n",
            "|    ep_rew_mean          | 1.08e+03     |\n",
            "| time/                   |              |\n",
            "|    fps                  | 572          |\n",
            "|    iterations           | 147          |\n",
            "|    time_elapsed         | 525          |\n",
            "|    total_timesteps      | 301056       |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 8.050469e-05 |\n",
            "|    clip_fraction        | 0            |\n",
            "|    clip_range           | 0.15         |\n",
            "|    entropy_loss         | -1.35        |\n",
            "|    explained_variance   | 1.19e-07     |\n",
            "|    learning_rate        | 0.0003       |\n",
            "|    loss                 | 7.55e+03     |\n",
            "|    n_updates            | 1460         |\n",
            "|    policy_gradient_loss | -0.000359    |\n",
            "|    value_loss           | 1.64e+04     |\n",
            "------------------------------------------\n",
            "Saved model ppo_2048_v2_simple.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from stable_baselines3 import PPO\n",
        "\n",
        "model_v2 = PPO.load(\"ppo_2048_v2_simple\")\n",
        "\n",
        "env_eval = Game2048EnvV2(render_mode=\"ansi\")\n",
        "obs, info = env_eval.reset()\n",
        "done = False\n",
        "step = 0\n",
        "\n",
        "print(\"Initial board:\")\n",
        "print(env_eval._board_to_string())\n",
        "\n",
        "while not done:\n",
        "    # üîΩ IMPORTANT: try deterministic=False to see variety\n",
        "    action, _ = model_v2.predict(obs, deterministic=False)\n",
        "    obs, reward, terminated, truncated, info = env_eval.step(int(action))\n",
        "    done = terminated or truncated\n",
        "\n",
        "    print(f\"\\nStep {step}, action={int(action)}, reward={reward:.2f}, score={info['score']:.2f}\")\n",
        "    print(env_eval._board_to_string())\n",
        "    time.sleep(0.1)\n",
        "    step += 1\n",
        "\n",
        "print(\"\\nEpisode finished.\")\n",
        "print(f\"Final score: {info['score']}, max tile: {info['max_tile']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h_jOji2Y9oBx",
        "outputId": "976e9fa3-5885-4853-a77e-3bb338e3c065"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial board:\n",
            ".\t.\t.\t4\n",
            ".\t.\t.\t.\n",
            ".\t.\t2\t.\n",
            ".\t.\t.\t.\n",
            "\n",
            "Step 0, action=1, reward=0.63, score=0.63\n",
            ".\t.\t.\t2\n",
            ".\t.\t.\t.\n",
            ".\t.\t.\t.\n",
            ".\t.\t2\t4\n",
            "\n",
            "Step 1, action=2, reward=0.12, score=0.75\n",
            "2\t.\t2\t.\n",
            ".\t.\t.\t.\n",
            ".\t.\t.\t.\n",
            "2\t4\t.\t.\n",
            "\n",
            "Step 2, action=0, reward=4.12, score=4.87\n",
            "4\t4\t2\t.\n",
            ".\t.\t.\t.\n",
            ".\t.\t.\t.\n",
            ".\t.\t4\t.\n",
            "\n",
            "Step 3, action=0, reward=0.11, score=4.98\n",
            "4\t4\t2\t.\n",
            ".\t.\t4\t.\n",
            ".\t.\t.\t.\n",
            ".\t.\t.\t2\n",
            "\n",
            "Step 4, action=1, reward=0.10, score=5.08\n",
            ".\t.\t.\t.\n",
            ".\t.\t.\t2\n",
            ".\t.\t2\t.\n",
            "4\t4\t4\t2\n",
            "\n",
            "Step 5, action=0, reward=4.10, score=9.18\n",
            "4\t4\t2\t4\n",
            ".\t.\t4\t.\n",
            "2\t.\t.\t.\n",
            ".\t.\t.\t.\n",
            "\n",
            "Step 6, action=3, reward=8.60, score=17.78\n",
            ".\t8\t2\t4\n",
            ".\t.\t2\t4\n",
            ".\t.\t.\t2\n",
            ".\t.\t.\t.\n",
            "\n",
            "Step 7, action=2, reward=0.09, score=17.87\n",
            "8\t2\t4\t.\n",
            "2\t4\t.\t.\n",
            "2\t.\t.\t2\n",
            ".\t.\t.\t.\n",
            "\n",
            "Step 8, action=0, reward=4.09, score=21.96\n",
            "8\t2\t4\t2\n",
            "4\t4\t.\t.\n",
            ".\t.\t.\t.\n",
            ".\t.\t2\t.\n",
            "\n",
            "Step 9, action=1, reward=0.08, score=22.04\n",
            ".\t.\t2\t.\n",
            ".\t.\t.\t.\n",
            "8\t2\t4\t.\n",
            "4\t4\t2\t2\n",
            "\n",
            "Step 10, action=3, reward=12.09, score=34.13\n",
            ".\t.\t.\t2\n",
            "2\t.\t.\t.\n",
            ".\t8\t2\t4\n",
            ".\t.\t8\t4\n",
            "\n",
            "Step 11, action=0, reward=8.09, score=42.22\n",
            "2\t8\t2\t2\n",
            ".\t2\t8\t8\n",
            ".\t.\t.\t.\n",
            ".\t.\t.\t.\n",
            "\n",
            "Step 12, action=1, reward=0.08, score=42.30\n",
            "2\t.\t.\t.\n",
            ".\t.\t.\t.\n",
            ".\t8\t2\t2\n",
            "2\t2\t8\t8\n",
            "\n",
            "Step 13, action=2, reward=24.60, score=66.90\n",
            "2\t.\t.\t.\n",
            ".\t.\t.\t.\n",
            "8\t4\t2\t.\n",
            "4\t16\t.\t.\n",
            "\n",
            "Step 14, action=1, reward=0.09, score=66.99\n",
            ".\t2\t.\t.\n",
            "2\t.\t.\t.\n",
            "8\t4\t.\t.\n",
            "4\t16\t2\t.\n",
            "\n",
            "Step 15, action=3, reward=0.08, score=67.07\n",
            ".\t2\t.\t2\n",
            ".\t.\t.\t2\n",
            ".\t.\t8\t4\n",
            ".\t4\t16\t2\n",
            "\n",
            "Step 16, action=1, reward=4.08, score=71.15\n",
            ".\t.\t.\t2\n",
            ".\t.\t.\t4\n",
            ".\t2\t8\t4\n",
            ".\t4\t16\t2\n",
            "\n",
            "Step 17, action=1, reward=8.08, score=79.23\n",
            ".\t.\t.\t.\n",
            ".\t4\t.\t2\n",
            ".\t2\t8\t8\n",
            ".\t4\t16\t2\n",
            "\n",
            "Step 18, action=3, reward=16.08, score=95.31\n",
            ".\t.\t2\t.\n",
            ".\t.\t4\t2\n",
            ".\t.\t2\t16\n",
            ".\t4\t16\t2\n",
            "\n",
            "Step 19, action=1, reward=-1.92, score=93.39\n",
            ".\t.\t2\t.\n",
            ".\t.\t4\t2\n",
            ".\t.\t2\t16\n",
            ".\t4\t16\t2\n",
            "\n",
            "Step 20, action=3, reward=0.07, score=93.46\n",
            ".\t2\t.\t2\n",
            ".\t.\t4\t2\n",
            ".\t.\t2\t16\n",
            ".\t4\t16\t2\n",
            "\n",
            "Step 21, action=3, reward=4.07, score=97.53\n",
            ".\t.\t.\t4\n",
            ".\t.\t4\t2\n",
            ".\t.\t2\t16\n",
            "2\t4\t16\t2\n",
            "\n",
            "Step 22, action=0, reward=0.06, score=97.59\n",
            "2\t4\t4\t4\n",
            ".\t.\t2\t2\n",
            ".\t.\t16\t16\n",
            ".\t2\t.\t2\n",
            "\n",
            "Step 23, action=0, reward=0.05, score=97.64\n",
            "2\t4\t4\t4\n",
            ".\t2\t2\t2\n",
            ".\t.\t16\t16\n",
            ".\t.\t4\t2\n",
            "\n",
            "Step 24, action=2, reward=44.57, score=142.21\n",
            "2\t8\t4\t2\n",
            "4\t2\t.\t.\n",
            "32\t.\t.\t.\n",
            "4\t2\t.\t.\n",
            "\n",
            "Step 25, action=1, reward=4.07, score=146.28\n",
            "2\t.\t.\t.\n",
            "4\t2\t.\t.\n",
            "32\t8\t.\t.\n",
            "4\t4\t4\t2\n",
            "\n",
            "Step 26, action=2, reward=8.07, score=154.35\n",
            "2\t.\t.\t.\n",
            "4\t2\t4\t.\n",
            "32\t8\t.\t.\n",
            "8\t4\t2\t.\n",
            "\n",
            "Step 27, action=3, reward=0.06, score=154.41\n",
            ".\t.\t2\t2\n",
            ".\t4\t2\t4\n",
            ".\t.\t32\t8\n",
            ".\t8\t4\t2\n",
            "\n",
            "Step 28, action=0, reward=4.06, score=158.47\n",
            "2\t4\t4\t2\n",
            ".\t8\t32\t4\n",
            ".\t.\t4\t8\n",
            ".\t.\t.\t2\n",
            "\n",
            "Step 29, action=0, reward=-1.94, score=156.53\n",
            "2\t4\t4\t2\n",
            ".\t8\t32\t4\n",
            ".\t.\t4\t8\n",
            ".\t.\t.\t2\n",
            "\n",
            "Step 30, action=0, reward=-1.94, score=154.59\n",
            "2\t4\t4\t2\n",
            ".\t8\t32\t4\n",
            ".\t.\t4\t8\n",
            ".\t.\t.\t2\n",
            "\n",
            "Step 31, action=3, reward=8.06, score=162.65\n",
            ".\t2\t8\t2\n",
            ".\t8\t32\t4\n",
            ".\t.\t4\t8\n",
            ".\t.\t2\t2\n",
            "\n",
            "Step 32, action=3, reward=4.06, score=166.71\n",
            ".\t2\t8\t2\n",
            ".\t8\t32\t4\n",
            ".\t2\t4\t8\n",
            ".\t.\t.\t4\n",
            "\n",
            "Step 33, action=3, reward=-1.94, score=164.77\n",
            ".\t2\t8\t2\n",
            ".\t8\t32\t4\n",
            ".\t2\t4\t8\n",
            ".\t.\t.\t4\n",
            "\n",
            "Step 34, action=0, reward=-1.94, score=162.83\n",
            ".\t2\t8\t2\n",
            ".\t8\t32\t4\n",
            ".\t2\t4\t8\n",
            ".\t.\t.\t4\n",
            "\n",
            "Step 35, action=1, reward=0.05, score=162.88\n",
            ".\t2\t.\t2\n",
            ".\t2\t8\t4\n",
            ".\t8\t32\t8\n",
            ".\t2\t4\t4\n",
            "\n",
            "Step 36, action=3, reward=12.06, score=174.94\n",
            ".\t.\t.\t4\n",
            ".\t2\t8\t4\n",
            ".\t8\t32\t8\n",
            "2\t.\t2\t8\n",
            "\n",
            "Step 37, action=0, reward=24.07, score=199.01\n",
            "2\t2\t8\t8\n",
            ".\t8\t32\t16\n",
            ".\t.\t2\t2\n",
            ".\t.\t.\t.\n",
            "\n",
            "Step 38, action=2, reward=24.09, score=223.10\n",
            "4\t16\t.\t.\n",
            "8\t32\t16\t.\n",
            "4\t.\t.\t2\n",
            ".\t.\t.\t.\n",
            "\n",
            "Step 39, action=0, reward=0.08, score=223.18\n",
            "4\t16\t16\t2\n",
            "8\t32\t.\t.\n",
            "4\t.\t.\t.\n",
            "2\t.\t.\t.\n",
            "\n",
            "Step 40, action=2, reward=32.08, score=255.26\n",
            "4\t32\t2\t.\n",
            "8\t32\t4\t.\n",
            "4\t.\t.\t.\n",
            "2\t.\t.\t.\n",
            "\n",
            "Step 41, action=1, reward=64.58, score=319.84\n",
            "4\t.\t.\t.\n",
            "8\t.\t.\t2\n",
            "4\t.\t2\t.\n",
            "2\t64\t4\t.\n",
            "\n",
            "Step 42, action=1, reward=0.07, score=319.91\n",
            "4\t.\t.\t.\n",
            "8\t.\t.\t.\n",
            "4\t2\t2\t.\n",
            "2\t64\t4\t2\n",
            "\n",
            "Step 43, action=0, reward=0.06, score=319.97\n",
            "4\t2\t2\t2\n",
            "8\t64\t4\t.\n",
            "4\t.\t.\t.\n",
            "2\t.\t2\t.\n",
            "\n",
            "Step 44, action=3, reward=8.07, score=328.04\n",
            ".\t4\t2\t4\n",
            ".\t8\t64\t4\n",
            ".\t.\t.\t4\n",
            ".\t2\t.\t4\n",
            "\n",
            "Step 45, action=2, reward=0.06, score=328.10\n",
            "4\t2\t4\t.\n",
            "8\t64\t4\t.\n",
            "4\t2\t.\t.\n",
            "2\t4\t.\t.\n",
            "\n",
            "Step 46, action=3, reward=0.05, score=328.15\n",
            ".\t4\t2\t4\n",
            ".\t8\t64\t4\n",
            "2\t.\t4\t2\n",
            ".\t.\t2\t4\n",
            "\n",
            "Step 47, action=1, reward=8.05, score=336.20\n",
            ".\t.\t2\t.\n",
            ".\t2\t64\t8\n",
            ".\t4\t4\t2\n",
            "2\t8\t2\t4\n",
            "\n",
            "Step 48, action=3, reward=8.05, score=344.25\n",
            ".\t.\t.\t2\n",
            ".\t2\t64\t8\n",
            "2\t.\t8\t2\n",
            "2\t8\t2\t4\n",
            "\n",
            "Step 49, action=1, reward=4.05, score=348.30\n",
            ".\t.\t2\t2\n",
            ".\t.\t64\t8\n",
            ".\t2\t8\t2\n",
            "4\t8\t2\t4\n",
            "\n",
            "Step 50, action=1, reward=-1.95, score=346.35\n",
            ".\t.\t2\t2\n",
            ".\t.\t64\t8\n",
            ".\t2\t8\t2\n",
            "4\t8\t2\t4\n",
            "\n",
            "Step 51, action=2, reward=4.05, score=350.40\n",
            "4\t.\t.\t.\n",
            "64\t8\t.\t2\n",
            "2\t8\t2\t.\n",
            "4\t8\t2\t4\n",
            "\n",
            "Step 52, action=3, reward=0.04, score=350.44\n",
            ".\t.\t2\t4\n",
            ".\t64\t8\t2\n",
            ".\t2\t8\t2\n",
            "4\t8\t2\t4\n",
            "\n",
            "Step 53, action=3, reward=-1.96, score=348.48\n",
            ".\t.\t2\t4\n",
            ".\t64\t8\t2\n",
            ".\t2\t8\t2\n",
            "4\t8\t2\t4\n",
            "\n",
            "Step 54, action=0, reward=20.05, score=368.53\n",
            "4\t64\t2\t4\n",
            "2\t2\t16\t4\n",
            ".\t8\t2\t4\n",
            ".\t.\t.\t.\n",
            "\n",
            "Step 55, action=1, reward=8.05, score=376.58\n",
            "2\t.\t.\t.\n",
            ".\t64\t2\t.\n",
            "4\t2\t16\t4\n",
            "2\t8\t2\t8\n",
            "\n",
            "Step 56, action=3, reward=0.04, score=376.62\n",
            ".\t.\t.\t2\n",
            "2\t.\t64\t2\n",
            "4\t2\t16\t4\n",
            "2\t8\t2\t8\n",
            "\n",
            "Step 57, action=1, reward=4.04, score=380.66\n",
            "2\t.\t.\t.\n",
            "2\t.\t64\t4\n",
            "4\t2\t16\t4\n",
            "2\t8\t2\t8\n",
            "\n",
            "Step 58, action=0, reward=12.05, score=392.71\n",
            "4\t2\t64\t8\n",
            "4\t8\t16\t8\n",
            "2\t.\t2\t.\n",
            ".\t.\t.\t2\n",
            "\n",
            "Step 59, action=1, reward=24.06, score=416.77\n",
            ".\t.\t.\t.\n",
            "4\t.\t64\t.\n",
            "8\t2\t16\t16\n",
            "2\t8\t2\t2\n",
            "\n",
            "Step 60, action=3, reward=36.07, score=452.84\n",
            ".\t.\t.\t.\n",
            "2\t.\t4\t64\n",
            ".\t8\t2\t32\n",
            ".\t2\t8\t4\n",
            "\n",
            "Step 61, action=3, reward=0.06, score=452.90\n",
            ".\t.\t.\t.\n",
            "2\t2\t4\t64\n",
            ".\t8\t2\t32\n",
            ".\t2\t8\t4\n",
            "\n",
            "Step 62, action=2, reward=4.06, score=456.96\n",
            ".\t.\t.\t4\n",
            "4\t4\t64\t.\n",
            "8\t2\t32\t.\n",
            "2\t8\t4\t.\n",
            "\n",
            "Step 63, action=0, reward=0.05, score=457.01\n",
            "4\t4\t64\t4\n",
            "8\t2\t32\t.\n",
            "2\t8\t4\t.\n",
            ".\t.\t2\t.\n",
            "\n",
            "Step 64, action=0, reward=-1.95, score=455.06\n",
            "4\t4\t64\t4\n",
            "8\t2\t32\t.\n",
            "2\t8\t4\t.\n",
            ".\t.\t2\t.\n",
            "\n",
            "Step 65, action=3, reward=8.05, score=463.11\n",
            ".\t8\t64\t4\n",
            "2\t8\t2\t32\n",
            ".\t2\t8\t4\n",
            ".\t.\t.\t2\n",
            "\n",
            "Step 66, action=1, reward=16.05, score=479.16\n",
            "2\t.\t.\t4\n",
            ".\t.\t64\t32\n",
            ".\t16\t2\t4\n",
            "2\t2\t8\t2\n",
            "\n",
            "Step 67, action=2, reward=4.05, score=483.21\n",
            "2\t4\t.\t.\n",
            "64\t32\t.\t.\n",
            "16\t2\t4\t4\n",
            "4\t8\t2\t.\n",
            "\n",
            "Step 68, action=1, reward=0.04, score=483.25\n",
            "2\t4\t.\t.\n",
            "64\t32\t.\t.\n",
            "16\t2\t4\t2\n",
            "4\t8\t2\t4\n",
            "\n",
            "Step 69, action=1, reward=-1.96, score=481.29\n",
            "2\t4\t.\t.\n",
            "64\t32\t.\t.\n",
            "16\t2\t4\t2\n",
            "4\t8\t2\t4\n",
            "\n",
            "Step 70, action=3, reward=0.03, score=481.32\n",
            ".\t2\t2\t4\n",
            ".\t.\t64\t32\n",
            "16\t2\t4\t2\n",
            "4\t8\t2\t4\n",
            "\n",
            "Step 71, action=1, reward=4.03, score=485.35\n",
            ".\t.\t2\t4\n",
            "2\t.\t64\t32\n",
            "16\t4\t4\t2\n",
            "4\t8\t2\t4\n",
            "\n",
            "Step 72, action=2, reward=8.03, score=493.38\n",
            "2\t4\t.\t2\n",
            "2\t64\t32\t.\n",
            "16\t8\t2\t.\n",
            "4\t8\t2\t4\n",
            "\n",
            "Step 73, action=0, reward=24.05, score=517.43\n",
            "4\t4\t32\t2\n",
            "16\t64\t4\t4\n",
            "4\t16\t.\t.\n",
            ".\t.\t.\t2\n",
            "\n",
            "Step 74, action=0, reward=0.04, score=517.47\n",
            "4\t4\t32\t2\n",
            "16\t64\t4\t4\n",
            "4\t16\t.\t2\n",
            ".\t2\t.\t.\n",
            "\n",
            "Step 75, action=0, reward=-1.96, score=515.51\n",
            "4\t4\t32\t2\n",
            "16\t64\t4\t4\n",
            "4\t16\t.\t2\n",
            ".\t2\t.\t.\n",
            "\n",
            "Step 76, action=3, reward=16.05, score=531.56\n",
            "2\t8\t32\t2\n",
            ".\t16\t64\t8\n",
            ".\t4\t16\t2\n",
            ".\t.\t.\t2\n",
            "\n",
            "Step 77, action=0, reward=4.05, score=535.61\n",
            "2\t8\t32\t2\n",
            ".\t16\t64\t8\n",
            ".\t4\t16\t4\n",
            ".\t2\t.\t.\n",
            "\n",
            "Step 78, action=1, reward=0.04, score=535.65\n",
            "2\t8\t.\t.\n",
            ".\t16\t32\t2\n",
            ".\t4\t64\t8\n",
            "2\t2\t16\t4\n",
            "\n",
            "Step 79, action=3, reward=4.04, score=539.69\n",
            "2\t.\t2\t8\n",
            ".\t16\t32\t2\n",
            ".\t4\t64\t8\n",
            ".\t4\t16\t4\n",
            "\n",
            "Step 80, action=3, reward=4.04, score=543.73\n",
            "2\t.\t4\t8\n",
            ".\t16\t32\t2\n",
            ".\t4\t64\t8\n",
            ".\t4\t16\t4\n",
            "\n",
            "Step 81, action=0, reward=8.04, score=551.77\n",
            "2\t16\t4\t8\n",
            ".\t8\t32\t2\n",
            ".\t.\t64\t8\n",
            "2\t.\t16\t4\n",
            "\n",
            "Step 82, action=3, reward=0.03, score=551.80\n",
            "2\t16\t4\t8\n",
            ".\t8\t32\t2\n",
            ".\t2\t64\t8\n",
            ".\t2\t16\t4\n",
            "\n",
            "Step 83, action=3, reward=-1.97, score=549.83\n",
            "2\t16\t4\t8\n",
            ".\t8\t32\t2\n",
            ".\t2\t64\t8\n",
            ".\t2\t16\t4\n",
            "\n",
            "Step 84, action=0, reward=4.03, score=553.86\n",
            "2\t16\t4\t8\n",
            "2\t8\t32\t2\n",
            ".\t4\t64\t8\n",
            ".\t.\t16\t4\n",
            "\n",
            "Step 85, action=0, reward=4.03, score=557.89\n",
            "4\t16\t4\t8\n",
            ".\t8\t32\t2\n",
            ".\t4\t64\t8\n",
            "2\t.\t16\t4\n",
            "\n",
            "Step 86, action=0, reward=0.02, score=557.91\n",
            "4\t16\t4\t8\n",
            "2\t8\t32\t2\n",
            ".\t4\t64\t8\n",
            ".\t2\t16\t4\n",
            "\n",
            "Step 87, action=1, reward=0.01, score=557.92\n",
            ".\t16\t4\t8\n",
            "2\t8\t32\t2\n",
            "4\t4\t64\t8\n",
            "2\t2\t16\t4\n",
            "\n",
            "Step 88, action=3, reward=12.02, score=569.94\n",
            ".\t16\t4\t8\n",
            "2\t8\t32\t2\n",
            ".\t8\t64\t8\n",
            "2\t4\t16\t4\n",
            "\n",
            "Step 89, action=3, reward=-1.98, score=567.96\n",
            ".\t16\t4\t8\n",
            "2\t8\t32\t2\n",
            ".\t8\t64\t8\n",
            "2\t4\t16\t4\n",
            "\n",
            "Step 90, action=0, reward=20.03, score=587.99\n",
            "4\t16\t4\t8\n",
            "2\t16\t32\t2\n",
            ".\t4\t64\t8\n",
            ".\t.\t16\t4\n",
            "\n",
            "Step 91, action=3, reward=-1.97, score=586.02\n",
            "4\t16\t4\t8\n",
            "2\t16\t32\t2\n",
            ".\t4\t64\t8\n",
            ".\t.\t16\t4\n",
            "\n",
            "Step 92, action=3, reward=-1.97, score=584.05\n",
            "4\t16\t4\t8\n",
            "2\t16\t32\t2\n",
            ".\t4\t64\t8\n",
            ".\t.\t16\t4\n",
            "\n",
            "Step 93, action=0, reward=32.03, score=616.08\n",
            "4\t32\t4\t8\n",
            "2\t4\t32\t2\n",
            "2\t.\t64\t8\n",
            ".\t.\t16\t4\n",
            "\n",
            "Step 94, action=3, reward=0.02, score=616.10\n",
            "4\t32\t4\t8\n",
            "2\t4\t32\t2\n",
            ".\t2\t64\t8\n",
            ".\t2\t16\t4\n",
            "\n",
            "Step 95, action=3, reward=-1.98, score=614.12\n",
            "4\t32\t4\t8\n",
            "2\t4\t32\t2\n",
            ".\t2\t64\t8\n",
            ".\t2\t16\t4\n",
            "\n",
            "Step 96, action=3, reward=-1.98, score=612.14\n",
            "4\t32\t4\t8\n",
            "2\t4\t32\t2\n",
            ".\t2\t64\t8\n",
            ".\t2\t16\t4\n",
            "\n",
            "Step 97, action=3, reward=-1.98, score=610.16\n",
            "4\t32\t4\t8\n",
            "2\t4\t32\t2\n",
            ".\t2\t64\t8\n",
            ".\t2\t16\t4\n",
            "\n",
            "Step 98, action=1, reward=4.02, score=614.18\n",
            "2\t.\t4\t8\n",
            ".\t32\t32\t2\n",
            "4\t4\t64\t8\n",
            "2\t4\t16\t4\n",
            "\n",
            "Step 99, action=0, reward=8.02, score=622.20\n",
            "2\t32\t4\t8\n",
            "4\t8\t32\t2\n",
            "2\t.\t64\t8\n",
            ".\t2\t16\t4\n",
            "\n",
            "Step 100, action=3, reward=0.01, score=622.21\n",
            "2\t32\t4\t8\n",
            "4\t8\t32\t2\n",
            ".\t2\t64\t8\n",
            "2\t2\t16\t4\n",
            "\n",
            "Step 101, action=1, reward=4.01, score=626.22\n",
            ".\t2\t4\t8\n",
            "2\t32\t32\t2\n",
            "4\t8\t64\t8\n",
            "2\t4\t16\t4\n",
            "\n",
            "Step 102, action=1, reward=-1.99, score=624.23\n",
            ".\t2\t4\t8\n",
            "2\t32\t32\t2\n",
            "4\t8\t64\t8\n",
            "2\t4\t16\t4\n",
            "\n",
            "Step 103, action=3, reward=64.01, score=688.24\n",
            "2\t2\t4\t8\n",
            ".\t2\t64\t2\n",
            "4\t8\t64\t8\n",
            "2\t4\t16\t4\n",
            "\n",
            "Step 104, action=3, reward=4.01, score=692.25\n",
            "2\t4\t4\t8\n",
            ".\t2\t64\t2\n",
            "4\t8\t64\t8\n",
            "2\t4\t16\t4\n",
            "\n",
            "Step 105, action=1, reward=128.51, score=820.76\n",
            ".\t4\t2\t8\n",
            "2\t2\t4\t2\n",
            "4\t8\t128\t8\n",
            "2\t4\t16\t4\n",
            "\n",
            "Step 106, action=1, reward=-1.99, score=818.77\n",
            ".\t4\t2\t8\n",
            "2\t2\t4\t2\n",
            "4\t8\t128\t8\n",
            "2\t4\t16\t4\n",
            "\n",
            "Step 107, action=3, reward=4.01, score=822.78\n",
            ".\t4\t2\t8\n",
            "2\t4\t4\t2\n",
            "4\t8\t128\t8\n",
            "2\t4\t16\t4\n",
            "\n",
            "Step 108, action=0, reward=8.01, score=830.79\n",
            "2\t8\t2\t8\n",
            "4\t8\t4\t2\n",
            "2\t4\t128\t8\n",
            ".\t2\t16\t4\n",
            "\n",
            "Step 109, action=0, reward=16.01, score=846.80\n",
            "2\t16\t2\t8\n",
            "4\t4\t4\t2\n",
            "2\t2\t128\t8\n",
            "2\t.\t16\t4\n",
            "\n",
            "Step 110, action=0, reward=4.01, score=850.81\n",
            "2\t16\t2\t8\n",
            "4\t4\t4\t2\n",
            "4\t2\t128\t8\n",
            ".\t2\t16\t4\n",
            "\n",
            "Step 111, action=0, reward=12.02, score=862.83\n",
            "2\t16\t2\t8\n",
            "8\t4\t4\t2\n",
            ".\t4\t128\t8\n",
            ".\t2\t16\t4\n",
            "\n",
            "Step 112, action=1, reward=8.02, score=870.85\n",
            ".\t.\t2\t8\n",
            "2\t16\t4\t2\n",
            "2\t8\t128\t8\n",
            "8\t2\t16\t4\n",
            "\n",
            "Step 113, action=1, reward=4.02, score=874.87\n",
            "2\t.\t2\t8\n",
            ".\t16\t4\t2\n",
            "4\t8\t128\t8\n",
            "8\t2\t16\t4\n",
            "\n",
            "Step 114, action=1, reward=0.01, score=874.88\n",
            "2\t.\t2\t8\n",
            "2\t16\t4\t2\n",
            "4\t8\t128\t8\n",
            "8\t2\t16\t4\n",
            "\n",
            "Step 115, action=1, reward=4.01, score=878.89\n",
            ".\t2\t2\t8\n",
            "4\t16\t4\t2\n",
            "4\t8\t128\t8\n",
            "8\t2\t16\t4\n",
            "\n",
            "Step 116, action=1, reward=8.01, score=886.90\n",
            ".\t2\t2\t8\n",
            "2\t16\t4\t2\n",
            "8\t8\t128\t8\n",
            "8\t2\t16\t4\n",
            "\n",
            "Step 117, action=3, reward=20.02, score=906.92\n",
            "4\t.\t4\t8\n",
            "2\t16\t4\t2\n",
            ".\t16\t128\t8\n",
            "8\t2\t16\t4\n",
            "\n",
            "Step 118, action=0, reward=40.03, score=946.95\n",
            "4\t32\t8\t8\n",
            "2\t2\t128\t2\n",
            "8\t2\t16\t8\n",
            ".\t.\t.\t4\n",
            "\n",
            "Step 119, action=0, reward=4.03, score=950.98\n",
            "4\t32\t8\t8\n",
            "2\t4\t128\t2\n",
            "8\t.\t16\t8\n",
            ".\t4\t.\t4\n",
            "\n",
            "Step 120, action=3, reward=24.04, score=975.02\n",
            "2\t4\t32\t16\n",
            "2\t4\t128\t2\n",
            ".\t8\t16\t8\n",
            ".\t.\t.\t8\n",
            "\n",
            "Step 121, action=0, reward=28.06, score=1003.08\n",
            "4\t8\t32\t16\n",
            ".\t8\t128\t2\n",
            ".\t.\t16\t16\n",
            ".\t.\t.\t2\n",
            "\n",
            "Step 122, action=3, reward=32.06, score=1035.14\n",
            "4\t8\t32\t16\n",
            ".\t8\t128\t2\n",
            ".\t.\t.\t32\n",
            ".\t2\t.\t2\n",
            "\n",
            "Step 123, action=0, reward=16.06, score=1051.20\n",
            "4\t16\t32\t16\n",
            ".\t2\t128\t2\n",
            ".\t.\t2\t32\n",
            ".\t.\t.\t2\n",
            "\n",
            "Step 124, action=2, reward=0.05, score=1051.25\n",
            "4\t16\t32\t16\n",
            "2\t128\t2\t.\n",
            "2\t32\t2\t.\n",
            "2\t.\t.\t.\n",
            "\n",
            "Step 125, action=1, reward=8.06, score=1059.31\n",
            ".\t2\t.\t.\n",
            "4\t16\t.\t.\n",
            "2\t128\t32\t.\n",
            "4\t32\t4\t16\n",
            "\n",
            "Step 126, action=2, reward=0.05, score=1059.36\n",
            "2\t.\t.\t.\n",
            "4\t16\t.\t2\n",
            "2\t128\t32\t.\n",
            "4\t32\t4\t16\n",
            "\n",
            "Step 127, action=3, reward=0.04, score=1059.40\n",
            ".\t.\t2\t2\n",
            ".\t4\t16\t2\n",
            ".\t2\t128\t32\n",
            "4\t32\t4\t16\n",
            "\n",
            "Step 128, action=2, reward=4.04, score=1063.44\n",
            "4\t.\t.\t.\n",
            "4\t16\t2\t2\n",
            "2\t128\t32\t.\n",
            "4\t32\t4\t16\n",
            "\n",
            "Step 129, action=3, reward=4.04, score=1067.48\n",
            ".\t.\t.\t4\n",
            "2\t4\t16\t4\n",
            ".\t2\t128\t32\n",
            "4\t32\t4\t16\n",
            "\n",
            "Step 130, action=1, reward=8.04, score=1075.52\n",
            ".\t.\t.\t.\n",
            "2\t4\t16\t8\n",
            "2\t2\t128\t32\n",
            "4\t32\t4\t16\n",
            "\n",
            "Step 131, action=2, reward=4.04, score=1079.56\n",
            ".\t.\t2\t.\n",
            "2\t4\t16\t8\n",
            "4\t128\t32\t.\n",
            "4\t32\t4\t16\n",
            "\n",
            "Step 132, action=2, reward=0.03, score=1079.59\n",
            "2\t4\t.\t.\n",
            "2\t4\t16\t8\n",
            "4\t128\t32\t.\n",
            "4\t32\t4\t16\n",
            "\n",
            "Step 133, action=3, reward=0.02, score=1079.61\n",
            ".\t.\t2\t4\n",
            "2\t4\t16\t8\n",
            "2\t4\t128\t32\n",
            "4\t32\t4\t16\n",
            "\n",
            "Step 134, action=3, reward=-1.98, score=1077.63\n",
            ".\t.\t2\t4\n",
            "2\t4\t16\t8\n",
            "2\t4\t128\t32\n",
            "4\t32\t4\t16\n",
            "\n",
            "Step 135, action=0, reward=12.03, score=1089.66\n",
            "4\t8\t2\t4\n",
            "4\t32\t16\t8\n",
            "4\t.\t128\t32\n",
            ".\t.\t4\t16\n",
            "\n",
            "Step 136, action=3, reward=0.02, score=1089.68\n",
            "4\t8\t2\t4\n",
            "4\t32\t16\t8\n",
            ".\t4\t128\t32\n",
            "2\t.\t4\t16\n",
            "\n",
            "Step 137, action=3, reward=0.01, score=1089.69\n",
            "4\t8\t2\t4\n",
            "4\t32\t16\t8\n",
            ".\t4\t128\t32\n",
            "2\t2\t4\t16\n",
            "\n",
            "Step 138, action=3, reward=4.01, score=1093.70\n",
            "4\t8\t2\t4\n",
            "4\t32\t16\t8\n",
            "2\t4\t128\t32\n",
            ".\t4\t4\t16\n",
            "\n",
            "Step 139, action=0, reward=16.02, score=1109.72\n",
            "8\t8\t2\t4\n",
            "2\t32\t16\t8\n",
            ".\t8\t128\t32\n",
            "2\t.\t4\t16\n",
            "\n",
            "Step 140, action=3, reward=16.02, score=1125.74\n",
            ".\t16\t2\t4\n",
            "2\t32\t16\t8\n",
            "2\t8\t128\t32\n",
            ".\t2\t4\t16\n",
            "\n",
            "Step 141, action=1, reward=4.02, score=1129.76\n",
            "2\t16\t2\t4\n",
            ".\t32\t16\t8\n",
            ".\t8\t128\t32\n",
            "4\t2\t4\t16\n",
            "\n",
            "Step 142, action=1, reward=0.01, score=1129.77\n",
            ".\t16\t2\t4\n",
            "4\t32\t16\t8\n",
            "2\t8\t128\t32\n",
            "4\t2\t4\t16\n",
            "\n",
            "Step 143, action=1, reward=-1.99, score=1127.78\n",
            ".\t16\t2\t4\n",
            "4\t32\t16\t8\n",
            "2\t8\t128\t32\n",
            "4\t2\t4\t16\n",
            "\n",
            "Step 144, action=2, reward=0.00, score=1127.78\n",
            "16\t2\t4\t2\n",
            "4\t32\t16\t8\n",
            "2\t8\t128\t32\n",
            "4\t2\t4\t16\n",
            "\n",
            "Episode finished.\n",
            "Final score: 1127.7799999999986, max tile: 128\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from stable_baselines3 import PPO\n",
        "\n",
        "# ---- Settings ----\n",
        "NUM_EPISODES = 30\n",
        "MODEL_PATH = \"ppo_2048_v2_simple\"  # change if your model name is different\n",
        "\n",
        "# ---- Helper: run one episode with a given policy ----\n",
        "def run_episode_with_policy(env, policy_fn, render=False):\n",
        "    obs, info = env.reset()\n",
        "    done = False\n",
        "    total_reward = 0.0\n",
        "    final_score = 0.0\n",
        "    max_tile = 0\n",
        "\n",
        "    while not done:\n",
        "        action = policy_fn(obs, env)\n",
        "        obs, reward, terminated, truncated, info = env.step(action)\n",
        "        done = terminated or truncated\n",
        "\n",
        "        total_reward += reward\n",
        "        final_score = info[\"score\"]\n",
        "        max_tile = info[\"max_tile\"]\n",
        "\n",
        "        if render:\n",
        "            print(env._board_to_string())\n",
        "            print(f\"Action: {action}, Reward: {reward:.2f}, Score: {final_score:.2f}\")\n",
        "            print(\"-\" * 40)\n",
        "\n",
        "    return total_reward, final_score, max_tile\n",
        "\n",
        "# ---- Random policy ----\n",
        "def random_policy(obs, env):\n",
        "    return env.action_space.sample()\n",
        "\n",
        "# ---- PPO policy ----\n",
        "print(\"Loading PPO model...\")\n",
        "ppo_model = PPO.load(MODEL_PATH)\n",
        "\n",
        "def ppo_policy(obs, env):\n",
        "    action, _ = ppo_model.predict(obs, deterministic=True)\n",
        "    return int(action)\n",
        "\n",
        "# ---- Evaluate both ----\n",
        "def evaluate_policy(name, policy_fn, num_episodes=NUM_EPISODES, render=False):\n",
        "    rewards = []\n",
        "    scores = []\n",
        "    max_tiles = []\n",
        "\n",
        "    for ep in range(num_episodes):\n",
        "        env = Game2048EnvV2()  # new fresh env each episode\n",
        "        total_r, score, max_tile = run_episode_with_policy(env, policy_fn, render=False)\n",
        "        rewards.append(total_r)\n",
        "        scores.append(score)\n",
        "        max_tiles.append(max_tile)\n",
        "\n",
        "    print(f\"\\n=== {name} over {num_episodes} episodes ===\")\n",
        "    print(f\"Avg total reward: {np.mean(rewards):.2f} ¬± {np.std(rewards):.2f}\")\n",
        "    print(f\"Avg final score:  {np.mean(scores):.2f} ¬± {np.std(scores):.2f}\")\n",
        "    print(f\"Avg max tile:     {np.mean(max_tiles):.1f}\")\n",
        "    print(f\"Max of max tiles: {np.max(max_tiles)}\")\n",
        "\n",
        "    return rewards, scores, max_tiles\n",
        "\n",
        "# Run comparison\n",
        "rand_rewards, rand_scores, rand_tiles = evaluate_policy(\"Random policy\", random_policy)\n",
        "ppo_rewards,  ppo_scores,  ppo_tiles  = evaluate_policy(\"PPO policy\",    ppo_policy)\n",
        "\n",
        "print(\"\\nDone.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 530
        },
        "id": "rSsC-Sy7PiI6",
        "outputId": "92a89d28-6184-4513-a15e-d6a6a51152ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading PPO model...\n",
            "\n",
            "=== Random policy over 30 episodes ===\n",
            "Avg total reward: 991.10 ¬± 475.12\n",
            "Avg final score:  991.10 ¬± 475.12\n",
            "Avg max tile:     104.5\n",
            "Max of max tiles: 256\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-191529638.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;31m# Run comparison\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0mrand_rewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrand_scores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrand_tiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_policy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Random policy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_policy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m \u001b[0mppo_rewards\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mppo_scores\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mppo_tiles\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mevaluate_policy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"PPO policy\"\u001b[0m\u001b[0;34m,\u001b[0m    \u001b[0mppo_policy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nDone.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-191529638.py\u001b[0m in \u001b[0;36mevaluate_policy\u001b[0;34m(name, policy_fn, num_episodes, render)\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_episodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m         \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGame2048EnvV2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# new fresh env each episode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m         \u001b[0mtotal_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_tile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_episode_with_policy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrender\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0mrewards\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_r\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-191529638.py\u001b[0m in \u001b[0;36mrun_episode_with_policy\u001b[0;34m(env, policy_fn, render)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicy_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mterminated\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-191529638.py\u001b[0m in \u001b[0;36mppo_policy\u001b[0;34m(obs, env)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mppo_policy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mppo_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/stable_baselines3/common/base_class.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, observation, state, episode_start, deterministic)\u001b[0m\n\u001b[1;32m    555\u001b[0m             \u001b[0;34m(\u001b[0m\u001b[0mused\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrecurrent\u001b[0m \u001b[0mpolicies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \"\"\"\n\u001b[0;32m--> 557\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpolicy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobservation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepisode_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mset_random_seed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/stable_baselines3/common/policies.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, observation, state, episode_start, deterministic)\u001b[0m\n\u001b[1;32m    368\u001b[0m             \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdeterministic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdeterministic\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0;31m# Convert to numpy, and reshape to the original action shape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 370\u001b[0;31m         \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mactions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc, assignment]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    371\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    372\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maction_space\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mspaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import gymnasium as gym\n",
        "from gymnasium import spaces\n",
        "\n",
        "class Game2048EnvV3(gym.Env):\n",
        "    \"\"\"\n",
        "    Simple, stable 2048 env for PPO.\n",
        "\n",
        "    - Obs: 4x4 grid, exponents / 15.0 in [0, 1]\n",
        "    - Action: 0=up,1=down,2=left,3=right\n",
        "    - Reward:\n",
        "        * (sum of merged tile values) / 32.0\n",
        "        * -1 for invalid move (no board change)\n",
        "    \"\"\"\n",
        "\n",
        "    metadata = {\"render_modes\": [\"ansi\"], \"render_fps\": 60}\n",
        "\n",
        "    def __init__(self, render_mode=None, target_tile=2048):\n",
        "        super().__init__()\n",
        "        self.board_size = 4\n",
        "        self.target_tile = target_tile\n",
        "\n",
        "        self.observation_space = spaces.Box(\n",
        "            low=0.0,\n",
        "            high=1.0,\n",
        "            shape=(self.board_size, self.board_size),\n",
        "            dtype=np.float32,\n",
        "        )\n",
        "        self.action_space = spaces.Discrete(4)\n",
        "\n",
        "        self.render_mode = render_mode\n",
        "        self.board = np.zeros((self.board_size, self.board_size), dtype=np.int32)\n",
        "        self.score = 0.0\n",
        "        self.rng = np.random.default_rng()\n",
        "\n",
        "    # ---------- Helpers ----------\n",
        "    def _get_obs(self):\n",
        "        return self.board.astype(np.float32) / 15.0\n",
        "\n",
        "    def _slide_and_merge_line(self, line):\n",
        "        non_zero = line[line != 0].tolist()\n",
        "        new = []\n",
        "        merged_value = 0\n",
        "        i = 0\n",
        "        while i < len(non_zero):\n",
        "            if i + 1 < len(non_zero) and non_zero[i] == non_zero[i+1]:\n",
        "                exp = non_zero[i] + 1\n",
        "                new.append(exp)\n",
        "                merged_value += 2 ** exp\n",
        "                i += 2\n",
        "            else:\n",
        "                new.append(non_zero[i])\n",
        "                i += 1\n",
        "        new += [0] * (len(line) - len(new))\n",
        "        return np.array(new, dtype=np.int32), merged_value\n",
        "\n",
        "    def _add_random_tile(self):\n",
        "        empties = list(zip(*np.where(self.board == 0)))\n",
        "        if not empties:\n",
        "            return\n",
        "        r, c = empties[self.rng.integers(len(empties))]\n",
        "        self.board[r, c] = 1 if self.rng.random() < 0.9 else 2  # 2 or 4\n",
        "\n",
        "    def _can_move(self):\n",
        "        if np.any(self.board == 0):\n",
        "            return True\n",
        "        for r in range(self.board_size):\n",
        "            for c in range(self.board_size - 1):\n",
        "                if self.board[r, c] == self.board[r, c+1]:\n",
        "                    return True\n",
        "        for c in range(self.board_size):\n",
        "            for r in range(self.board_size - 1):\n",
        "                if self.board[r, c] == self.board[r+1, c]:\n",
        "                    return True\n",
        "        return False\n",
        "\n",
        "    def _get_max_tile(self):\n",
        "        exp = int(self.board.max())\n",
        "        return 0 if exp == 0 else 2 ** exp\n",
        "\n",
        "    # ---------- Gym API ----------\n",
        "    def reset(self, seed=None, options=None):\n",
        "        super().reset(seed=seed)\n",
        "        if seed is not None:\n",
        "            self.rng = np.random.default_rng(seed)\n",
        "\n",
        "        self.board[:] = 0\n",
        "        self.score = 0.0\n",
        "\n",
        "        self._add_random_tile()\n",
        "        self._add_random_tile()\n",
        "\n",
        "        return self._get_obs(), {\"score\": self.score, \"max_tile\": self._get_max_tile()}\n",
        "\n",
        "    def step(self, action):\n",
        "        assert self.action_space.contains(action), \"Invalid action\"\n",
        "\n",
        "        old_board = self.board.copy()\n",
        "        merged_value = 0\n",
        "\n",
        "        if action == 0:  # up\n",
        "            for c in range(self.board_size):\n",
        "                new_line, mv = self._slide_and_merge_line(self.board[:, c])\n",
        "                self.board[:, c] = new_line\n",
        "                merged_value += mv\n",
        "        elif action == 1:  # down\n",
        "            for c in range(self.board_size):\n",
        "                new_line, mv = self._slide_and_merge_line(self.board[:, c][::-1])\n",
        "                self.board[:, c] = new_line[::-1]\n",
        "                merged_value += mv\n",
        "        elif action == 2:  # left\n",
        "            for r in range(self.board_size):\n",
        "                new_line, mv = self._slide_and_merge_line(self.board[r])\n",
        "                self.board[r] = new_line\n",
        "                merged_value += mv\n",
        "        elif action == 3:  # right\n",
        "            for r in range(self.board_size):\n",
        "                new_line, mv = self._slide_and_merge_line(self.board[r][::-1])\n",
        "                self.board[r] = new_line[::-1]\n",
        "                merged_value += mv\n",
        "\n",
        "        moved = not np.array_equal(old_board, self.board)\n",
        "\n",
        "        reward = 0.0\n",
        "        if moved:\n",
        "            self._add_random_tile()\n",
        "            # scale down raw 2048 reward to keep PPO stable\n",
        "            reward += merged_value / 32.0\n",
        "        else:\n",
        "            # strong penalty for useless move\n",
        "            reward -= 1.0\n",
        "\n",
        "        self.score += merged_value  # human-style score for reporting\n",
        "\n",
        "        max_tile = self._get_max_tile()\n",
        "        terminated = (not self._can_move()) or (max_tile >= self.target_tile)\n",
        "        truncated = False\n",
        "\n",
        "        obs = self._get_obs()\n",
        "        info = {\"score\": self.score, \"max_tile\": max_tile}\n",
        "        return obs, reward, terminated, truncated, info\n",
        "\n",
        "    def _board_to_string(self):\n",
        "        rows = []\n",
        "        for row in self.board:\n",
        "            r = []\n",
        "            for exp in row:\n",
        "                r.append(\".\" if exp == 0 else str(2 ** exp))\n",
        "            rows.append(\"\\t\".join(r))\n",
        "        return \"\\n\".join(rows)\n"
      ],
      "metadata": {
        "id": "H7B5PM1NVbPv"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from stable_baselines3 import PPO\n",
        "\n",
        "env = Game2048EnvV3()\n",
        "\n",
        "policy_kwargs = dict(\n",
        "    net_arch=[dict(pi=[256, 256, 256],\n",
        "                   vf=[256, 256, 256])]\n",
        ")\n",
        "\n",
        "model = PPO(\n",
        "    \"MlpPolicy\",\n",
        "    env,\n",
        "    policy_kwargs=policy_kwargs,\n",
        "    learning_rate=1e-4,   # smaller LR\n",
        "    n_steps=4096,         # more rollout per update\n",
        "    batch_size=512,\n",
        "    n_epochs=20,          # reuse data more\n",
        "    gamma=0.99,\n",
        "    clip_range=0.1,\n",
        "    ent_coef=0.1,         # stronger exploration\n",
        "    target_kl=0.02,\n",
        "    verbose=1,\n",
        ")\n",
        "\n",
        "model.learn(total_timesteps=2_000_000)  # 2M instead of 500k\n",
        "model.save(\"ppo_2048_v3_big\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O0p7Gt_JVepb",
        "outputId": "6553513b-af84-4ce1-bc1e-4488a6331139"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
            "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
            "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n",
            "/usr/local/lib/python3.12/dist-packages/stable_baselines3/common/policies.py:486: UserWarning: As shared layers in the mlp_extractor are removed since SB3 v1.8.0, you should now pass directly a dictionary and not a list (net_arch=dict(pi=..., vf=...) instead of net_arch=[dict(pi=..., vf=...)])\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "Wrapping the env with a `Monitor` wrapper\n",
            "Wrapping the env in a DummyVecEnv.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n",
            "/usr/local/lib/python3.12/dist-packages/stable_baselines3/common/on_policy_algorithm.py:150: UserWarning: You are trying to run PPO on the GPU, but it is primarily intended to run on the CPU when not using a CNN policy (you are using ActorCriticPolicy which should be a MlpPolicy). See https://github.com/DLR-RM/stable-baselines3/issues/1245 for more info. You can pass `device='cpu'` or `export CUDA_VISIBLE_DEVICES=` to force using the CPU.Note: The model will train, but the GPU utilization will be poor and the training might take longer than on CPU.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/jupyter_client/session.py:203: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
            "  return datetime.utcnow().replace(tzinfo=utc)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "|    value_loss           | 8.07         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 121          |\n",
            "|    ep_rew_mean          | 18.5         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 252          |\n",
            "|    time_elapsed         | 1865         |\n",
            "|    total_timesteps      | 1032192      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016753317 |\n",
            "|    clip_fraction        | 0.0377       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.461        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.19         |\n",
            "|    n_updates            | 5020         |\n",
            "|    policy_gradient_loss | -0.00353     |\n",
            "|    value_loss           | 7.36         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 124          |\n",
            "|    ep_rew_mean          | 19.1         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 253          |\n",
            "|    time_elapsed         | 1873         |\n",
            "|    total_timesteps      | 1036288      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016772728 |\n",
            "|    clip_fraction        | 0.0421       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.429        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.37         |\n",
            "|    n_updates            | 5040         |\n",
            "|    policy_gradient_loss | -0.00357     |\n",
            "|    value_loss           | 7.58         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 120          |\n",
            "|    ep_rew_mean          | 17.8         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 254          |\n",
            "|    time_elapsed         | 1880         |\n",
            "|    total_timesteps      | 1040384      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016890832 |\n",
            "|    clip_fraction        | 0.0463       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.552        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 2.58         |\n",
            "|    n_updates            | 5060         |\n",
            "|    policy_gradient_loss | -0.00444     |\n",
            "|    value_loss           | 6.65         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 126         |\n",
            "|    ep_rew_mean          | 18.5        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 553         |\n",
            "|    iterations           | 255         |\n",
            "|    time_elapsed         | 1888        |\n",
            "|    total_timesteps      | 1044480     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001037695 |\n",
            "|    clip_fraction        | 0.0132      |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.29       |\n",
            "|    explained_variance   | 0.552       |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 3.52        |\n",
            "|    n_updates            | 5080        |\n",
            "|    policy_gradient_loss | -0.00287    |\n",
            "|    value_loss           | 7.62        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 129          |\n",
            "|    ep_rew_mean          | 18.9         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 256          |\n",
            "|    time_elapsed         | 1895         |\n",
            "|    total_timesteps      | 1048576      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018641459 |\n",
            "|    clip_fraction        | 0.0685       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.595        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 2.87         |\n",
            "|    n_updates            | 5100         |\n",
            "|    policy_gradient_loss | -0.00471     |\n",
            "|    value_loss           | 7.08         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 131          |\n",
            "|    ep_rew_mean          | 19.6         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 257          |\n",
            "|    time_elapsed         | 1903         |\n",
            "|    total_timesteps      | 1052672      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0014167677 |\n",
            "|    clip_fraction        | 0.0313       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.484        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.86         |\n",
            "|    n_updates            | 5120         |\n",
            "|    policy_gradient_loss | -0.00366     |\n",
            "|    value_loss           | 8.42         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 133          |\n",
            "|    ep_rew_mean          | 21.2         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 258          |\n",
            "|    time_elapsed         | 1910         |\n",
            "|    total_timesteps      | 1056768      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015226618 |\n",
            "|    clip_fraction        | 0.0434       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.28        |\n",
            "|    explained_variance   | 0.535        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.12         |\n",
            "|    n_updates            | 5140         |\n",
            "|    policy_gradient_loss | -0.00387     |\n",
            "|    value_loss           | 6.63         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 131          |\n",
            "|    ep_rew_mean          | 20.9         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 259          |\n",
            "|    time_elapsed         | 1918         |\n",
            "|    total_timesteps      | 1060864      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0014990314 |\n",
            "|    clip_fraction        | 0.0359       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.28        |\n",
            "|    explained_variance   | 0.428        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 4.6          |\n",
            "|    n_updates            | 5160         |\n",
            "|    policy_gradient_loss | -0.00333     |\n",
            "|    value_loss           | 9.87         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 134          |\n",
            "|    ep_rew_mean          | 21.9         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 260          |\n",
            "|    time_elapsed         | 1925         |\n",
            "|    total_timesteps      | 1064960      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0012088905 |\n",
            "|    clip_fraction        | 0.0314       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.473        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 2.53         |\n",
            "|    n_updates            | 5180         |\n",
            "|    policy_gradient_loss | -0.00274     |\n",
            "|    value_loss           | 7.08         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 127          |\n",
            "|    ep_rew_mean          | 20.6         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 261          |\n",
            "|    time_elapsed         | 1932         |\n",
            "|    total_timesteps      | 1069056      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0014044784 |\n",
            "|    clip_fraction        | 0.0436       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.482        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.24         |\n",
            "|    n_updates            | 5200         |\n",
            "|    policy_gradient_loss | -0.00354     |\n",
            "|    value_loss           | 7.99         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 126          |\n",
            "|    ep_rew_mean          | 19.7         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 262          |\n",
            "|    time_elapsed         | 1940         |\n",
            "|    total_timesteps      | 1073152      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015764779 |\n",
            "|    clip_fraction        | 0.0583       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.28        |\n",
            "|    explained_variance   | 0.519        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.18         |\n",
            "|    n_updates            | 5220         |\n",
            "|    policy_gradient_loss | -0.00522     |\n",
            "|    value_loss           | 7            |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 119          |\n",
            "|    ep_rew_mean          | 17.3         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 263          |\n",
            "|    time_elapsed         | 1947         |\n",
            "|    total_timesteps      | 1077248      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0013361733 |\n",
            "|    clip_fraction        | 0.0375       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.534        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.13         |\n",
            "|    n_updates            | 5240         |\n",
            "|    policy_gradient_loss | -0.00243     |\n",
            "|    value_loss           | 8.47         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 121          |\n",
            "|    ep_rew_mean          | 17.9         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 264          |\n",
            "|    time_elapsed         | 1955         |\n",
            "|    total_timesteps      | 1081344      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0014113047 |\n",
            "|    clip_fraction        | 0.0342       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.28        |\n",
            "|    explained_variance   | 0.532        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 2.73         |\n",
            "|    n_updates            | 5260         |\n",
            "|    policy_gradient_loss | -0.00356     |\n",
            "|    value_loss           | 6.83         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 122          |\n",
            "|    ep_rew_mean          | 17.6         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 265          |\n",
            "|    time_elapsed         | 1962         |\n",
            "|    total_timesteps      | 1085440      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016966861 |\n",
            "|    clip_fraction        | 0.05         |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.28        |\n",
            "|    explained_variance   | 0.516        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 2.69         |\n",
            "|    n_updates            | 5280         |\n",
            "|    policy_gradient_loss | -0.00464     |\n",
            "|    value_loss           | 6.5          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 123          |\n",
            "|    ep_rew_mean          | 17.8         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 266          |\n",
            "|    time_elapsed         | 1969         |\n",
            "|    total_timesteps      | 1089536      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016253302 |\n",
            "|    clip_fraction        | 0.0521       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.28        |\n",
            "|    explained_variance   | 0.541        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 2.83         |\n",
            "|    n_updates            | 5300         |\n",
            "|    policy_gradient_loss | -0.00398     |\n",
            "|    value_loss           | 6.75         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 123         |\n",
            "|    ep_rew_mean          | 18          |\n",
            "| time/                   |             |\n",
            "|    fps                  | 553         |\n",
            "|    iterations           | 267         |\n",
            "|    time_elapsed         | 1977        |\n",
            "|    total_timesteps      | 1093632     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001638494 |\n",
            "|    clip_fraction        | 0.0432      |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.29       |\n",
            "|    explained_variance   | 0.489       |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 3.04        |\n",
            "|    n_updates            | 5320        |\n",
            "|    policy_gradient_loss | -0.00309    |\n",
            "|    value_loss           | 7.3         |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 123          |\n",
            "|    ep_rew_mean          | 18.9         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 268          |\n",
            "|    time_elapsed         | 1984         |\n",
            "|    total_timesteps      | 1097728      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0019003884 |\n",
            "|    clip_fraction        | 0.062        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.285        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.55         |\n",
            "|    n_updates            | 5340         |\n",
            "|    policy_gradient_loss | -0.00485     |\n",
            "|    value_loss           | 9            |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 127          |\n",
            "|    ep_rew_mean          | 20.8         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 269          |\n",
            "|    time_elapsed         | 1991         |\n",
            "|    total_timesteps      | 1101824      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015079257 |\n",
            "|    clip_fraction        | 0.0398       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.299        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.69         |\n",
            "|    n_updates            | 5360         |\n",
            "|    policy_gradient_loss | -0.00358     |\n",
            "|    value_loss           | 9.02         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 126          |\n",
            "|    ep_rew_mean          | 19.7         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 270          |\n",
            "|    time_elapsed         | 1999         |\n",
            "|    total_timesteps      | 1105920      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0014211175 |\n",
            "|    clip_fraction        | 0.0247       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.301        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.12         |\n",
            "|    n_updates            | 5380         |\n",
            "|    policy_gradient_loss | -0.00263     |\n",
            "|    value_loss           | 8.09         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 128          |\n",
            "|    ep_rew_mean          | 20.5         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 271          |\n",
            "|    time_elapsed         | 2006         |\n",
            "|    total_timesteps      | 1110016      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0019622091 |\n",
            "|    clip_fraction        | 0.0616       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.383        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.56         |\n",
            "|    n_updates            | 5400         |\n",
            "|    policy_gradient_loss | -0.00477     |\n",
            "|    value_loss           | 7.68         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 124          |\n",
            "|    ep_rew_mean          | 19           |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 272          |\n",
            "|    time_elapsed         | 2014         |\n",
            "|    total_timesteps      | 1114112      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015681253 |\n",
            "|    clip_fraction        | 0.0418       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.463        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.59         |\n",
            "|    n_updates            | 5420         |\n",
            "|    policy_gradient_loss | -0.00438     |\n",
            "|    value_loss           | 7.74         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 125          |\n",
            "|    ep_rew_mean          | 20.1         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 273          |\n",
            "|    time_elapsed         | 2021         |\n",
            "|    total_timesteps      | 1118208      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016731188 |\n",
            "|    clip_fraction        | 0.0505       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.472        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 2.84         |\n",
            "|    n_updates            | 5440         |\n",
            "|    policy_gradient_loss | -0.00412     |\n",
            "|    value_loss           | 6.95         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 121          |\n",
            "|    ep_rew_mean          | 18.9         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 274          |\n",
            "|    time_elapsed         | 2029         |\n",
            "|    total_timesteps      | 1122304      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015804536 |\n",
            "|    clip_fraction        | 0.0365       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.5          |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.06         |\n",
            "|    n_updates            | 5460         |\n",
            "|    policy_gradient_loss | -0.00299     |\n",
            "|    value_loss           | 7.24         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 126          |\n",
            "|    ep_rew_mean          | 20.5         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 275          |\n",
            "|    time_elapsed         | 2036         |\n",
            "|    total_timesteps      | 1126400      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0013945708 |\n",
            "|    clip_fraction        | 0.032        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.332        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 5.4          |\n",
            "|    n_updates            | 5480         |\n",
            "|    policy_gradient_loss | -0.00303     |\n",
            "|    value_loss           | 10.9         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 129          |\n",
            "|    ep_rew_mean          | 21.5         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 276          |\n",
            "|    time_elapsed         | 2044         |\n",
            "|    total_timesteps      | 1130496      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017294514 |\n",
            "|    clip_fraction        | 0.0389       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.378        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.72         |\n",
            "|    n_updates            | 5500         |\n",
            "|    policy_gradient_loss | -0.00288     |\n",
            "|    value_loss           | 8.41         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 131          |\n",
            "|    ep_rew_mean          | 22.5         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 277          |\n",
            "|    time_elapsed         | 2051         |\n",
            "|    total_timesteps      | 1134592      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016682633 |\n",
            "|    clip_fraction        | 0.0536       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.404        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 4.16         |\n",
            "|    n_updates            | 5520         |\n",
            "|    policy_gradient_loss | -0.00515     |\n",
            "|    value_loss           | 9.16         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 128          |\n",
            "|    ep_rew_mean          | 20.9         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 278          |\n",
            "|    time_elapsed         | 2058         |\n",
            "|    total_timesteps      | 1138688      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0014315229 |\n",
            "|    clip_fraction        | 0.0465       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.408        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 4            |\n",
            "|    n_updates            | 5540         |\n",
            "|    policy_gradient_loss | -0.00265     |\n",
            "|    value_loss           | 9.52         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 126          |\n",
            "|    ep_rew_mean          | 20.4         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 279          |\n",
            "|    time_elapsed         | 2066         |\n",
            "|    total_timesteps      | 1142784      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0021819042 |\n",
            "|    clip_fraction        | 0.0731       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.31        |\n",
            "|    explained_variance   | 0.447        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.31         |\n",
            "|    n_updates            | 5560         |\n",
            "|    policy_gradient_loss | -0.00504     |\n",
            "|    value_loss           | 8.4          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 131          |\n",
            "|    ep_rew_mean          | 21.2         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 280          |\n",
            "|    time_elapsed         | 2073         |\n",
            "|    total_timesteps      | 1146880      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016731138 |\n",
            "|    clip_fraction        | 0.0488       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.509        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.35         |\n",
            "|    n_updates            | 5580         |\n",
            "|    policy_gradient_loss | -0.00387     |\n",
            "|    value_loss           | 7.97         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 135          |\n",
            "|    ep_rew_mean          | 22.5         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 281          |\n",
            "|    time_elapsed         | 2081         |\n",
            "|    total_timesteps      | 1150976      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015671103 |\n",
            "|    clip_fraction        | 0.0404       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.398        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.5          |\n",
            "|    n_updates            | 5600         |\n",
            "|    policy_gradient_loss | -0.00362     |\n",
            "|    value_loss           | 8.99         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 135          |\n",
            "|    ep_rew_mean          | 22.2         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 282          |\n",
            "|    time_elapsed         | 2088         |\n",
            "|    total_timesteps      | 1155072      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016541381 |\n",
            "|    clip_fraction        | 0.0427       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.394        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.64         |\n",
            "|    n_updates            | 5620         |\n",
            "|    policy_gradient_loss | -0.00308     |\n",
            "|    value_loss           | 8.19         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 129          |\n",
            "|    ep_rew_mean          | 20.7         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 283          |\n",
            "|    time_elapsed         | 2095         |\n",
            "|    total_timesteps      | 1159168      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0014763733 |\n",
            "|    clip_fraction        | 0.052        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.442        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.46         |\n",
            "|    n_updates            | 5640         |\n",
            "|    policy_gradient_loss | -0.00369     |\n",
            "|    value_loss           | 8.55         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 122          |\n",
            "|    ep_rew_mean          | 18.6         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 284          |\n",
            "|    time_elapsed         | 2103         |\n",
            "|    total_timesteps      | 1163264      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015301114 |\n",
            "|    clip_fraction        | 0.0343       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.439        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.97         |\n",
            "|    n_updates            | 5660         |\n",
            "|    policy_gradient_loss | -0.00283     |\n",
            "|    value_loss           | 9.33         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 126          |\n",
            "|    ep_rew_mean          | 19.6         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 285          |\n",
            "|    time_elapsed         | 2110         |\n",
            "|    total_timesteps      | 1167360      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015830994 |\n",
            "|    clip_fraction        | 0.0414       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.553        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 2.91         |\n",
            "|    n_updates            | 5680         |\n",
            "|    policy_gradient_loss | -0.00395     |\n",
            "|    value_loss           | 7.38         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 125         |\n",
            "|    ep_rew_mean          | 18.8        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 553         |\n",
            "|    iterations           | 286         |\n",
            "|    time_elapsed         | 2118        |\n",
            "|    total_timesteps      | 1171456     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001646631 |\n",
            "|    clip_fraction        | 0.0546      |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.29       |\n",
            "|    explained_variance   | 0.583       |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 3.23        |\n",
            "|    n_updates            | 5700        |\n",
            "|    policy_gradient_loss | -0.00468    |\n",
            "|    value_loss           | 7.23        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 130          |\n",
            "|    ep_rew_mean          | 20           |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 287          |\n",
            "|    time_elapsed         | 2125         |\n",
            "|    total_timesteps      | 1175552      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015267043 |\n",
            "|    clip_fraction        | 0.0362       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.497        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.28         |\n",
            "|    n_updates            | 5720         |\n",
            "|    policy_gradient_loss | -0.00263     |\n",
            "|    value_loss           | 8.72         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 128          |\n",
            "|    ep_rew_mean          | 20.1         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 288          |\n",
            "|    time_elapsed         | 2132         |\n",
            "|    total_timesteps      | 1179648      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016401571 |\n",
            "|    clip_fraction        | 0.044        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.584        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 2.67         |\n",
            "|    n_updates            | 5740         |\n",
            "|    policy_gradient_loss | -0.00342     |\n",
            "|    value_loss           | 6.47         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 127          |\n",
            "|    ep_rew_mean          | 19.2         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 289          |\n",
            "|    time_elapsed         | 2140         |\n",
            "|    total_timesteps      | 1183744      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016405864 |\n",
            "|    clip_fraction        | 0.0372       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.494        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.35         |\n",
            "|    n_updates            | 5760         |\n",
            "|    policy_gradient_loss | -0.00321     |\n",
            "|    value_loss           | 8.02         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 129          |\n",
            "|    ep_rew_mean          | 20           |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 290          |\n",
            "|    time_elapsed         | 2147         |\n",
            "|    total_timesteps      | 1187840      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015980473 |\n",
            "|    clip_fraction        | 0.0525       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.5          |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.1          |\n",
            "|    n_updates            | 5780         |\n",
            "|    policy_gradient_loss | -0.00485     |\n",
            "|    value_loss           | 7.32         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 126          |\n",
            "|    ep_rew_mean          | 20.2         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 291          |\n",
            "|    time_elapsed         | 2155         |\n",
            "|    total_timesteps      | 1191936      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0012403452 |\n",
            "|    clip_fraction        | 0.0229       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.28        |\n",
            "|    explained_variance   | 0.525        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.39         |\n",
            "|    n_updates            | 5800         |\n",
            "|    policy_gradient_loss | -0.00342     |\n",
            "|    value_loss           | 6.81         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 129          |\n",
            "|    ep_rew_mean          | 21.5         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 292          |\n",
            "|    time_elapsed         | 2162         |\n",
            "|    total_timesteps      | 1196032      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0014283591 |\n",
            "|    clip_fraction        | 0.0341       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.476        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 2.78         |\n",
            "|    n_updates            | 5820         |\n",
            "|    policy_gradient_loss | -0.00322     |\n",
            "|    value_loss           | 6.95         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 129          |\n",
            "|    ep_rew_mean          | 21           |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 293          |\n",
            "|    time_elapsed         | 2169         |\n",
            "|    total_timesteps      | 1200128      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016865171 |\n",
            "|    clip_fraction        | 0.0419       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.408        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.82         |\n",
            "|    n_updates            | 5840         |\n",
            "|    policy_gradient_loss | -0.00371     |\n",
            "|    value_loss           | 9.16         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 134          |\n",
            "|    ep_rew_mean          | 21.6         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 294          |\n",
            "|    time_elapsed         | 2177         |\n",
            "|    total_timesteps      | 1204224      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0014819708 |\n",
            "|    clip_fraction        | 0.0365       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.514        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.38         |\n",
            "|    n_updates            | 5860         |\n",
            "|    policy_gradient_loss | -0.00342     |\n",
            "|    value_loss           | 8.02         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 134         |\n",
            "|    ep_rew_mean          | 21.1        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 553         |\n",
            "|    iterations           | 295         |\n",
            "|    time_elapsed         | 2184        |\n",
            "|    total_timesteps      | 1208320     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001529149 |\n",
            "|    clip_fraction        | 0.048       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.3        |\n",
            "|    explained_variance   | 0.483       |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 4.94        |\n",
            "|    n_updates            | 5880        |\n",
            "|    policy_gradient_loss | -0.00308    |\n",
            "|    value_loss           | 10.7        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 128          |\n",
            "|    ep_rew_mean          | 19.4         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 296          |\n",
            "|    time_elapsed         | 2191         |\n",
            "|    total_timesteps      | 1212416      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015966373 |\n",
            "|    clip_fraction        | 0.0503       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.487        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 4.02         |\n",
            "|    n_updates            | 5900         |\n",
            "|    policy_gradient_loss | -0.0038      |\n",
            "|    value_loss           | 8.34         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 123          |\n",
            "|    ep_rew_mean          | 18.2         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 297          |\n",
            "|    time_elapsed         | 2199         |\n",
            "|    total_timesteps      | 1216512      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015706884 |\n",
            "|    clip_fraction        | 0.0337       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.473        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.09         |\n",
            "|    n_updates            | 5920         |\n",
            "|    policy_gradient_loss | -0.00303     |\n",
            "|    value_loss           | 7.98         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 118          |\n",
            "|    ep_rew_mean          | 16.6         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 298          |\n",
            "|    time_elapsed         | 2206         |\n",
            "|    total_timesteps      | 1220608      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0014015859 |\n",
            "|    clip_fraction        | 0.0306       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.31        |\n",
            "|    explained_variance   | 0.551        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 2.83         |\n",
            "|    n_updates            | 5940         |\n",
            "|    policy_gradient_loss | -0.00246     |\n",
            "|    value_loss           | 6.82         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 120          |\n",
            "|    ep_rew_mean          | 16.6         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 299          |\n",
            "|    time_elapsed         | 2214         |\n",
            "|    total_timesteps      | 1224704      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0013193056 |\n",
            "|    clip_fraction        | 0.0278       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.31        |\n",
            "|    explained_variance   | 0.592        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.07         |\n",
            "|    n_updates            | 5960         |\n",
            "|    policy_gradient_loss | -0.00323     |\n",
            "|    value_loss           | 6.89         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 123          |\n",
            "|    ep_rew_mean          | 18.2         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 300          |\n",
            "|    time_elapsed         | 2221         |\n",
            "|    total_timesteps      | 1228800      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018147668 |\n",
            "|    clip_fraction        | 0.0585       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.515        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.05         |\n",
            "|    n_updates            | 5980         |\n",
            "|    policy_gradient_loss | -0.00509     |\n",
            "|    value_loss           | 7.26         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 126          |\n",
            "|    ep_rew_mean          | 19.6         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 301          |\n",
            "|    time_elapsed         | 2228         |\n",
            "|    total_timesteps      | 1232896      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0012710532 |\n",
            "|    clip_fraction        | 0.0305       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.498        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 2.7          |\n",
            "|    n_updates            | 6000         |\n",
            "|    policy_gradient_loss | -0.00406     |\n",
            "|    value_loss           | 6.79         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 128          |\n",
            "|    ep_rew_mean          | 21           |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 302          |\n",
            "|    time_elapsed         | 2236         |\n",
            "|    total_timesteps      | 1236992      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0013616245 |\n",
            "|    clip_fraction        | 0.0331       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.436        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.14         |\n",
            "|    n_updates            | 6020         |\n",
            "|    policy_gradient_loss | -0.00352     |\n",
            "|    value_loss           | 7.29         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 126          |\n",
            "|    ep_rew_mean          | 20           |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 303          |\n",
            "|    time_elapsed         | 2243         |\n",
            "|    total_timesteps      | 1241088      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015896753 |\n",
            "|    clip_fraction        | 0.0563       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.43         |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 2.77         |\n",
            "|    n_updates            | 6040         |\n",
            "|    policy_gradient_loss | -0.00515     |\n",
            "|    value_loss           | 6.79         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 124          |\n",
            "|    ep_rew_mean          | 19.3         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 304          |\n",
            "|    time_elapsed         | 2251         |\n",
            "|    total_timesteps      | 1245184      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015062233 |\n",
            "|    clip_fraction        | 0.0463       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.459        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.04         |\n",
            "|    n_updates            | 6060         |\n",
            "|    policy_gradient_loss | -0.00514     |\n",
            "|    value_loss           | 7.56         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 129          |\n",
            "|    ep_rew_mean          | 20.1         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 305          |\n",
            "|    time_elapsed         | 2258         |\n",
            "|    total_timesteps      | 1249280      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0022435985 |\n",
            "|    clip_fraction        | 0.0763       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.34         |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.21         |\n",
            "|    n_updates            | 6080         |\n",
            "|    policy_gradient_loss | -0.00454     |\n",
            "|    value_loss           | 8.09         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 133          |\n",
            "|    ep_rew_mean          | 21.7         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 306          |\n",
            "|    time_elapsed         | 2265         |\n",
            "|    total_timesteps      | 1253376      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018122622 |\n",
            "|    clip_fraction        | 0.0517       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.297        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.43         |\n",
            "|    n_updates            | 6100         |\n",
            "|    policy_gradient_loss | -0.00493     |\n",
            "|    value_loss           | 8.58         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 133          |\n",
            "|    ep_rew_mean          | 21.3         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 307          |\n",
            "|    time_elapsed         | 2273         |\n",
            "|    total_timesteps      | 1257472      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018598187 |\n",
            "|    clip_fraction        | 0.0576       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.42         |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 2.46         |\n",
            "|    n_updates            | 6120         |\n",
            "|    policy_gradient_loss | -0.00356     |\n",
            "|    value_loss           | 7.94         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 129          |\n",
            "|    ep_rew_mean          | 20.1         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 308          |\n",
            "|    time_elapsed         | 2280         |\n",
            "|    total_timesteps      | 1261568      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0013978714 |\n",
            "|    clip_fraction        | 0.0325       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.457        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.7          |\n",
            "|    n_updates            | 6140         |\n",
            "|    policy_gradient_loss | -0.00365     |\n",
            "|    value_loss           | 8.2          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 125          |\n",
            "|    ep_rew_mean          | 19.4         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 309          |\n",
            "|    time_elapsed         | 2288         |\n",
            "|    total_timesteps      | 1265664      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0012787166 |\n",
            "|    clip_fraction        | 0.0299       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.419        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 4.55         |\n",
            "|    n_updates            | 6160         |\n",
            "|    policy_gradient_loss | -0.00263     |\n",
            "|    value_loss           | 9.46         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 122         |\n",
            "|    ep_rew_mean          | 18.7        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 553         |\n",
            "|    iterations           | 310         |\n",
            "|    time_elapsed         | 2295        |\n",
            "|    total_timesteps      | 1269760     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001239591 |\n",
            "|    clip_fraction        | 0.02        |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.28       |\n",
            "|    explained_variance   | 0.413       |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 4.43        |\n",
            "|    n_updates            | 6180        |\n",
            "|    policy_gradient_loss | -0.00318    |\n",
            "|    value_loss           | 9.49        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 128          |\n",
            "|    ep_rew_mean          | 20.5         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 311          |\n",
            "|    time_elapsed         | 2302         |\n",
            "|    total_timesteps      | 1273856      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017466587 |\n",
            "|    clip_fraction        | 0.0477       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.529        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.47         |\n",
            "|    n_updates            | 6200         |\n",
            "|    policy_gradient_loss | -0.00385     |\n",
            "|    value_loss           | 7.56         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 125         |\n",
            "|    ep_rew_mean          | 19.9        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 553         |\n",
            "|    iterations           | 312         |\n",
            "|    time_elapsed         | 2310        |\n",
            "|    total_timesteps      | 1277952     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001527387 |\n",
            "|    clip_fraction        | 0.0397      |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.29       |\n",
            "|    explained_variance   | 0.51        |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 3.39        |\n",
            "|    n_updates            | 6220        |\n",
            "|    policy_gradient_loss | -0.00358    |\n",
            "|    value_loss           | 7.19        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 128          |\n",
            "|    ep_rew_mean          | 21.2         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 313          |\n",
            "|    time_elapsed         | 2317         |\n",
            "|    total_timesteps      | 1282048      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018704848 |\n",
            "|    clip_fraction        | 0.0586       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.28        |\n",
            "|    explained_variance   | 0.427        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 4.34         |\n",
            "|    n_updates            | 6240         |\n",
            "|    policy_gradient_loss | -0.00437     |\n",
            "|    value_loss           | 8.98         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 126          |\n",
            "|    ep_rew_mean          | 20.4         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 314          |\n",
            "|    time_elapsed         | 2325         |\n",
            "|    total_timesteps      | 1286144      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016784237 |\n",
            "|    clip_fraction        | 0.0367       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.394        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.88         |\n",
            "|    n_updates            | 6260         |\n",
            "|    policy_gradient_loss | -0.0028      |\n",
            "|    value_loss           | 8.88         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 128          |\n",
            "|    ep_rew_mean          | 20.7         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 315          |\n",
            "|    time_elapsed         | 2332         |\n",
            "|    total_timesteps      | 1290240      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015355244 |\n",
            "|    clip_fraction        | 0.0301       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.28        |\n",
            "|    explained_variance   | 0.377        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.97         |\n",
            "|    n_updates            | 6280         |\n",
            "|    policy_gradient_loss | -0.00352     |\n",
            "|    value_loss           | 9.28         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 131          |\n",
            "|    ep_rew_mean          | 21.1         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 316          |\n",
            "|    time_elapsed         | 2339         |\n",
            "|    total_timesteps      | 1294336      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015445695 |\n",
            "|    clip_fraction        | 0.04         |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.429        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.98         |\n",
            "|    n_updates            | 6300         |\n",
            "|    policy_gradient_loss | -0.00371     |\n",
            "|    value_loss           | 9.16         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 131          |\n",
            "|    ep_rew_mean          | 20.7         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 317          |\n",
            "|    time_elapsed         | 2347         |\n",
            "|    total_timesteps      | 1298432      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018919513 |\n",
            "|    clip_fraction        | 0.0474       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.432        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 4.15         |\n",
            "|    n_updates            | 6320         |\n",
            "|    policy_gradient_loss | -0.00396     |\n",
            "|    value_loss           | 9.16         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 131          |\n",
            "|    ep_rew_mean          | 20.5         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 318          |\n",
            "|    time_elapsed         | 2354         |\n",
            "|    total_timesteps      | 1302528      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016406926 |\n",
            "|    clip_fraction        | 0.0569       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.543        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.31         |\n",
            "|    n_updates            | 6340         |\n",
            "|    policy_gradient_loss | -0.00484     |\n",
            "|    value_loss           | 7.73         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 132          |\n",
            "|    ep_rew_mean          | 21.1         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 319          |\n",
            "|    time_elapsed         | 2361         |\n",
            "|    total_timesteps      | 1306624      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0013034793 |\n",
            "|    clip_fraction        | 0.0286       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.505        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 4.23         |\n",
            "|    n_updates            | 6360         |\n",
            "|    policy_gradient_loss | -0.00272     |\n",
            "|    value_loss           | 9.65         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 131          |\n",
            "|    ep_rew_mean          | 21.3         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 320          |\n",
            "|    time_elapsed         | 2369         |\n",
            "|    total_timesteps      | 1310720      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0014592437 |\n",
            "|    clip_fraction        | 0.0378       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.493        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.51         |\n",
            "|    n_updates            | 6380         |\n",
            "|    policy_gradient_loss | -0.00399     |\n",
            "|    value_loss           | 8.58         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 128          |\n",
            "|    ep_rew_mean          | 20.2         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 321          |\n",
            "|    time_elapsed         | 2376         |\n",
            "|    total_timesteps      | 1314816      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017393476 |\n",
            "|    clip_fraction        | 0.0462       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.28        |\n",
            "|    explained_variance   | 0.416        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 4.22         |\n",
            "|    n_updates            | 6400         |\n",
            "|    policy_gradient_loss | -0.00425     |\n",
            "|    value_loss           | 9.24         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 130          |\n",
            "|    ep_rew_mean          | 20.2         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 322          |\n",
            "|    time_elapsed         | 2384         |\n",
            "|    total_timesteps      | 1318912      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018728389 |\n",
            "|    clip_fraction        | 0.0519       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.514        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.23         |\n",
            "|    n_updates            | 6420         |\n",
            "|    policy_gradient_loss | -0.00409     |\n",
            "|    value_loss           | 7.9          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 132          |\n",
            "|    ep_rew_mean          | 20.3         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 323          |\n",
            "|    time_elapsed         | 2391         |\n",
            "|    total_timesteps      | 1323008      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015445559 |\n",
            "|    clip_fraction        | 0.0412       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.419        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.65         |\n",
            "|    n_updates            | 6440         |\n",
            "|    policy_gradient_loss | -0.00481     |\n",
            "|    value_loss           | 8.6          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 131          |\n",
            "|    ep_rew_mean          | 21.2         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 324          |\n",
            "|    time_elapsed         | 2399         |\n",
            "|    total_timesteps      | 1327104      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0014303462 |\n",
            "|    clip_fraction        | 0.036        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.501        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 2.92         |\n",
            "|    n_updates            | 6460         |\n",
            "|    policy_gradient_loss | -0.00262     |\n",
            "|    value_loss           | 7.55         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 132          |\n",
            "|    ep_rew_mean          | 21.5         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 325          |\n",
            "|    time_elapsed         | 2406         |\n",
            "|    total_timesteps      | 1331200      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017303908 |\n",
            "|    clip_fraction        | 0.0635       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.535        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.46         |\n",
            "|    n_updates            | 6480         |\n",
            "|    policy_gradient_loss | -0.0036      |\n",
            "|    value_loss           | 7.67         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 133          |\n",
            "|    ep_rew_mean          | 20.4         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 326          |\n",
            "|    time_elapsed         | 2414         |\n",
            "|    total_timesteps      | 1335296      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017440654 |\n",
            "|    clip_fraction        | 0.05         |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.477        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.45         |\n",
            "|    n_updates            | 6500         |\n",
            "|    policy_gradient_loss | -0.00456     |\n",
            "|    value_loss           | 8.28         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 137          |\n",
            "|    ep_rew_mean          | 19.7         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 327          |\n",
            "|    time_elapsed         | 2421         |\n",
            "|    total_timesteps      | 1339392      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018355739 |\n",
            "|    clip_fraction        | 0.0503       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.54         |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 2.45         |\n",
            "|    n_updates            | 6520         |\n",
            "|    policy_gradient_loss | -0.00545     |\n",
            "|    value_loss           | 6.34         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 142          |\n",
            "|    ep_rew_mean          | 21.9         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 328          |\n",
            "|    time_elapsed         | 2428         |\n",
            "|    total_timesteps      | 1343488      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016330048 |\n",
            "|    clip_fraction        | 0.0297       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.515        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 4.13         |\n",
            "|    n_updates            | 6540         |\n",
            "|    policy_gradient_loss | -0.00378     |\n",
            "|    value_loss           | 9.09         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 138          |\n",
            "|    ep_rew_mean          | 21.6         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 329          |\n",
            "|    time_elapsed         | 2436         |\n",
            "|    total_timesteps      | 1347584      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017812492 |\n",
            "|    clip_fraction        | 0.0572       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.507        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.36         |\n",
            "|    n_updates            | 6560         |\n",
            "|    policy_gradient_loss | -0.00372     |\n",
            "|    value_loss           | 7.89         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 136          |\n",
            "|    ep_rew_mean          | 23.7         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 330          |\n",
            "|    time_elapsed         | 2443         |\n",
            "|    total_timesteps      | 1351680      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015932978 |\n",
            "|    clip_fraction        | 0.0612       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.408        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.93         |\n",
            "|    n_updates            | 6580         |\n",
            "|    policy_gradient_loss | -0.00539     |\n",
            "|    value_loss           | 9.48         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 132          |\n",
            "|    ep_rew_mean          | 22.1         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 331          |\n",
            "|    time_elapsed         | 2450         |\n",
            "|    total_timesteps      | 1355776      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015747346 |\n",
            "|    clip_fraction        | 0.0403       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.292        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.83         |\n",
            "|    n_updates            | 6600         |\n",
            "|    policy_gradient_loss | -0.00402     |\n",
            "|    value_loss           | 9.84         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 136          |\n",
            "|    ep_rew_mean          | 23.6         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 332          |\n",
            "|    time_elapsed         | 2458         |\n",
            "|    total_timesteps      | 1359872      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017070856 |\n",
            "|    clip_fraction        | 0.0575       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.357        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.67         |\n",
            "|    n_updates            | 6620         |\n",
            "|    policy_gradient_loss | -0.00501     |\n",
            "|    value_loss           | 9.35         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 131          |\n",
            "|    ep_rew_mean          | 21.5         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 333          |\n",
            "|    time_elapsed         | 2465         |\n",
            "|    total_timesteps      | 1363968      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017167402 |\n",
            "|    clip_fraction        | 0.0641       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.32         |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.84         |\n",
            "|    n_updates            | 6640         |\n",
            "|    policy_gradient_loss | -0.00444     |\n",
            "|    value_loss           | 9.12         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 133          |\n",
            "|    ep_rew_mean          | 21.5         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 334          |\n",
            "|    time_elapsed         | 2473         |\n",
            "|    total_timesteps      | 1368064      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015434248 |\n",
            "|    clip_fraction        | 0.0471       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.4          |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.63         |\n",
            "|    n_updates            | 6660         |\n",
            "|    policy_gradient_loss | -0.0046      |\n",
            "|    value_loss           | 9.03         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 131          |\n",
            "|    ep_rew_mean          | 20.8         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 335          |\n",
            "|    time_elapsed         | 2480         |\n",
            "|    total_timesteps      | 1372160      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0013944653 |\n",
            "|    clip_fraction        | 0.0364       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.462        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 4.28         |\n",
            "|    n_updates            | 6680         |\n",
            "|    policy_gradient_loss | -0.00412     |\n",
            "|    value_loss           | 8.98         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 133         |\n",
            "|    ep_rew_mean          | 20.9        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 553         |\n",
            "|    iterations           | 336         |\n",
            "|    time_elapsed         | 2488        |\n",
            "|    total_timesteps      | 1376256     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002258771 |\n",
            "|    clip_fraction        | 0.0876      |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.29       |\n",
            "|    explained_variance   | 0.517       |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 3.78        |\n",
            "|    n_updates            | 6700        |\n",
            "|    policy_gradient_loss | -0.00532    |\n",
            "|    value_loss           | 8.54        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 134          |\n",
            "|    ep_rew_mean          | 21           |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 337          |\n",
            "|    time_elapsed         | 2495         |\n",
            "|    total_timesteps      | 1380352      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015686385 |\n",
            "|    clip_fraction        | 0.0566       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.542        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 2.92         |\n",
            "|    n_updates            | 6720         |\n",
            "|    policy_gradient_loss | -0.0042      |\n",
            "|    value_loss           | 7.84         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 128          |\n",
            "|    ep_rew_mean          | 19.5         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 338          |\n",
            "|    time_elapsed         | 2502         |\n",
            "|    total_timesteps      | 1384448      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016530959 |\n",
            "|    clip_fraction        | 0.058        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.501        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 4.02         |\n",
            "|    n_updates            | 6740         |\n",
            "|    policy_gradient_loss | -0.00468     |\n",
            "|    value_loss           | 9.28         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 132          |\n",
            "|    ep_rew_mean          | 20.2         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 339          |\n",
            "|    time_elapsed         | 2510         |\n",
            "|    total_timesteps      | 1388544      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0019527421 |\n",
            "|    clip_fraction        | 0.0675       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.31        |\n",
            "|    explained_variance   | 0.51         |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.17         |\n",
            "|    n_updates            | 6760         |\n",
            "|    policy_gradient_loss | -0.0039      |\n",
            "|    value_loss           | 7.81         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 123         |\n",
            "|    ep_rew_mean          | 18.3        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 553         |\n",
            "|    iterations           | 340         |\n",
            "|    time_elapsed         | 2517        |\n",
            "|    total_timesteps      | 1392640     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001577346 |\n",
            "|    clip_fraction        | 0.0425      |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.3        |\n",
            "|    explained_variance   | 0.477       |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 3.72        |\n",
            "|    n_updates            | 6780        |\n",
            "|    policy_gradient_loss | -0.00411    |\n",
            "|    value_loss           | 7.73        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 126          |\n",
            "|    ep_rew_mean          | 19.1         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 341          |\n",
            "|    time_elapsed         | 2525         |\n",
            "|    total_timesteps      | 1396736      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015022769 |\n",
            "|    clip_fraction        | 0.035        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.48         |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.25         |\n",
            "|    n_updates            | 6800         |\n",
            "|    policy_gradient_loss | -0.00487     |\n",
            "|    value_loss           | 7.56         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 123         |\n",
            "|    ep_rew_mean          | 18.4        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 553         |\n",
            "|    iterations           | 342         |\n",
            "|    time_elapsed         | 2532        |\n",
            "|    total_timesteps      | 1400832     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001673836 |\n",
            "|    clip_fraction        | 0.0642      |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.3        |\n",
            "|    explained_variance   | 0.447       |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 3.18        |\n",
            "|    n_updates            | 6820        |\n",
            "|    policy_gradient_loss | -0.00376    |\n",
            "|    value_loss           | 7.95        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 130          |\n",
            "|    ep_rew_mean          | 19.9         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 343          |\n",
            "|    time_elapsed         | 2540         |\n",
            "|    total_timesteps      | 1404928      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0020260666 |\n",
            "|    clip_fraction        | 0.0642       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.372        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.88         |\n",
            "|    n_updates            | 6840         |\n",
            "|    policy_gradient_loss | -0.00504     |\n",
            "|    value_loss           | 10.2         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 128          |\n",
            "|    ep_rew_mean          | 20.4         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 344          |\n",
            "|    time_elapsed         | 2547         |\n",
            "|    total_timesteps      | 1409024      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0020515113 |\n",
            "|    clip_fraction        | 0.0751       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.349        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.97         |\n",
            "|    n_updates            | 6860         |\n",
            "|    policy_gradient_loss | -0.00517     |\n",
            "|    value_loss           | 9.68         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 131          |\n",
            "|    ep_rew_mean          | 20.8         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 345          |\n",
            "|    time_elapsed         | 2555         |\n",
            "|    total_timesteps      | 1413120      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015522493 |\n",
            "|    clip_fraction        | 0.0584       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.261        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.96         |\n",
            "|    n_updates            | 6880         |\n",
            "|    policy_gradient_loss | -0.00392     |\n",
            "|    value_loss           | 8.87         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 131          |\n",
            "|    ep_rew_mean          | 20.8         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 346          |\n",
            "|    time_elapsed         | 2562         |\n",
            "|    total_timesteps      | 1417216      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015068279 |\n",
            "|    clip_fraction        | 0.0309       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.383        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.25         |\n",
            "|    n_updates            | 6900         |\n",
            "|    policy_gradient_loss | -0.00417     |\n",
            "|    value_loss           | 8.42         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 130          |\n",
            "|    ep_rew_mean          | 20.6         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 347          |\n",
            "|    time_elapsed         | 2569         |\n",
            "|    total_timesteps      | 1421312      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016603535 |\n",
            "|    clip_fraction        | 0.0565       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.386        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.45         |\n",
            "|    n_updates            | 6920         |\n",
            "|    policy_gradient_loss | -0.00456     |\n",
            "|    value_loss           | 9.51         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 126         |\n",
            "|    ep_rew_mean          | 19.6        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 553         |\n",
            "|    iterations           | 348         |\n",
            "|    time_elapsed         | 2577        |\n",
            "|    total_timesteps      | 1425408     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001789191 |\n",
            "|    clip_fraction        | 0.0519      |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.3        |\n",
            "|    explained_variance   | 0.465       |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 3.07        |\n",
            "|    n_updates            | 6940        |\n",
            "|    policy_gradient_loss | -0.00461    |\n",
            "|    value_loss           | 7.39        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 124          |\n",
            "|    ep_rew_mean          | 17.9         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 349          |\n",
            "|    time_elapsed         | 2584         |\n",
            "|    total_timesteps      | 1429504      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0014519612 |\n",
            "|    clip_fraction        | 0.0354       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.449        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.49         |\n",
            "|    n_updates            | 6960         |\n",
            "|    policy_gradient_loss | -0.00307     |\n",
            "|    value_loss           | 8.96         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 127          |\n",
            "|    ep_rew_mean          | 19.6         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 350          |\n",
            "|    time_elapsed         | 2592         |\n",
            "|    total_timesteps      | 1433600      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0014309515 |\n",
            "|    clip_fraction        | 0.0374       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.578        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 2.47         |\n",
            "|    n_updates            | 6980         |\n",
            "|    policy_gradient_loss | -0.00441     |\n",
            "|    value_loss           | 6.63         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 136          |\n",
            "|    ep_rew_mean          | 22.1         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 351          |\n",
            "|    time_elapsed         | 2599         |\n",
            "|    total_timesteps      | 1437696      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018023987 |\n",
            "|    clip_fraction        | 0.0404       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.331        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 4.49         |\n",
            "|    n_updates            | 7000         |\n",
            "|    policy_gradient_loss | -0.00304     |\n",
            "|    value_loss           | 10.3         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 140          |\n",
            "|    ep_rew_mean          | 23.6         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 352          |\n",
            "|    time_elapsed         | 2606         |\n",
            "|    total_timesteps      | 1441792      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0013013915 |\n",
            "|    clip_fraction        | 0.0244       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.342        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.19         |\n",
            "|    n_updates            | 7020         |\n",
            "|    policy_gradient_loss | -0.00359     |\n",
            "|    value_loss           | 8.52         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 138          |\n",
            "|    ep_rew_mean          | 22.8         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 353          |\n",
            "|    time_elapsed         | 2614         |\n",
            "|    total_timesteps      | 1445888      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0020449192 |\n",
            "|    clip_fraction        | 0.0729       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.319        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 2.99         |\n",
            "|    n_updates            | 7040         |\n",
            "|    policy_gradient_loss | -0.00532     |\n",
            "|    value_loss           | 8.59         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 135          |\n",
            "|    ep_rew_mean          | 20.6         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 354          |\n",
            "|    time_elapsed         | 2621         |\n",
            "|    total_timesteps      | 1449984      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016633094 |\n",
            "|    clip_fraction        | 0.0439       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.31        |\n",
            "|    explained_variance   | 0.281        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 4.06         |\n",
            "|    n_updates            | 7060         |\n",
            "|    policy_gradient_loss | -0.00318     |\n",
            "|    value_loss           | 9.07         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 132          |\n",
            "|    ep_rew_mean          | 19.8         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 355          |\n",
            "|    time_elapsed         | 2629         |\n",
            "|    total_timesteps      | 1454080      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015481452 |\n",
            "|    clip_fraction        | 0.0357       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.31        |\n",
            "|    explained_variance   | 0.323        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.6          |\n",
            "|    n_updates            | 7080         |\n",
            "|    policy_gradient_loss | -0.00424     |\n",
            "|    value_loss           | 9.34         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 132          |\n",
            "|    ep_rew_mean          | 20.1         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 356          |\n",
            "|    time_elapsed         | 2636         |\n",
            "|    total_timesteps      | 1458176      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0019392403 |\n",
            "|    clip_fraction        | 0.075        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.463        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.45         |\n",
            "|    n_updates            | 7100         |\n",
            "|    policy_gradient_loss | -0.00586     |\n",
            "|    value_loss           | 8.41         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 130          |\n",
            "|    ep_rew_mean          | 19.4         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 357          |\n",
            "|    time_elapsed         | 2644         |\n",
            "|    total_timesteps      | 1462272      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0014392801 |\n",
            "|    clip_fraction        | 0.0347       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.422        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.12         |\n",
            "|    n_updates            | 7120         |\n",
            "|    policy_gradient_loss | -0.00458     |\n",
            "|    value_loss           | 8.41         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 131          |\n",
            "|    ep_rew_mean          | 20.8         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 358          |\n",
            "|    time_elapsed         | 2651         |\n",
            "|    total_timesteps      | 1466368      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017605706 |\n",
            "|    clip_fraction        | 0.0472       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.501        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.41         |\n",
            "|    n_updates            | 7140         |\n",
            "|    policy_gradient_loss | -0.00509     |\n",
            "|    value_loss           | 7.78         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 129          |\n",
            "|    ep_rew_mean          | 20.8         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 359          |\n",
            "|    time_elapsed         | 2658         |\n",
            "|    total_timesteps      | 1470464      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0019245084 |\n",
            "|    clip_fraction        | 0.065        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.412        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.85         |\n",
            "|    n_updates            | 7160         |\n",
            "|    policy_gradient_loss | -0.00504     |\n",
            "|    value_loss           | 7.99         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 133         |\n",
            "|    ep_rew_mean          | 22.1        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 553         |\n",
            "|    iterations           | 360         |\n",
            "|    time_elapsed         | 2666        |\n",
            "|    total_timesteps      | 1474560     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001653799 |\n",
            "|    clip_fraction        | 0.051       |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.3        |\n",
            "|    explained_variance   | 0.371       |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 4.27        |\n",
            "|    n_updates            | 7180        |\n",
            "|    policy_gradient_loss | -0.00392    |\n",
            "|    value_loss           | 9.59        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 134          |\n",
            "|    ep_rew_mean          | 21.2         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 361          |\n",
            "|    time_elapsed         | 2673         |\n",
            "|    total_timesteps      | 1478656      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017513405 |\n",
            "|    clip_fraction        | 0.057        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.411        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.04         |\n",
            "|    n_updates            | 7200         |\n",
            "|    policy_gradient_loss | -0.00444     |\n",
            "|    value_loss           | 8.05         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 135          |\n",
            "|    ep_rew_mean          | 21.2         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 362          |\n",
            "|    time_elapsed         | 2681         |\n",
            "|    total_timesteps      | 1482752      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017791578 |\n",
            "|    clip_fraction        | 0.0607       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.442        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 4.64         |\n",
            "|    n_updates            | 7220         |\n",
            "|    policy_gradient_loss | -0.00438     |\n",
            "|    value_loss           | 9.55         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 134          |\n",
            "|    ep_rew_mean          | 20.2         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 363          |\n",
            "|    time_elapsed         | 2688         |\n",
            "|    total_timesteps      | 1486848      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0019428643 |\n",
            "|    clip_fraction        | 0.0641       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.534        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 2.8          |\n",
            "|    n_updates            | 7240         |\n",
            "|    policy_gradient_loss | -0.00564     |\n",
            "|    value_loss           | 6.72         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 128          |\n",
            "|    ep_rew_mean          | 19.6         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 364          |\n",
            "|    time_elapsed         | 2695         |\n",
            "|    total_timesteps      | 1490944      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0014942699 |\n",
            "|    clip_fraction        | 0.0339       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.544        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.25         |\n",
            "|    n_updates            | 7260         |\n",
            "|    policy_gradient_loss | -0.00447     |\n",
            "|    value_loss           | 8.63         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 131          |\n",
            "|    ep_rew_mean          | 20.8         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 365          |\n",
            "|    time_elapsed         | 2703         |\n",
            "|    total_timesteps      | 1495040      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015388659 |\n",
            "|    clip_fraction        | 0.0436       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.468        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.85         |\n",
            "|    n_updates            | 7280         |\n",
            "|    policy_gradient_loss | -0.00374     |\n",
            "|    value_loss           | 9.84         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 133          |\n",
            "|    ep_rew_mean          | 20.7         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 366          |\n",
            "|    time_elapsed         | 2710         |\n",
            "|    total_timesteps      | 1499136      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017851427 |\n",
            "|    clip_fraction        | 0.0632       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.488        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 2.99         |\n",
            "|    n_updates            | 7300         |\n",
            "|    policy_gradient_loss | -0.00564     |\n",
            "|    value_loss           | 7.44         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 134          |\n",
            "|    ep_rew_mean          | 20.6         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 367          |\n",
            "|    time_elapsed         | 2717         |\n",
            "|    total_timesteps      | 1503232      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0014744552 |\n",
            "|    clip_fraction        | 0.0332       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.465        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.11         |\n",
            "|    n_updates            | 7320         |\n",
            "|    policy_gradient_loss | -0.00396     |\n",
            "|    value_loss           | 7.28         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 137         |\n",
            "|    ep_rew_mean          | 21.6        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 553         |\n",
            "|    iterations           | 368         |\n",
            "|    time_elapsed         | 2725        |\n",
            "|    total_timesteps      | 1507328     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001460901 |\n",
            "|    clip_fraction        | 0.0396      |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.29       |\n",
            "|    explained_variance   | 0.507       |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 3.19        |\n",
            "|    n_updates            | 7340        |\n",
            "|    policy_gradient_loss | -0.00362    |\n",
            "|    value_loss           | 7           |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 129          |\n",
            "|    ep_rew_mean          | 20           |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 369          |\n",
            "|    time_elapsed         | 2732         |\n",
            "|    total_timesteps      | 1511424      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0014692035 |\n",
            "|    clip_fraction        | 0.0373       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.486        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.48         |\n",
            "|    n_updates            | 7360         |\n",
            "|    policy_gradient_loss | -0.00373     |\n",
            "|    value_loss           | 8.91         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 124          |\n",
            "|    ep_rew_mean          | 19.4         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 370          |\n",
            "|    time_elapsed         | 2739         |\n",
            "|    total_timesteps      | 1515520      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016011497 |\n",
            "|    clip_fraction        | 0.0365       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.55         |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.63         |\n",
            "|    n_updates            | 7380         |\n",
            "|    policy_gradient_loss | -0.0036      |\n",
            "|    value_loss           | 7.93         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 125          |\n",
            "|    ep_rew_mean          | 19.5         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 371          |\n",
            "|    time_elapsed         | 2747         |\n",
            "|    total_timesteps      | 1519616      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018257301 |\n",
            "|    clip_fraction        | 0.0616       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.498        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.81         |\n",
            "|    n_updates            | 7400         |\n",
            "|    policy_gradient_loss | -0.00433     |\n",
            "|    value_loss           | 8.66         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 124          |\n",
            "|    ep_rew_mean          | 19           |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 372          |\n",
            "|    time_elapsed         | 2754         |\n",
            "|    total_timesteps      | 1523712      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0019131026 |\n",
            "|    clip_fraction        | 0.0753       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.434        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.29         |\n",
            "|    n_updates            | 7420         |\n",
            "|    policy_gradient_loss | -0.0051      |\n",
            "|    value_loss           | 8.17         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 128          |\n",
            "|    ep_rew_mean          | 20.2         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 373          |\n",
            "|    time_elapsed         | 2762         |\n",
            "|    total_timesteps      | 1527808      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016423634 |\n",
            "|    clip_fraction        | 0.0527       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.469        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.15         |\n",
            "|    n_updates            | 7440         |\n",
            "|    policy_gradient_loss | -0.00539     |\n",
            "|    value_loss           | 7.16         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 126          |\n",
            "|    ep_rew_mean          | 19.8         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 374          |\n",
            "|    time_elapsed         | 2769         |\n",
            "|    total_timesteps      | 1531904      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0014280515 |\n",
            "|    clip_fraction        | 0.0363       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.394        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 4.12         |\n",
            "|    n_updates            | 7460         |\n",
            "|    policy_gradient_loss | -0.00403     |\n",
            "|    value_loss           | 9.45         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 131          |\n",
            "|    ep_rew_mean          | 21.3         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 375          |\n",
            "|    time_elapsed         | 2777         |\n",
            "|    total_timesteps      | 1536000      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018493568 |\n",
            "|    clip_fraction        | 0.0725       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.455        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 2.71         |\n",
            "|    n_updates            | 7480         |\n",
            "|    policy_gradient_loss | -0.00413     |\n",
            "|    value_loss           | 7.18         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 132          |\n",
            "|    ep_rew_mean          | 20.9         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 376          |\n",
            "|    time_elapsed         | 2784         |\n",
            "|    total_timesteps      | 1540096      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0014524697 |\n",
            "|    clip_fraction        | 0.0374       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.438        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.2          |\n",
            "|    n_updates            | 7500         |\n",
            "|    policy_gradient_loss | -0.00389     |\n",
            "|    value_loss           | 8.17         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 131         |\n",
            "|    ep_rew_mean          | 19.9        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 553         |\n",
            "|    iterations           | 377         |\n",
            "|    time_elapsed         | 2791        |\n",
            "|    total_timesteps      | 1544192     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001727113 |\n",
            "|    clip_fraction        | 0.0482      |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.29       |\n",
            "|    explained_variance   | 0.484       |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 3.53        |\n",
            "|    n_updates            | 7520        |\n",
            "|    policy_gradient_loss | -0.00403    |\n",
            "|    value_loss           | 7.82        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 131          |\n",
            "|    ep_rew_mean          | 19.2         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 378          |\n",
            "|    time_elapsed         | 2799         |\n",
            "|    total_timesteps      | 1548288      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017916623 |\n",
            "|    clip_fraction        | 0.0676       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.534        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.5          |\n",
            "|    n_updates            | 7540         |\n",
            "|    policy_gradient_loss | -0.00573     |\n",
            "|    value_loss           | 7.8          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 130          |\n",
            "|    ep_rew_mean          | 19.7         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 379          |\n",
            "|    time_elapsed         | 2806         |\n",
            "|    total_timesteps      | 1552384      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016559295 |\n",
            "|    clip_fraction        | 0.057        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.535        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.46         |\n",
            "|    n_updates            | 7560         |\n",
            "|    policy_gradient_loss | -0.00516     |\n",
            "|    value_loss           | 8.42         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 133          |\n",
            "|    ep_rew_mean          | 21           |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 380          |\n",
            "|    time_elapsed         | 2813         |\n",
            "|    total_timesteps      | 1556480      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0020879852 |\n",
            "|    clip_fraction        | 0.0707       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.495        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.54         |\n",
            "|    n_updates            | 7580         |\n",
            "|    policy_gradient_loss | -0.00536     |\n",
            "|    value_loss           | 8.07         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 127         |\n",
            "|    ep_rew_mean          | 20.3        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 553         |\n",
            "|    iterations           | 381         |\n",
            "|    time_elapsed         | 2821        |\n",
            "|    total_timesteps      | 1560576     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001454019 |\n",
            "|    clip_fraction        | 0.0262      |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.29       |\n",
            "|    explained_variance   | 0.483       |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 3.15        |\n",
            "|    n_updates            | 7600        |\n",
            "|    policy_gradient_loss | -0.00331    |\n",
            "|    value_loss           | 7.75        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 128          |\n",
            "|    ep_rew_mean          | 20.1         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 382          |\n",
            "|    time_elapsed         | 2828         |\n",
            "|    total_timesteps      | 1564672      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018401406 |\n",
            "|    clip_fraction        | 0.057        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.561        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 2.56         |\n",
            "|    n_updates            | 7620         |\n",
            "|    policy_gradient_loss | -0.00323     |\n",
            "|    value_loss           | 6.43         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 125          |\n",
            "|    ep_rew_mean          | 19           |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 383          |\n",
            "|    time_elapsed         | 2836         |\n",
            "|    total_timesteps      | 1568768      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0013674808 |\n",
            "|    clip_fraction        | 0.0346       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.501        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.74         |\n",
            "|    n_updates            | 7640         |\n",
            "|    policy_gradient_loss | -0.00344     |\n",
            "|    value_loss           | 8.96         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 131          |\n",
            "|    ep_rew_mean          | 19.6         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 384          |\n",
            "|    time_elapsed         | 2843         |\n",
            "|    total_timesteps      | 1572864      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016632425 |\n",
            "|    clip_fraction        | 0.0391       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.578        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 2.38         |\n",
            "|    n_updates            | 7660         |\n",
            "|    policy_gradient_loss | -0.00436     |\n",
            "|    value_loss           | 6.14         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 130         |\n",
            "|    ep_rew_mean          | 19.3        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 553         |\n",
            "|    iterations           | 385         |\n",
            "|    time_elapsed         | 2850        |\n",
            "|    total_timesteps      | 1576960     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001785344 |\n",
            "|    clip_fraction        | 0.0519      |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.3        |\n",
            "|    explained_variance   | 0.602       |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 3.22        |\n",
            "|    n_updates            | 7680        |\n",
            "|    policy_gradient_loss | -0.0038     |\n",
            "|    value_loss           | 7.53        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 126          |\n",
            "|    ep_rew_mean          | 18.6         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 386          |\n",
            "|    time_elapsed         | 2858         |\n",
            "|    total_timesteps      | 1581056      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0014710586 |\n",
            "|    clip_fraction        | 0.0521       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.559        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.13         |\n",
            "|    n_updates            | 7700         |\n",
            "|    policy_gradient_loss | -0.00524     |\n",
            "|    value_loss           | 7.94         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 120          |\n",
            "|    ep_rew_mean          | 18.3         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 387          |\n",
            "|    time_elapsed         | 2865         |\n",
            "|    total_timesteps      | 1585152      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016973563 |\n",
            "|    clip_fraction        | 0.0564       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.574        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 2.74         |\n",
            "|    n_updates            | 7720         |\n",
            "|    policy_gradient_loss | -0.00515     |\n",
            "|    value_loss           | 6.18         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 123          |\n",
            "|    ep_rew_mean          | 18.7         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 388          |\n",
            "|    time_elapsed         | 2873         |\n",
            "|    total_timesteps      | 1589248      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016433463 |\n",
            "|    clip_fraction        | 0.0427       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.55         |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.46         |\n",
            "|    n_updates            | 7740         |\n",
            "|    policy_gradient_loss | -0.00403     |\n",
            "|    value_loss           | 7.59         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 128          |\n",
            "|    ep_rew_mean          | 19.7         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 389          |\n",
            "|    time_elapsed         | 2880         |\n",
            "|    total_timesteps      | 1593344      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017531198 |\n",
            "|    clip_fraction        | 0.0527       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.51         |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 2.9          |\n",
            "|    n_updates            | 7760         |\n",
            "|    policy_gradient_loss | -0.00409     |\n",
            "|    value_loss           | 7.29         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 128          |\n",
            "|    ep_rew_mean          | 20.2         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 390          |\n",
            "|    time_elapsed         | 2887         |\n",
            "|    total_timesteps      | 1597440      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0014443075 |\n",
            "|    clip_fraction        | 0.0486       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.466        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 2.98         |\n",
            "|    n_updates            | 7780         |\n",
            "|    policy_gradient_loss | -0.00395     |\n",
            "|    value_loss           | 7.48         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 127          |\n",
            "|    ep_rew_mean          | 20.2         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 391          |\n",
            "|    time_elapsed         | 2895         |\n",
            "|    total_timesteps      | 1601536      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0014707593 |\n",
            "|    clip_fraction        | 0.0411       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.572        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 2.74         |\n",
            "|    n_updates            | 7800         |\n",
            "|    policy_gradient_loss | -0.00458     |\n",
            "|    value_loss           | 6.16         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 129          |\n",
            "|    ep_rew_mean          | 20.5         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 392          |\n",
            "|    time_elapsed         | 2902         |\n",
            "|    total_timesteps      | 1605632      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016779139 |\n",
            "|    clip_fraction        | 0.0498       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.528        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 2.56         |\n",
            "|    n_updates            | 7820         |\n",
            "|    policy_gradient_loss | -0.00445     |\n",
            "|    value_loss           | 7.46         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 129          |\n",
            "|    ep_rew_mean          | 21.2         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 393          |\n",
            "|    time_elapsed         | 2910         |\n",
            "|    total_timesteps      | 1609728      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0013665988 |\n",
            "|    clip_fraction        | 0.0343       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.304        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.79         |\n",
            "|    n_updates            | 7840         |\n",
            "|    policy_gradient_loss | -0.00304     |\n",
            "|    value_loss           | 9.8          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 132          |\n",
            "|    ep_rew_mean          | 22.3         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 394          |\n",
            "|    time_elapsed         | 2917         |\n",
            "|    total_timesteps      | 1613824      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018818281 |\n",
            "|    clip_fraction        | 0.0632       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.28         |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.53         |\n",
            "|    n_updates            | 7860         |\n",
            "|    policy_gradient_loss | -0.00627     |\n",
            "|    value_loss           | 8.97         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 129          |\n",
            "|    ep_rew_mean          | 22           |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 395          |\n",
            "|    time_elapsed         | 2925         |\n",
            "|    total_timesteps      | 1617920      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0020225546 |\n",
            "|    clip_fraction        | 0.0668       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.358        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 4.56         |\n",
            "|    n_updates            | 7880         |\n",
            "|    policy_gradient_loss | -0.00485     |\n",
            "|    value_loss           | 9.79         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 132          |\n",
            "|    ep_rew_mean          | 22.4         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 396          |\n",
            "|    time_elapsed         | 2932         |\n",
            "|    total_timesteps      | 1622016      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015201925 |\n",
            "|    clip_fraction        | 0.0457       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.409        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 2.99         |\n",
            "|    n_updates            | 7900         |\n",
            "|    policy_gradient_loss | -0.00458     |\n",
            "|    value_loss           | 7.39         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 130          |\n",
            "|    ep_rew_mean          | 21.6         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 397          |\n",
            "|    time_elapsed         | 2939         |\n",
            "|    total_timesteps      | 1626112      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018255205 |\n",
            "|    clip_fraction        | 0.0676       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.428        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.74         |\n",
            "|    n_updates            | 7920         |\n",
            "|    policy_gradient_loss | -0.00483     |\n",
            "|    value_loss           | 8.93         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 134          |\n",
            "|    ep_rew_mean          | 21.2         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 398          |\n",
            "|    time_elapsed         | 2947         |\n",
            "|    total_timesteps      | 1630208      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015297593 |\n",
            "|    clip_fraction        | 0.0363       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.31        |\n",
            "|    explained_variance   | 0.432        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.32         |\n",
            "|    n_updates            | 7940         |\n",
            "|    policy_gradient_loss | -0.0031      |\n",
            "|    value_loss           | 7.73         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 135          |\n",
            "|    ep_rew_mean          | 21.9         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 399          |\n",
            "|    time_elapsed         | 2954         |\n",
            "|    total_timesteps      | 1634304      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0012632319 |\n",
            "|    clip_fraction        | 0.0368       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.539        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.21         |\n",
            "|    n_updates            | 7960         |\n",
            "|    policy_gradient_loss | -0.00394     |\n",
            "|    value_loss           | 7.79         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 133          |\n",
            "|    ep_rew_mean          | 21.3         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 400          |\n",
            "|    time_elapsed         | 2962         |\n",
            "|    total_timesteps      | 1638400      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0014650438 |\n",
            "|    clip_fraction        | 0.0327       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.471        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.46         |\n",
            "|    n_updates            | 7980         |\n",
            "|    policy_gradient_loss | -0.00273     |\n",
            "|    value_loss           | 8.92         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 128          |\n",
            "|    ep_rew_mean          | 20.5         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 401          |\n",
            "|    time_elapsed         | 2969         |\n",
            "|    total_timesteps      | 1642496      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016600941 |\n",
            "|    clip_fraction        | 0.051        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.474        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.53         |\n",
            "|    n_updates            | 8000         |\n",
            "|    policy_gradient_loss | -0.0043      |\n",
            "|    value_loss           | 8.87         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 125          |\n",
            "|    ep_rew_mean          | 18.4         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 402          |\n",
            "|    time_elapsed         | 2976         |\n",
            "|    total_timesteps      | 1646592      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016095438 |\n",
            "|    clip_fraction        | 0.0453       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.548        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 2.85         |\n",
            "|    n_updates            | 8020         |\n",
            "|    policy_gradient_loss | -0.00446     |\n",
            "|    value_loss           | 6.81         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 128          |\n",
            "|    ep_rew_mean          | 18.4         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 403          |\n",
            "|    time_elapsed         | 2984         |\n",
            "|    total_timesteps      | 1650688      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018727991 |\n",
            "|    clip_fraction        | 0.0566       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.575        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.3          |\n",
            "|    n_updates            | 8040         |\n",
            "|    policy_gradient_loss | -0.0046      |\n",
            "|    value_loss           | 7.55         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 131          |\n",
            "|    ep_rew_mean          | 18.5         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 404          |\n",
            "|    time_elapsed         | 2991         |\n",
            "|    total_timesteps      | 1654784      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016273423 |\n",
            "|    clip_fraction        | 0.0532       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.31        |\n",
            "|    explained_variance   | 0.527        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.33         |\n",
            "|    n_updates            | 8060         |\n",
            "|    policy_gradient_loss | -0.00461     |\n",
            "|    value_loss           | 7.45         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 133         |\n",
            "|    ep_rew_mean          | 18.5        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 553         |\n",
            "|    iterations           | 405         |\n",
            "|    time_elapsed         | 2999        |\n",
            "|    total_timesteps      | 1658880     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001730248 |\n",
            "|    clip_fraction        | 0.0542      |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.3        |\n",
            "|    explained_variance   | 0.477       |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 3.71        |\n",
            "|    n_updates            | 8080        |\n",
            "|    policy_gradient_loss | -0.00464    |\n",
            "|    value_loss           | 8.03        |\n",
            "-----------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 138         |\n",
            "|    ep_rew_mean          | 20.8        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 553         |\n",
            "|    iterations           | 406         |\n",
            "|    time_elapsed         | 3006        |\n",
            "|    total_timesteps      | 1662976     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001513234 |\n",
            "|    clip_fraction        | 0.0454      |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.29       |\n",
            "|    explained_variance   | 0.507       |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 3.44        |\n",
            "|    n_updates            | 8100        |\n",
            "|    policy_gradient_loss | -0.00467    |\n",
            "|    value_loss           | 7.81        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 136          |\n",
            "|    ep_rew_mean          | 20.8         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 407          |\n",
            "|    time_elapsed         | 3013         |\n",
            "|    total_timesteps      | 1667072      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0014887201 |\n",
            "|    clip_fraction        | 0.0457       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.417        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.71         |\n",
            "|    n_updates            | 8120         |\n",
            "|    policy_gradient_loss | -0.00394     |\n",
            "|    value_loss           | 8.28         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 137          |\n",
            "|    ep_rew_mean          | 22.2         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 408          |\n",
            "|    time_elapsed         | 3021         |\n",
            "|    total_timesteps      | 1671168      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016132019 |\n",
            "|    clip_fraction        | 0.0332       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.525        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 2.96         |\n",
            "|    n_updates            | 8140         |\n",
            "|    policy_gradient_loss | -0.00289     |\n",
            "|    value_loss           | 6.42         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 132          |\n",
            "|    ep_rew_mean          | 20.9         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 409          |\n",
            "|    time_elapsed         | 3028         |\n",
            "|    total_timesteps      | 1675264      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0014868494 |\n",
            "|    clip_fraction        | 0.0349       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.403        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.77         |\n",
            "|    n_updates            | 8160         |\n",
            "|    policy_gradient_loss | -0.00345     |\n",
            "|    value_loss           | 8.56         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 130          |\n",
            "|    ep_rew_mean          | 20.8         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 410          |\n",
            "|    time_elapsed         | 3036         |\n",
            "|    total_timesteps      | 1679360      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016765607 |\n",
            "|    clip_fraction        | 0.0476       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.465        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 2.94         |\n",
            "|    n_updates            | 8180         |\n",
            "|    policy_gradient_loss | -0.00392     |\n",
            "|    value_loss           | 7.7          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 124          |\n",
            "|    ep_rew_mean          | 19.2         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 411          |\n",
            "|    time_elapsed         | 3043         |\n",
            "|    total_timesteps      | 1683456      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017570814 |\n",
            "|    clip_fraction        | 0.0582       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.414        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.32         |\n",
            "|    n_updates            | 8200         |\n",
            "|    policy_gradient_loss | -0.00551     |\n",
            "|    value_loss           | 8.2          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 128          |\n",
            "|    ep_rew_mean          | 20.1         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 412          |\n",
            "|    time_elapsed         | 3051         |\n",
            "|    total_timesteps      | 1687552      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016246665 |\n",
            "|    clip_fraction        | 0.0487       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.451        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 2.42         |\n",
            "|    n_updates            | 8220         |\n",
            "|    policy_gradient_loss | -0.00434     |\n",
            "|    value_loss           | 6.94         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 126          |\n",
            "|    ep_rew_mean          | 20.2         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 413          |\n",
            "|    time_elapsed         | 3058         |\n",
            "|    total_timesteps      | 1691648      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0019327991 |\n",
            "|    clip_fraction        | 0.0585       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.403        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.4          |\n",
            "|    n_updates            | 8240         |\n",
            "|    policy_gradient_loss | -0.00493     |\n",
            "|    value_loss           | 8.64         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 130          |\n",
            "|    ep_rew_mean          | 21.1         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 414          |\n",
            "|    time_elapsed         | 3065         |\n",
            "|    total_timesteps      | 1695744      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015731899 |\n",
            "|    clip_fraction        | 0.0504       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.523        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 2.5          |\n",
            "|    n_updates            | 8260         |\n",
            "|    policy_gradient_loss | -0.0039      |\n",
            "|    value_loss           | 6.76         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 125          |\n",
            "|    ep_rew_mean          | 20.6         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 415          |\n",
            "|    time_elapsed         | 3073         |\n",
            "|    total_timesteps      | 1699840      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016356332 |\n",
            "|    clip_fraction        | 0.0506       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.528        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.1          |\n",
            "|    n_updates            | 8280         |\n",
            "|    policy_gradient_loss | -0.00478     |\n",
            "|    value_loss           | 7.44         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 129         |\n",
            "|    ep_rew_mean          | 20.2        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 553         |\n",
            "|    iterations           | 416         |\n",
            "|    time_elapsed         | 3080        |\n",
            "|    total_timesteps      | 1703936     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001365937 |\n",
            "|    clip_fraction        | 0.0378      |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.3        |\n",
            "|    explained_variance   | 0.526       |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 3.21        |\n",
            "|    n_updates            | 8300        |\n",
            "|    policy_gradient_loss | -0.00321    |\n",
            "|    value_loss           | 7.88        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 127          |\n",
            "|    ep_rew_mean          | 19.1         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 417          |\n",
            "|    time_elapsed         | 3087         |\n",
            "|    total_timesteps      | 1708032      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0014415354 |\n",
            "|    clip_fraction        | 0.0541       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.341        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 4.51         |\n",
            "|    n_updates            | 8320         |\n",
            "|    policy_gradient_loss | -0.0048      |\n",
            "|    value_loss           | 11.3         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 129          |\n",
            "|    ep_rew_mean          | 18.7         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 418          |\n",
            "|    time_elapsed         | 3095         |\n",
            "|    total_timesteps      | 1712128      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018038601 |\n",
            "|    clip_fraction        | 0.051        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.473        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.49         |\n",
            "|    n_updates            | 8340         |\n",
            "|    policy_gradient_loss | -0.00441     |\n",
            "|    value_loss           | 6.97         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 129          |\n",
            "|    ep_rew_mean          | 18.9         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 419          |\n",
            "|    time_elapsed         | 3102         |\n",
            "|    total_timesteps      | 1716224      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0019459103 |\n",
            "|    clip_fraction        | 0.0741       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.42         |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 2.72         |\n",
            "|    n_updates            | 8360         |\n",
            "|    policy_gradient_loss | -0.00496     |\n",
            "|    value_loss           | 7.71         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 126          |\n",
            "|    ep_rew_mean          | 18.9         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 420          |\n",
            "|    time_elapsed         | 3109         |\n",
            "|    total_timesteps      | 1720320      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016433318 |\n",
            "|    clip_fraction        | 0.0474       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.476        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 2.55         |\n",
            "|    n_updates            | 8380         |\n",
            "|    policy_gradient_loss | -0.00426     |\n",
            "|    value_loss           | 6.53         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 128         |\n",
            "|    ep_rew_mean          | 19.8        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 553         |\n",
            "|    iterations           | 421         |\n",
            "|    time_elapsed         | 3117        |\n",
            "|    total_timesteps      | 1724416     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001980411 |\n",
            "|    clip_fraction        | 0.0569      |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.31       |\n",
            "|    explained_variance   | 0.435       |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 2.61        |\n",
            "|    n_updates            | 8400        |\n",
            "|    policy_gradient_loss | -0.0043     |\n",
            "|    value_loss           | 6.79        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 129          |\n",
            "|    ep_rew_mean          | 20.3         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 422          |\n",
            "|    time_elapsed         | 3124         |\n",
            "|    total_timesteps      | 1728512      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018753342 |\n",
            "|    clip_fraction        | 0.0615       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.31        |\n",
            "|    explained_variance   | 0.439        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 2.73         |\n",
            "|    n_updates            | 8420         |\n",
            "|    policy_gradient_loss | -0.00457     |\n",
            "|    value_loss           | 8.11         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 131          |\n",
            "|    ep_rew_mean          | 21.2         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 423          |\n",
            "|    time_elapsed         | 3132         |\n",
            "|    total_timesteps      | 1732608      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015877474 |\n",
            "|    clip_fraction        | 0.0616       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.31        |\n",
            "|    explained_variance   | 0.387        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.39         |\n",
            "|    n_updates            | 8440         |\n",
            "|    policy_gradient_loss | -0.00474     |\n",
            "|    value_loss           | 8.04         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 132          |\n",
            "|    ep_rew_mean          | 21.5         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 424          |\n",
            "|    time_elapsed         | 3139         |\n",
            "|    total_timesteps      | 1736704      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0014350028 |\n",
            "|    clip_fraction        | 0.0339       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.31        |\n",
            "|    explained_variance   | 0.315        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.65         |\n",
            "|    n_updates            | 8460         |\n",
            "|    policy_gradient_loss | -0.00403     |\n",
            "|    value_loss           | 9.01         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 128          |\n",
            "|    ep_rew_mean          | 19.6         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 425          |\n",
            "|    time_elapsed         | 3146         |\n",
            "|    total_timesteps      | 1740800      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015858077 |\n",
            "|    clip_fraction        | 0.0464       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.525        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 2.4          |\n",
            "|    n_updates            | 8480         |\n",
            "|    policy_gradient_loss | -0.0046      |\n",
            "|    value_loss           | 6.31         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 133          |\n",
            "|    ep_rew_mean          | 21.1         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 426          |\n",
            "|    time_elapsed         | 3154         |\n",
            "|    total_timesteps      | 1744896      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018371707 |\n",
            "|    clip_fraction        | 0.062        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.439        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.93         |\n",
            "|    n_updates            | 8500         |\n",
            "|    policy_gradient_loss | -0.00519     |\n",
            "|    value_loss           | 8.55         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 131          |\n",
            "|    ep_rew_mean          | 20.1         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 427          |\n",
            "|    time_elapsed         | 3161         |\n",
            "|    total_timesteps      | 1748992      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0014579825 |\n",
            "|    clip_fraction        | 0.0403       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.369        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 4.42         |\n",
            "|    n_updates            | 8520         |\n",
            "|    policy_gradient_loss | -0.00418     |\n",
            "|    value_loss           | 11           |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 129         |\n",
            "|    ep_rew_mean          | 21.2        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 553         |\n",
            "|    iterations           | 428         |\n",
            "|    time_elapsed         | 3169        |\n",
            "|    total_timesteps      | 1753088     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001359668 |\n",
            "|    clip_fraction        | 0.0461      |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.3        |\n",
            "|    explained_variance   | 0.367       |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 3.42        |\n",
            "|    n_updates            | 8540        |\n",
            "|    policy_gradient_loss | -0.00444    |\n",
            "|    value_loss           | 8.71        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 121          |\n",
            "|    ep_rew_mean          | 19           |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 429          |\n",
            "|    time_elapsed         | 3176         |\n",
            "|    total_timesteps      | 1757184      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016879542 |\n",
            "|    clip_fraction        | 0.0436       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.318        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.59         |\n",
            "|    n_updates            | 8560         |\n",
            "|    policy_gradient_loss | -0.00447     |\n",
            "|    value_loss           | 8.41         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 122         |\n",
            "|    ep_rew_mean          | 19.6        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 553         |\n",
            "|    iterations           | 430         |\n",
            "|    time_elapsed         | 3183        |\n",
            "|    total_timesteps      | 1761280     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001612234 |\n",
            "|    clip_fraction        | 0.0499      |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.3        |\n",
            "|    explained_variance   | 0.417       |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 3.47        |\n",
            "|    n_updates            | 8580        |\n",
            "|    policy_gradient_loss | -0.00464    |\n",
            "|    value_loss           | 7.68        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 126          |\n",
            "|    ep_rew_mean          | 20.1         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 431          |\n",
            "|    time_elapsed         | 3191         |\n",
            "|    total_timesteps      | 1765376      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018498782 |\n",
            "|    clip_fraction        | 0.0538       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.425        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.71         |\n",
            "|    n_updates            | 8600         |\n",
            "|    policy_gradient_loss | -0.00545     |\n",
            "|    value_loss           | 7.99         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 128          |\n",
            "|    ep_rew_mean          | 21           |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 432          |\n",
            "|    time_elapsed         | 3198         |\n",
            "|    total_timesteps      | 1769472      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015131726 |\n",
            "|    clip_fraction        | 0.0481       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.487        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 2.73         |\n",
            "|    n_updates            | 8620         |\n",
            "|    policy_gradient_loss | -0.00456     |\n",
            "|    value_loss           | 6.87         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 126          |\n",
            "|    ep_rew_mean          | 20.7         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 433          |\n",
            "|    time_elapsed         | 3205         |\n",
            "|    total_timesteps      | 1773568      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015566101 |\n",
            "|    clip_fraction        | 0.0416       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.447        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.45         |\n",
            "|    n_updates            | 8640         |\n",
            "|    policy_gradient_loss | -0.00363     |\n",
            "|    value_loss           | 8.78         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 128          |\n",
            "|    ep_rew_mean          | 20.4         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 434          |\n",
            "|    time_elapsed         | 3213         |\n",
            "|    total_timesteps      | 1777664      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018759607 |\n",
            "|    clip_fraction        | 0.0535       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.28        |\n",
            "|    explained_variance   | 0.542        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 2.7          |\n",
            "|    n_updates            | 8660         |\n",
            "|    policy_gradient_loss | -0.00599     |\n",
            "|    value_loss           | 7.32         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 130          |\n",
            "|    ep_rew_mean          | 21.2         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 435          |\n",
            "|    time_elapsed         | 3220         |\n",
            "|    total_timesteps      | 1781760      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0019312619 |\n",
            "|    clip_fraction        | 0.0487       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.59         |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 2.96         |\n",
            "|    n_updates            | 8680         |\n",
            "|    policy_gradient_loss | -0.00433     |\n",
            "|    value_loss           | 6.87         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 130          |\n",
            "|    ep_rew_mean          | 21.7         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 436          |\n",
            "|    time_elapsed         | 3227         |\n",
            "|    total_timesteps      | 1785856      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0012737277 |\n",
            "|    clip_fraction        | 0.0335       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.554        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.62         |\n",
            "|    n_updates            | 8700         |\n",
            "|    policy_gradient_loss | -0.0025      |\n",
            "|    value_loss           | 8.61         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 130          |\n",
            "|    ep_rew_mean          | 23.1         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 437          |\n",
            "|    time_elapsed         | 3235         |\n",
            "|    total_timesteps      | 1789952      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0020230475 |\n",
            "|    clip_fraction        | 0.0598       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.486        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.16         |\n",
            "|    n_updates            | 8720         |\n",
            "|    policy_gradient_loss | -0.00373     |\n",
            "|    value_loss           | 7.99         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 127          |\n",
            "|    ep_rew_mean          | 21.7         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 438          |\n",
            "|    time_elapsed         | 3242         |\n",
            "|    total_timesteps      | 1794048      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018715671 |\n",
            "|    clip_fraction        | 0.0634       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.56         |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.57         |\n",
            "|    n_updates            | 8740         |\n",
            "|    policy_gradient_loss | -0.00454     |\n",
            "|    value_loss           | 8.23         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 128          |\n",
            "|    ep_rew_mean          | 21.9         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 439          |\n",
            "|    time_elapsed         | 3250         |\n",
            "|    total_timesteps      | 1798144      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018756452 |\n",
            "|    clip_fraction        | 0.0571       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.524        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.62         |\n",
            "|    n_updates            | 8760         |\n",
            "|    policy_gradient_loss | -0.00468     |\n",
            "|    value_loss           | 8.46         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 130          |\n",
            "|    ep_rew_mean          | 20.7         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 440          |\n",
            "|    time_elapsed         | 3257         |\n",
            "|    total_timesteps      | 1802240      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016313246 |\n",
            "|    clip_fraction        | 0.0478       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.438        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.36         |\n",
            "|    n_updates            | 8780         |\n",
            "|    policy_gradient_loss | -0.00445     |\n",
            "|    value_loss           | 8.1          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 134          |\n",
            "|    ep_rew_mean          | 21.1         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 441          |\n",
            "|    time_elapsed         | 3265         |\n",
            "|    total_timesteps      | 1806336      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0012314102 |\n",
            "|    clip_fraction        | 0.0381       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.473        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.76         |\n",
            "|    n_updates            | 8800         |\n",
            "|    policy_gradient_loss | -0.00389     |\n",
            "|    value_loss           | 9.44         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 130          |\n",
            "|    ep_rew_mean          | 19.2         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 442          |\n",
            "|    time_elapsed         | 3272         |\n",
            "|    total_timesteps      | 1810432      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015815524 |\n",
            "|    clip_fraction        | 0.0387       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.435        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.98         |\n",
            "|    n_updates            | 8820         |\n",
            "|    policy_gradient_loss | -0.00413     |\n",
            "|    value_loss           | 9.3          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 130          |\n",
            "|    ep_rew_mean          | 20.2         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 443          |\n",
            "|    time_elapsed         | 3279         |\n",
            "|    total_timesteps      | 1814528      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0013951871 |\n",
            "|    clip_fraction        | 0.0384       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.471        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.04         |\n",
            "|    n_updates            | 8840         |\n",
            "|    policy_gradient_loss | -0.00416     |\n",
            "|    value_loss           | 8.03         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 127          |\n",
            "|    ep_rew_mean          | 20.1         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 444          |\n",
            "|    time_elapsed         | 3287         |\n",
            "|    total_timesteps      | 1818624      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015182537 |\n",
            "|    clip_fraction        | 0.0326       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.435        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.19         |\n",
            "|    n_updates            | 8860         |\n",
            "|    policy_gradient_loss | -0.00321     |\n",
            "|    value_loss           | 8.86         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 130          |\n",
            "|    ep_rew_mean          | 20.6         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 445          |\n",
            "|    time_elapsed         | 3294         |\n",
            "|    total_timesteps      | 1822720      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0014634305 |\n",
            "|    clip_fraction        | 0.0401       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.47         |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 4.44         |\n",
            "|    n_updates            | 8880         |\n",
            "|    policy_gradient_loss | -0.00481     |\n",
            "|    value_loss           | 9.07         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 133          |\n",
            "|    ep_rew_mean          | 21.6         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 446          |\n",
            "|    time_elapsed         | 3301         |\n",
            "|    total_timesteps      | 1826816      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0021123933 |\n",
            "|    clip_fraction        | 0.0648       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.516        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 2.38         |\n",
            "|    n_updates            | 8900         |\n",
            "|    policy_gradient_loss | -0.00501     |\n",
            "|    value_loss           | 6.72         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 132          |\n",
            "|    ep_rew_mean          | 21.4         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 447          |\n",
            "|    time_elapsed         | 3309         |\n",
            "|    total_timesteps      | 1830912      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017526101 |\n",
            "|    clip_fraction        | 0.0546       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.355        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.49         |\n",
            "|    n_updates            | 8920         |\n",
            "|    policy_gradient_loss | -0.0048      |\n",
            "|    value_loss           | 9.3          |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 130          |\n",
            "|    ep_rew_mean          | 21.2         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 448          |\n",
            "|    time_elapsed         | 3316         |\n",
            "|    total_timesteps      | 1835008      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018994047 |\n",
            "|    clip_fraction        | 0.0747       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.438        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.38         |\n",
            "|    n_updates            | 8940         |\n",
            "|    policy_gradient_loss | -0.00655     |\n",
            "|    value_loss           | 9.05         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 126          |\n",
            "|    ep_rew_mean          | 19.5         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 449          |\n",
            "|    time_elapsed         | 3324         |\n",
            "|    total_timesteps      | 1839104      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015281041 |\n",
            "|    clip_fraction        | 0.0424       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.514        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.12         |\n",
            "|    n_updates            | 8960         |\n",
            "|    policy_gradient_loss | -0.00498     |\n",
            "|    value_loss           | 7.59         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 130          |\n",
            "|    ep_rew_mean          | 19.7         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 450          |\n",
            "|    time_elapsed         | 3331         |\n",
            "|    total_timesteps      | 1843200      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016858052 |\n",
            "|    clip_fraction        | 0.0475       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.274        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 4.69         |\n",
            "|    n_updates            | 8980         |\n",
            "|    policy_gradient_loss | -0.00451     |\n",
            "|    value_loss           | 10.6         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 126          |\n",
            "|    ep_rew_mean          | 19.4         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 451          |\n",
            "|    time_elapsed         | 3338         |\n",
            "|    total_timesteps      | 1847296      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0019695424 |\n",
            "|    clip_fraction        | 0.0475       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.405        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.24         |\n",
            "|    n_updates            | 9000         |\n",
            "|    policy_gradient_loss | -0.00556     |\n",
            "|    value_loss           | 7.79         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 129          |\n",
            "|    ep_rew_mean          | 20           |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 452          |\n",
            "|    time_elapsed         | 3346         |\n",
            "|    total_timesteps      | 1851392      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016864019 |\n",
            "|    clip_fraction        | 0.0428       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.434        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.36         |\n",
            "|    n_updates            | 9020         |\n",
            "|    policy_gradient_loss | -0.0041      |\n",
            "|    value_loss           | 7.57         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 129          |\n",
            "|    ep_rew_mean          | 20           |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 453          |\n",
            "|    time_elapsed         | 3353         |\n",
            "|    total_timesteps      | 1855488      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015783783 |\n",
            "|    clip_fraction        | 0.0681       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.572        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 2.94         |\n",
            "|    n_updates            | 9040         |\n",
            "|    policy_gradient_loss | -0.00422     |\n",
            "|    value_loss           | 7.43         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 131          |\n",
            "|    ep_rew_mean          | 21.2         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 454          |\n",
            "|    time_elapsed         | 3361         |\n",
            "|    total_timesteps      | 1859584      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018084827 |\n",
            "|    clip_fraction        | 0.0534       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.571        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.42         |\n",
            "|    n_updates            | 9060         |\n",
            "|    policy_gradient_loss | -0.00467     |\n",
            "|    value_loss           | 7.89         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 130          |\n",
            "|    ep_rew_mean          | 21.3         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 455          |\n",
            "|    time_elapsed         | 3368         |\n",
            "|    total_timesteps      | 1863680      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016908774 |\n",
            "|    clip_fraction        | 0.0526       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.31        |\n",
            "|    explained_variance   | 0.434        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.36         |\n",
            "|    n_updates            | 9080         |\n",
            "|    policy_gradient_loss | -0.00414     |\n",
            "|    value_loss           | 8.37         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 127          |\n",
            "|    ep_rew_mean          | 19.9         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 456          |\n",
            "|    time_elapsed         | 3376         |\n",
            "|    total_timesteps      | 1867776      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0014839567 |\n",
            "|    clip_fraction        | 0.0398       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.488        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.11         |\n",
            "|    n_updates            | 9100         |\n",
            "|    policy_gradient_loss | -0.0041      |\n",
            "|    value_loss           | 6.91         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 131          |\n",
            "|    ep_rew_mean          | 19.7         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 457          |\n",
            "|    time_elapsed         | 3383         |\n",
            "|    total_timesteps      | 1871872      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018418275 |\n",
            "|    clip_fraction        | 0.0536       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.522        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.03         |\n",
            "|    n_updates            | 9120         |\n",
            "|    policy_gradient_loss | -0.00465     |\n",
            "|    value_loss           | 6.97         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 131          |\n",
            "|    ep_rew_mean          | 19.8         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 458          |\n",
            "|    time_elapsed         | 3390         |\n",
            "|    total_timesteps      | 1875968      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015803365 |\n",
            "|    clip_fraction        | 0.0599       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.31        |\n",
            "|    explained_variance   | 0.563        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3            |\n",
            "|    n_updates            | 9140         |\n",
            "|    policy_gradient_loss | -0.00481     |\n",
            "|    value_loss           | 6.74         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 133          |\n",
            "|    ep_rew_mean          | 21.4         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 459          |\n",
            "|    time_elapsed         | 3398         |\n",
            "|    total_timesteps      | 1880064      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018675387 |\n",
            "|    clip_fraction        | 0.0697       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.31        |\n",
            "|    explained_variance   | 0.52         |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.96         |\n",
            "|    n_updates            | 9160         |\n",
            "|    policy_gradient_loss | -0.00483     |\n",
            "|    value_loss           | 7.83         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 133         |\n",
            "|    ep_rew_mean          | 21.2        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 553         |\n",
            "|    iterations           | 460         |\n",
            "|    time_elapsed         | 3405        |\n",
            "|    total_timesteps      | 1884160     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001499814 |\n",
            "|    clip_fraction        | 0.0475      |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.31       |\n",
            "|    explained_variance   | 0.521       |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 2.91        |\n",
            "|    n_updates            | 9180        |\n",
            "|    policy_gradient_loss | -0.00514    |\n",
            "|    value_loss           | 7.17        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 131          |\n",
            "|    ep_rew_mean          | 20.1         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 461          |\n",
            "|    time_elapsed         | 3413         |\n",
            "|    total_timesteps      | 1888256      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0019364199 |\n",
            "|    clip_fraction        | 0.0659       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.31        |\n",
            "|    explained_variance   | 0.419        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.9          |\n",
            "|    n_updates            | 9200         |\n",
            "|    policy_gradient_loss | -0.00492     |\n",
            "|    value_loss           | 9.09         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 128          |\n",
            "|    ep_rew_mean          | 19.8         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 462          |\n",
            "|    time_elapsed         | 3420         |\n",
            "|    total_timesteps      | 1892352      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0014792056 |\n",
            "|    clip_fraction        | 0.0473       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.31        |\n",
            "|    explained_variance   | 0.516        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.54         |\n",
            "|    n_updates            | 9220         |\n",
            "|    policy_gradient_loss | -0.00569     |\n",
            "|    value_loss           | 7.42         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 124          |\n",
            "|    ep_rew_mean          | 19.2         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 463          |\n",
            "|    time_elapsed         | 3427         |\n",
            "|    total_timesteps      | 1896448      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016482144 |\n",
            "|    clip_fraction        | 0.0403       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.427        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 4.39         |\n",
            "|    n_updates            | 9240         |\n",
            "|    policy_gradient_loss | -0.0047      |\n",
            "|    value_loss           | 9.42         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 125          |\n",
            "|    ep_rew_mean          | 20.2         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 464          |\n",
            "|    time_elapsed         | 3435         |\n",
            "|    total_timesteps      | 1900544      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0019354722 |\n",
            "|    clip_fraction        | 0.0674       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.475        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 2.95         |\n",
            "|    n_updates            | 9260         |\n",
            "|    policy_gradient_loss | -0.00542     |\n",
            "|    value_loss           | 7.62         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 129          |\n",
            "|    ep_rew_mean          | 19.4         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 465          |\n",
            "|    time_elapsed         | 3442         |\n",
            "|    total_timesteps      | 1904640      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0020145355 |\n",
            "|    clip_fraction        | 0.0798       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.368        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.94         |\n",
            "|    n_updates            | 9280         |\n",
            "|    policy_gradient_loss | -0.00519     |\n",
            "|    value_loss           | 9.05         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 133          |\n",
            "|    ep_rew_mean          | 20.4         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 466          |\n",
            "|    time_elapsed         | 3449         |\n",
            "|    total_timesteps      | 1908736      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0019388867 |\n",
            "|    clip_fraction        | 0.0589       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.31        |\n",
            "|    explained_variance   | 0.421        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 2.97         |\n",
            "|    n_updates            | 9300         |\n",
            "|    policy_gradient_loss | -0.00527     |\n",
            "|    value_loss           | 6.97         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 139          |\n",
            "|    ep_rew_mean          | 21.1         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 467          |\n",
            "|    time_elapsed         | 3457         |\n",
            "|    total_timesteps      | 1912832      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016071885 |\n",
            "|    clip_fraction        | 0.0391       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.31        |\n",
            "|    explained_variance   | 0.476        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.02         |\n",
            "|    n_updates            | 9320         |\n",
            "|    policy_gradient_loss | -0.00408     |\n",
            "|    value_loss           | 6.97         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 137          |\n",
            "|    ep_rew_mean          | 21.2         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 468          |\n",
            "|    time_elapsed         | 3464         |\n",
            "|    total_timesteps      | 1916928      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0021254634 |\n",
            "|    clip_fraction        | 0.0961       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.31        |\n",
            "|    explained_variance   | 0.438        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.78         |\n",
            "|    n_updates            | 9340         |\n",
            "|    policy_gradient_loss | -0.00607     |\n",
            "|    value_loss           | 8.58         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 140          |\n",
            "|    ep_rew_mean          | 22.1         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 469          |\n",
            "|    time_elapsed         | 3471         |\n",
            "|    total_timesteps      | 1921024      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015009079 |\n",
            "|    clip_fraction        | 0.0337       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.31        |\n",
            "|    explained_variance   | 0.324        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 4.05         |\n",
            "|    n_updates            | 9360         |\n",
            "|    policy_gradient_loss | -0.00401     |\n",
            "|    value_loss           | 9.11         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 147          |\n",
            "|    ep_rew_mean          | 23.2         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 470          |\n",
            "|    time_elapsed         | 3479         |\n",
            "|    total_timesteps      | 1925120      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017235719 |\n",
            "|    clip_fraction        | 0.0487       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.28         |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 4.1          |\n",
            "|    n_updates            | 9380         |\n",
            "|    policy_gradient_loss | -0.00444     |\n",
            "|    value_loss           | 8.84         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 134          |\n",
            "|    ep_rew_mean          | 21.1         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 471          |\n",
            "|    time_elapsed         | 3486         |\n",
            "|    total_timesteps      | 1929216      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0012902614 |\n",
            "|    clip_fraction        | 0.0181       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.302        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.92         |\n",
            "|    n_updates            | 9400         |\n",
            "|    policy_gradient_loss | -0.00323     |\n",
            "|    value_loss           | 9.51         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 138          |\n",
            "|    ep_rew_mean          | 22.7         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 472          |\n",
            "|    time_elapsed         | 3493         |\n",
            "|    total_timesteps      | 1933312      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016161005 |\n",
            "|    clip_fraction        | 0.0501       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.31        |\n",
            "|    explained_variance   | 0.529        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 2.91         |\n",
            "|    n_updates            | 9420         |\n",
            "|    policy_gradient_loss | -0.00413     |\n",
            "|    value_loss           | 6.63         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 130          |\n",
            "|    ep_rew_mean          | 20.6         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 473          |\n",
            "|    time_elapsed         | 3501         |\n",
            "|    total_timesteps      | 1937408      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0015325283 |\n",
            "|    clip_fraction        | 0.0458       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.44         |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 4.77         |\n",
            "|    n_updates            | 9440         |\n",
            "|    policy_gradient_loss | -0.00488     |\n",
            "|    value_loss           | 10           |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 132          |\n",
            "|    ep_rew_mean          | 20.9         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 474          |\n",
            "|    time_elapsed         | 3508         |\n",
            "|    total_timesteps      | 1941504      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016726999 |\n",
            "|    clip_fraction        | 0.0446       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.538        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.06         |\n",
            "|    n_updates            | 9460         |\n",
            "|    policy_gradient_loss | -0.00336     |\n",
            "|    value_loss           | 7.26         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 127          |\n",
            "|    ep_rew_mean          | 18.8         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 475          |\n",
            "|    time_elapsed         | 3516         |\n",
            "|    total_timesteps      | 1945600      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017708342 |\n",
            "|    clip_fraction        | 0.0619       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.551        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.03         |\n",
            "|    n_updates            | 9480         |\n",
            "|    policy_gradient_loss | -0.00641     |\n",
            "|    value_loss           | 7.72         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 127         |\n",
            "|    ep_rew_mean          | 19.9        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 553         |\n",
            "|    iterations           | 476         |\n",
            "|    time_elapsed         | 3523        |\n",
            "|    total_timesteps      | 1949696     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001610996 |\n",
            "|    clip_fraction        | 0.0525      |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.3        |\n",
            "|    explained_variance   | 0.512       |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 4.2         |\n",
            "|    n_updates            | 9500        |\n",
            "|    policy_gradient_loss | -0.00448    |\n",
            "|    value_loss           | 8.17        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 129          |\n",
            "|    ep_rew_mean          | 20.6         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 477          |\n",
            "|    time_elapsed         | 3530         |\n",
            "|    total_timesteps      | 1953792      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016764125 |\n",
            "|    clip_fraction        | 0.0489       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.544        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.3          |\n",
            "|    n_updates            | 9520         |\n",
            "|    policy_gradient_loss | -0.00435     |\n",
            "|    value_loss           | 8.18         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 131         |\n",
            "|    ep_rew_mean          | 20.9        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 553         |\n",
            "|    iterations           | 478         |\n",
            "|    time_elapsed         | 3538        |\n",
            "|    total_timesteps      | 1957888     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.002254674 |\n",
            "|    clip_fraction        | 0.0717      |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.3        |\n",
            "|    explained_variance   | 0.407       |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 3.58        |\n",
            "|    n_updates            | 9540        |\n",
            "|    policy_gradient_loss | -0.00535    |\n",
            "|    value_loss           | 9.31        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 129          |\n",
            "|    ep_rew_mean          | 19.8         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 479          |\n",
            "|    time_elapsed         | 3545         |\n",
            "|    total_timesteps      | 1961984      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017368938 |\n",
            "|    clip_fraction        | 0.0503       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.544        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.24         |\n",
            "|    n_updates            | 9560         |\n",
            "|    policy_gradient_loss | -0.00502     |\n",
            "|    value_loss           | 6.83         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 128          |\n",
            "|    ep_rew_mean          | 19.4         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 480          |\n",
            "|    time_elapsed         | 3552         |\n",
            "|    total_timesteps      | 1966080      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0013176985 |\n",
            "|    clip_fraction        | 0.0293       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.443        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.89         |\n",
            "|    n_updates            | 9580         |\n",
            "|    policy_gradient_loss | -0.00377     |\n",
            "|    value_loss           | 8.38         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 125          |\n",
            "|    ep_rew_mean          | 18.1         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 481          |\n",
            "|    time_elapsed         | 3560         |\n",
            "|    total_timesteps      | 1970176      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017868653 |\n",
            "|    clip_fraction        | 0.0557       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.528        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.29         |\n",
            "|    n_updates            | 9600         |\n",
            "|    policy_gradient_loss | -0.00465     |\n",
            "|    value_loss           | 7.36         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 125          |\n",
            "|    ep_rew_mean          | 18.3         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 482          |\n",
            "|    time_elapsed         | 3567         |\n",
            "|    total_timesteps      | 1974272      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016062132 |\n",
            "|    clip_fraction        | 0.0502       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.429        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 4.09         |\n",
            "|    n_updates            | 9620         |\n",
            "|    policy_gradient_loss | -0.00512     |\n",
            "|    value_loss           | 9.19         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 126          |\n",
            "|    ep_rew_mean          | 19.3         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 483          |\n",
            "|    time_elapsed         | 3575         |\n",
            "|    total_timesteps      | 1978368      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017922453 |\n",
            "|    clip_fraction        | 0.0532       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.419        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.28         |\n",
            "|    n_updates            | 9640         |\n",
            "|    policy_gradient_loss | -0.00543     |\n",
            "|    value_loss           | 8.38         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 125          |\n",
            "|    ep_rew_mean          | 20.6         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 484          |\n",
            "|    time_elapsed         | 3582         |\n",
            "|    total_timesteps      | 1982464      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017143842 |\n",
            "|    clip_fraction        | 0.058        |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.304        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.94         |\n",
            "|    n_updates            | 9660         |\n",
            "|    policy_gradient_loss | -0.00437     |\n",
            "|    value_loss           | 10.7         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 125          |\n",
            "|    ep_rew_mean          | 19.7         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 485          |\n",
            "|    time_elapsed         | 3589         |\n",
            "|    total_timesteps      | 1986560      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0018469848 |\n",
            "|    clip_fraction        | 0.0693       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.443        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.55         |\n",
            "|    n_updates            | 9680         |\n",
            "|    policy_gradient_loss | -0.00594     |\n",
            "|    value_loss           | 7.73         |\n",
            "------------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 126          |\n",
            "|    ep_rew_mean          | 19.2         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 486          |\n",
            "|    time_elapsed         | 3597         |\n",
            "|    total_timesteps      | 1990656      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0017361763 |\n",
            "|    clip_fraction        | 0.0619       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.29        |\n",
            "|    explained_variance   | 0.471        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.34         |\n",
            "|    n_updates            | 9700         |\n",
            "|    policy_gradient_loss | -0.00561     |\n",
            "|    value_loss           | 7.24         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 126         |\n",
            "|    ep_rew_mean          | 18.8        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 553         |\n",
            "|    iterations           | 487         |\n",
            "|    time_elapsed         | 3604        |\n",
            "|    total_timesteps      | 1994752     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001813197 |\n",
            "|    clip_fraction        | 0.0622      |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.29       |\n",
            "|    explained_variance   | 0.474       |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 3.52        |\n",
            "|    n_updates            | 9720        |\n",
            "|    policy_gradient_loss | -0.00507    |\n",
            "|    value_loss           | 7.76        |\n",
            "-----------------------------------------\n",
            "------------------------------------------\n",
            "| rollout/                |              |\n",
            "|    ep_len_mean          | 132          |\n",
            "|    ep_rew_mean          | 20.8         |\n",
            "| time/                   |              |\n",
            "|    fps                  | 553          |\n",
            "|    iterations           | 488          |\n",
            "|    time_elapsed         | 3611         |\n",
            "|    total_timesteps      | 1998848      |\n",
            "| train/                  |              |\n",
            "|    approx_kl            | 0.0016611791 |\n",
            "|    clip_fraction        | 0.0488       |\n",
            "|    clip_range           | 0.1          |\n",
            "|    entropy_loss         | -1.3         |\n",
            "|    explained_variance   | 0.533        |\n",
            "|    learning_rate        | 0.0001       |\n",
            "|    loss                 | 3.79         |\n",
            "|    n_updates            | 9740         |\n",
            "|    policy_gradient_loss | -0.00444     |\n",
            "|    value_loss           | 8.34         |\n",
            "------------------------------------------\n",
            "-----------------------------------------\n",
            "| rollout/                |             |\n",
            "|    ep_len_mean          | 131         |\n",
            "|    ep_rew_mean          | 21.1        |\n",
            "| time/                   |             |\n",
            "|    fps                  | 553         |\n",
            "|    iterations           | 489         |\n",
            "|    time_elapsed         | 3619        |\n",
            "|    total_timesteps      | 2002944     |\n",
            "| train/                  |             |\n",
            "|    approx_kl            | 0.001367301 |\n",
            "|    clip_fraction        | 0.0339      |\n",
            "|    clip_range           | 0.1         |\n",
            "|    entropy_loss         | -1.3        |\n",
            "|    explained_variance   | 0.335       |\n",
            "|    learning_rate        | 0.0001      |\n",
            "|    loss                 | 4.23        |\n",
            "|    n_updates            | 9760        |\n",
            "|    policy_gradient_loss | -0.00378    |\n",
            "|    value_loss           | 9.54        |\n",
            "-----------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from stable_baselines3.common.preprocessing import preprocess_obs\n",
        "\n",
        "env_dbg = Game2048EnvV3()\n",
        "obs, info = env_dbg.reset()\n",
        "\n",
        "for i in range(5):\n",
        "    obs_tensor = torch.as_tensor([obs], device=model.device)\n",
        "    obs_tensor = preprocess_obs(obs_tensor, env_dbg.observation_space)\n",
        "\n",
        "    dist = model.policy.get_distribution(obs_tensor)\n",
        "    probs = dist.distribution.probs.detach().cpu().numpy()[0]\n",
        "\n",
        "    print(f\"Probs on state {i}: {probs}\")\n",
        "\n",
        "    # create new state\n",
        "    action = env_dbg.action_space.sample()\n",
        "    obs, _, done, _, _ = env_dbg.step(action)\n",
        "    if done:\n",
        "        obs, info = env_dbg.reset()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BnWGzbW4Z5Ay",
        "outputId": "51be4c7d-05a7-431b-94c1-f5b7420fd97c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Probs on state 0: [0.26067576 0.22560897 0.22320904 0.29050624]\n",
            "Probs on state 1: [0.18664004 0.33731905 0.13716367 0.33887723]\n",
            "Probs on state 2: [0.14637853 0.40725422 0.15866132 0.2877059 ]\n",
            "Probs on state 3: [0.11983611 0.4621226  0.31354755 0.10449384]\n",
            "Probs on state 4: [0.10891565 0.47009867 0.3245981  0.09638763]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2830357457.py:8: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /pytorch/torch/csrc/utils/tensor_new.cpp:253.)\n",
            "  obs_tensor = torch.as_tensor([obs], device=model.device)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "env = Game2048EnvV3()\n",
        "obs, info = env.reset()\n",
        "\n",
        "print(\"Initial obs:\", obs.flatten())\n",
        "\n",
        "for i in range(5):\n",
        "    action = env.action_space.sample()\n",
        "    obs, reward, term, trunc, info = env.step(action)\n",
        "    print(f\"Step {i}, action={action}, obs:\", obs.flatten())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AQVOugRQZ9q1",
        "outputId": "768c2f21-1982-4d64-d782-0c917684a532"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial obs: [0.06666667 0.         0.         0.         0.         0.\n",
            " 0.         0.         0.06666667 0.         0.         0.\n",
            " 0.         0.         0.         0.        ]\n",
            "Step 0, action=2, obs: [0.06666667 0.         0.         0.         0.         0.\n",
            " 0.         0.         0.06666667 0.         0.         0.\n",
            " 0.         0.         0.         0.        ]\n",
            "Step 1, action=1, obs: [0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.06666667\n",
            " 0.13333334 0.         0.         0.        ]\n",
            "Step 2, action=0, obs: [0.13333334 0.06666667 0.         0.06666667 0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.        ]\n",
            "Step 3, action=2, obs: [0.13333334 0.13333334 0.         0.         0.         0.\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.06666667 0.         0.         0.        ]\n",
            "Step 4, action=0, obs: [0.13333334 0.13333334 0.         0.         0.06666667 0.06666667\n",
            " 0.         0.         0.         0.         0.         0.\n",
            " 0.         0.         0.         0.        ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from stable_baselines3 import PPO\n",
        "\n",
        "# Load the trained model\n",
        "model = PPO.load(\"ppo_2048_v3_big\")\n",
        "\n",
        "# Create a fresh environment for playing\n",
        "env = Game2048EnvV3(render_mode=\"ansi\")\n",
        "\n",
        "obs, info = env.reset()\n",
        "done = False\n",
        "step = 0\n",
        "\n",
        "print(\"Initial Board:\")\n",
        "print(env._board_to_string())\n",
        "\n",
        "while not done:\n",
        "    # deterministic=True = best move according to PPO\n",
        "    # deterministic=False = allows exploration\n",
        "    action, _ = model.predict(obs, deterministic=False)\n",
        "\n",
        "    obs, reward, terminated, truncated, info = env.step(int(action))\n",
        "    done = terminated or truncated\n",
        "\n",
        "    print(f\"\\nStep {step} | Action: {int(action)} | Reward: {reward:.2f} | Score: {info['score']:.1f}\")\n",
        "    print(env._board_to_string())\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    step += 1\n",
        "    time.sleep(0.15)  # Slow down for visual effect (optional)\n",
        "\n",
        "print(\"\\n=== Episode Finished ===\")\n",
        "print(f\"Final Score: {info['score']}\")\n",
        "print(f\"Max Tile: {info['max_tile']}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50LatPD7WOO1",
        "outputId": "b11f044d-78a2-49b6-ceae-2f06e47c5538"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial Board:\n",
            ".\t.\t.\t.\n",
            ".\t2\t.\t.\n",
            ".\t.\t2\t.\n",
            ".\t.\t.\t.\n",
            "\n",
            "Step 0 | Action: 0 | Reward: 0.00 | Score: 0.0\n",
            ".\t2\t2\t.\n",
            ".\t.\t4\t.\n",
            ".\t.\t.\t.\n",
            ".\t.\t.\t.\n",
            "----------------------------------------\n",
            "\n",
            "Step 1 | Action: 1 | Reward: 0.00 | Score: 0.0\n",
            ".\t.\t.\t.\n",
            ".\t.\t.\t.\n",
            ".\t2\t2\t.\n",
            ".\t2\t4\t.\n",
            "----------------------------------------\n",
            "\n",
            "Step 2 | Action: 1 | Reward: 0.12 | Score: 4.0\n",
            ".\t.\t.\t.\n",
            ".\t.\t.\t.\n",
            ".\t.\t2\t2\n",
            ".\t4\t4\t.\n",
            "----------------------------------------\n",
            "\n",
            "Step 3 | Action: 1 | Reward: 0.00 | Score: 4.0\n",
            ".\t.\t.\t2\n",
            ".\t.\t.\t.\n",
            ".\t.\t2\t.\n",
            ".\t4\t4\t2\n",
            "----------------------------------------\n",
            "\n",
            "Step 4 | Action: 0 | Reward: 0.12 | Score: 8.0\n",
            ".\t4\t2\t4\n",
            ".\t.\t4\t.\n",
            ".\t.\t.\t.\n",
            ".\t2\t.\t.\n",
            "----------------------------------------\n",
            "\n",
            "Step 5 | Action: 0 | Reward: 0.00 | Score: 8.0\n",
            ".\t4\t2\t4\n",
            ".\t2\t4\t4\n",
            ".\t.\t.\t.\n",
            ".\t.\t.\t.\n",
            "----------------------------------------\n",
            "\n",
            "Step 6 | Action: 2 | Reward: 0.25 | Score: 16.0\n",
            "4\t2\t4\t.\n",
            "2\t8\t.\t.\n",
            ".\t.\t.\t.\n",
            ".\t.\t.\t2\n",
            "----------------------------------------\n",
            "\n",
            "Step 7 | Action: 1 | Reward: 0.00 | Score: 16.0\n",
            ".\t.\t.\t.\n",
            ".\t.\t.\t.\n",
            "4\t2\t.\t2\n",
            "2\t8\t4\t2\n",
            "----------------------------------------\n",
            "\n",
            "Step 8 | Action: 0 | Reward: 0.12 | Score: 20.0\n",
            "4\t2\t4\t4\n",
            "2\t8\t.\t.\n",
            "2\t.\t.\t.\n",
            ".\t.\t.\t.\n",
            "----------------------------------------\n",
            "\n",
            "Step 9 | Action: 3 | Reward: 0.25 | Score: 28.0\n",
            ".\t4\t2\t8\n",
            "2\t.\t2\t8\n",
            ".\t.\t.\t2\n",
            ".\t.\t.\t.\n",
            "----------------------------------------\n",
            "\n",
            "Step 10 | Action: 2 | Reward: 0.12 | Score: 32.0\n",
            "4\t2\t8\t.\n",
            "4\t8\t.\t.\n",
            "2\t.\t2\t.\n",
            ".\t.\t.\t.\n",
            "----------------------------------------\n",
            "\n",
            "Step 11 | Action: 3 | Reward: 0.12 | Score: 36.0\n",
            "2\t4\t2\t8\n",
            ".\t.\t4\t8\n",
            ".\t.\t.\t4\n",
            ".\t.\t.\t.\n",
            "----------------------------------------\n",
            "\n",
            "Step 12 | Action: 2 | Reward: 0.00 | Score: 36.0\n",
            "2\t4\t2\t8\n",
            "4\t8\t.\t4\n",
            "4\t.\t.\t.\n",
            ".\t.\t.\t.\n",
            "----------------------------------------\n",
            "\n",
            "Step 13 | Action: 1 | Reward: 0.25 | Score: 44.0\n",
            ".\t.\t.\t.\n",
            ".\t.\t.\t2\n",
            "2\t4\t.\t8\n",
            "8\t8\t2\t4\n",
            "----------------------------------------\n",
            "\n",
            "Step 14 | Action: 2 | Reward: 0.50 | Score: 60.0\n",
            "2\t.\t.\t.\n",
            "2\t.\t.\t.\n",
            "2\t4\t8\t.\n",
            "16\t2\t4\t.\n",
            "----------------------------------------\n",
            "\n",
            "Step 15 | Action: 0 | Reward: 0.12 | Score: 64.0\n",
            "4\t4\t8\t.\n",
            "2\t2\t4\t.\n",
            "16\t.\t2\t.\n",
            ".\t.\t.\t.\n",
            "----------------------------------------\n",
            "\n",
            "Step 16 | Action: 1 | Reward: 0.00 | Score: 64.0\n",
            ".\t2\t.\t.\n",
            "4\t.\t8\t.\n",
            "2\t4\t4\t.\n",
            "16\t2\t2\t.\n",
            "----------------------------------------\n",
            "\n",
            "Step 17 | Action: 0 | Reward: 0.00 | Score: 64.0\n",
            "4\t2\t8\t.\n",
            "2\t4\t4\t.\n",
            "16\t2\t2\t.\n",
            "2\t.\t.\t.\n",
            "----------------------------------------\n",
            "\n",
            "Step 18 | Action: 1 | Reward: 0.00 | Score: 64.0\n",
            "4\t.\t.\t.\n",
            "2\t2\t8\t.\n",
            "16\t4\t4\t.\n",
            "2\t2\t2\t4\n",
            "----------------------------------------\n",
            "\n",
            "Step 19 | Action: 3 | Reward: 0.50 | Score: 80.0\n",
            ".\t.\t2\t4\n",
            ".\t.\t4\t8\n",
            ".\t.\t16\t8\n",
            ".\t2\t4\t4\n",
            "----------------------------------------\n",
            "\n",
            "Step 20 | Action: 0 | Reward: 0.50 | Score: 96.0\n",
            ".\t2\t2\t4\n",
            ".\t.\t4\t16\n",
            ".\t.\t16\t4\n",
            ".\t.\t4\t2\n",
            "----------------------------------------\n",
            "\n",
            "Step 21 | Action: 2 | Reward: 0.12 | Score: 100.0\n",
            "4\t4\t2\t.\n",
            "4\t16\t.\t.\n",
            "16\t4\t.\t.\n",
            "4\t2\t.\t.\n",
            "----------------------------------------\n",
            "\n",
            "Step 22 | Action: 3 | Reward: 0.25 | Score: 108.0\n",
            ".\t.\t8\t2\n",
            ".\t.\t4\t16\n",
            "2\t.\t16\t4\n",
            ".\t.\t4\t2\n",
            "----------------------------------------\n",
            "\n",
            "Step 23 | Action: 1 | Reward: 0.00 | Score: 108.0\n",
            ".\t.\t8\t2\n",
            ".\t.\t4\t16\n",
            ".\t.\t16\t4\n",
            "2\t2\t4\t2\n",
            "----------------------------------------\n",
            "\n",
            "Step 24 | Action: 3 | Reward: 0.12 | Score: 112.0\n",
            ".\t.\t8\t2\n",
            ".\t2\t4\t16\n",
            ".\t.\t16\t4\n",
            ".\t4\t4\t2\n",
            "----------------------------------------\n",
            "\n",
            "Step 25 | Action: 3 | Reward: 0.25 | Score: 120.0\n",
            ".\t.\t8\t2\n",
            ".\t2\t4\t16\n",
            ".\t.\t16\t4\n",
            "2\t.\t8\t2\n",
            "----------------------------------------\n",
            "\n",
            "Step 26 | Action: 0 | Reward: 0.00 | Score: 120.0\n",
            "2\t2\t8\t2\n",
            ".\t.\t4\t16\n",
            ".\t.\t16\t4\n",
            ".\t2\t8\t2\n",
            "----------------------------------------\n",
            "\n",
            "Step 27 | Action: 1 | Reward: 0.12 | Score: 124.0\n",
            ".\t.\t8\t2\n",
            "2\t.\t4\t16\n",
            ".\t.\t16\t4\n",
            "2\t4\t8\t2\n",
            "----------------------------------------\n",
            "\n",
            "Step 28 | Action: 0 | Reward: 0.12 | Score: 128.0\n",
            "4\t4\t8\t2\n",
            ".\t.\t4\t16\n",
            ".\t2\t16\t4\n",
            ".\t.\t8\t2\n",
            "----------------------------------------\n",
            "\n",
            "Step 29 | Action: 1 | Reward: 0.00 | Score: 128.0\n",
            "2\t.\t8\t2\n",
            ".\t.\t4\t16\n",
            ".\t4\t16\t4\n",
            "4\t2\t8\t2\n",
            "----------------------------------------\n",
            "\n",
            "Step 30 | Action: 0 | Reward: 0.00 | Score: 128.0\n",
            "2\t4\t8\t2\n",
            "4\t2\t4\t16\n",
            ".\t.\t16\t4\n",
            ".\t2\t8\t2\n",
            "----------------------------------------\n",
            "\n",
            "Step 31 | Action: 1 | Reward: 0.12 | Score: 132.0\n",
            ".\t.\t8\t2\n",
            "2\t.\t4\t16\n",
            "2\t4\t16\t4\n",
            "4\t4\t8\t2\n",
            "----------------------------------------\n",
            "\n",
            "Step 32 | Action: 3 | Reward: 0.25 | Score: 140.0\n",
            ".\t.\t8\t2\n",
            "2\t2\t4\t16\n",
            "2\t4\t16\t4\n",
            ".\t8\t8\t2\n",
            "----------------------------------------\n",
            "\n",
            "Step 33 | Action: 1 | Reward: 0.12 | Score: 144.0\n",
            "2\t.\t8\t2\n",
            ".\t2\t4\t16\n",
            ".\t4\t16\t4\n",
            "4\t8\t8\t2\n",
            "----------------------------------------\n",
            "\n",
            "Step 34 | Action: 1 | Reward: 0.00 | Score: 144.0\n",
            ".\t2\t8\t2\n",
            ".\t2\t4\t16\n",
            "2\t4\t16\t4\n",
            "4\t8\t8\t2\n",
            "----------------------------------------\n",
            "\n",
            "Step 35 | Action: 2 | Reward: 0.50 | Score: 160.0\n",
            "2\t8\t2\t2\n",
            "2\t4\t16\t.\n",
            "2\t4\t16\t4\n",
            "4\t16\t2\t.\n",
            "----------------------------------------\n",
            "\n",
            "Step 36 | Action: 3 | Reward: 0.12 | Score: 164.0\n",
            ".\t2\t8\t4\n",
            "2\t2\t4\t16\n",
            "2\t4\t16\t4\n",
            ".\t4\t16\t2\n",
            "----------------------------------------\n",
            "\n",
            "Step 37 | Action: 1 | Reward: 1.50 | Score: 212.0\n",
            ".\t.\t.\t4\n",
            ".\t2\t8\t16\n",
            ".\t4\t4\t4\n",
            "4\t8\t32\t2\n",
            "----------------------------------------\n",
            "\n",
            "Step 38 | Action: 3 | Reward: 0.25 | Score: 220.0\n",
            ".\t.\t.\t4\n",
            "2\t2\t8\t16\n",
            ".\t.\t4\t8\n",
            "4\t8\t32\t2\n",
            "----------------------------------------\n",
            "\n",
            "Step 39 | Action: 0 | Reward: 0.00 | Score: 220.0\n",
            "2\t2\t8\t4\n",
            "4\t8\t4\t16\n",
            ".\t.\t32\t8\n",
            "2\t.\t.\t2\n",
            "----------------------------------------\n",
            "\n",
            "Step 40 | Action: 2 | Reward: 0.25 | Score: 228.0\n",
            "4\t8\t4\t.\n",
            "4\t8\t4\t16\n",
            "32\t8\t.\t.\n",
            "4\t2\t.\t.\n",
            "----------------------------------------\n",
            "\n",
            "Step 41 | Action: 1 | Reward: 1.00 | Score: 260.0\n",
            ".\t.\t.\t.\n",
            "8\t8\t2\t.\n",
            "32\t16\t.\t.\n",
            "4\t2\t8\t16\n",
            "----------------------------------------\n",
            "\n",
            "Step 42 | Action: 0 | Reward: 0.00 | Score: 260.0\n",
            "8\t8\t2\t16\n",
            "32\t16\t8\t2\n",
            "4\t2\t.\t.\n",
            ".\t.\t.\t.\n",
            "----------------------------------------\n",
            "\n",
            "Step 43 | Action: 3 | Reward: 0.50 | Score: 276.0\n",
            ".\t16\t2\t16\n",
            "32\t16\t8\t2\n",
            ".\t.\t4\t2\n",
            ".\t2\t.\t.\n",
            "----------------------------------------\n",
            "\n",
            "Step 44 | Action: 2 | Reward: 0.00 | Score: 276.0\n",
            "16\t2\t16\t2\n",
            "32\t16\t8\t2\n",
            "4\t2\t.\t.\n",
            "2\t.\t.\t.\n",
            "----------------------------------------\n",
            "\n",
            "Step 45 | Action: 3 | Reward: 0.00 | Score: 276.0\n",
            "16\t2\t16\t2\n",
            "32\t16\t8\t2\n",
            ".\t.\t4\t2\n",
            ".\t2\t.\t2\n",
            "----------------------------------------\n",
            "\n",
            "Step 46 | Action: 3 | Reward: 0.12 | Score: 280.0\n",
            "16\t2\t16\t2\n",
            "32\t16\t8\t2\n",
            ".\t2\t4\t2\n",
            ".\t.\t.\t4\n",
            "----------------------------------------\n",
            "\n",
            "Step 47 | Action: 0 | Reward: 0.12 | Score: 284.0\n",
            "16\t2\t16\t4\n",
            "32\t16\t8\t2\n",
            ".\t2\t4\t4\n",
            ".\t2\t.\t.\n",
            "----------------------------------------\n",
            "\n",
            "Step 48 | Action: 3 | Reward: 0.25 | Score: 292.0\n",
            "16\t2\t16\t4\n",
            "32\t16\t8\t2\n",
            ".\t2\t2\t8\n",
            ".\t.\t.\t2\n",
            "----------------------------------------\n",
            "\n",
            "Step 49 | Action: 2 | Reward: 0.12 | Score: 296.0\n",
            "16\t2\t16\t4\n",
            "32\t16\t8\t2\n",
            "4\t8\t.\t.\n",
            "2\t.\t2\t.\n",
            "----------------------------------------\n",
            "\n",
            "Step 50 | Action: 3 | Reward: 0.12 | Score: 300.0\n",
            "16\t2\t16\t4\n",
            "32\t16\t8\t2\n",
            "2\t.\t4\t8\n",
            ".\t.\t.\t4\n",
            "----------------------------------------\n",
            "\n",
            "Step 51 | Action: 1 | Reward: 0.00 | Score: 300.0\n",
            ".\t.\t.\t4\n",
            "16\t2\t16\t2\n",
            "32\t2\t8\t8\n",
            "2\t16\t4\t4\n",
            "----------------------------------------\n",
            "\n",
            "Step 52 | Action: 3 | Reward: 0.75 | Score: 324.0\n",
            ".\t.\t.\t4\n",
            "16\t2\t16\t2\n",
            "4\t32\t2\t16\n",
            ".\t2\t16\t8\n",
            "----------------------------------------\n",
            "\n",
            "Step 53 | Action: 1 | Reward: 0.00 | Score: 324.0\n",
            ".\t.\t2\t4\n",
            ".\t2\t16\t2\n",
            "16\t32\t2\t16\n",
            "4\t2\t16\t8\n",
            "----------------------------------------\n",
            "\n",
            "Step 54 | Action: 0 | Reward: 0.00 | Score: 324.0\n",
            "16\t2\t2\t4\n",
            "4\t32\t16\t2\n",
            ".\t2\t2\t16\n",
            ".\t2\t16\t8\n",
            "----------------------------------------\n",
            "\n",
            "Step 55 | Action: 2 | Reward: 0.25 | Score: 332.0\n",
            "16\t4\t4\t.\n",
            "4\t32\t16\t2\n",
            "4\t16\t2\t.\n",
            "2\t16\t8\t.\n",
            "----------------------------------------\n",
            "\n",
            "Step 56 | Action: 2 | Reward: 0.25 | Score: 340.0\n",
            "16\t8\t.\t.\n",
            "4\t32\t16\t2\n",
            "4\t16\t2\t.\n",
            "2\t16\t8\t2\n",
            "----------------------------------------\n",
            "\n",
            "Step 57 | Action: 3 | Reward: 0.00 | Score: 340.0\n",
            ".\t.\t16\t8\n",
            "4\t32\t16\t2\n",
            "2\t4\t16\t2\n",
            "2\t16\t8\t2\n",
            "----------------------------------------\n",
            "\n",
            "Step 58 | Action: 1 | Reward: 1.25 | Score: 380.0\n",
            ".\t.\t4\t.\n",
            ".\t32\t16\t8\n",
            "4\t4\t32\t2\n",
            "4\t16\t8\t4\n",
            "----------------------------------------\n",
            "\n",
            "Step 59 | Action: 2 | Reward: 0.25 | Score: 388.0\n",
            "4\t4\t.\t.\n",
            "32\t16\t8\t.\n",
            "8\t32\t2\t.\n",
            "4\t16\t8\t4\n",
            "----------------------------------------\n",
            "\n",
            "Step 60 | Action: 3 | Reward: 0.25 | Score: 396.0\n",
            ".\t2\t.\t8\n",
            ".\t32\t16\t8\n",
            ".\t8\t32\t2\n",
            "4\t16\t8\t4\n",
            "----------------------------------------\n",
            "\n",
            "Step 61 | Action: 0 | Reward: 0.50 | Score: 412.0\n",
            "4\t2\t16\t16\n",
            ".\t32\t32\t2\n",
            ".\t8\t8\t4\n",
            "2\t16\t.\t.\n",
            "----------------------------------------\n",
            "\n",
            "Step 62 | Action: 2 | Reward: 3.50 | Score: 524.0\n",
            "4\t2\t32\t2\n",
            "64\t2\t.\t.\n",
            "16\t4\t.\t.\n",
            "2\t16\t.\t.\n",
            "----------------------------------------\n",
            "\n",
            "Step 63 | Action: 2 | Reward: -1.00 | Score: 524.0\n",
            "4\t2\t32\t2\n",
            "64\t2\t.\t.\n",
            "16\t4\t.\t.\n",
            "2\t16\t.\t.\n",
            "----------------------------------------\n",
            "\n",
            "Step 64 | Action: 3 | Reward: 0.00 | Score: 524.0\n",
            "4\t2\t32\t2\n",
            ".\t.\t64\t2\n",
            "2\t.\t16\t4\n",
            ".\t.\t2\t16\n",
            "----------------------------------------\n",
            "\n",
            "Step 65 | Action: 2 | Reward: 0.00 | Score: 524.0\n",
            "4\t2\t32\t2\n",
            "64\t2\t.\t2\n",
            "2\t16\t4\t.\n",
            "2\t16\t.\t.\n",
            "----------------------------------------\n",
            "\n",
            "Step 66 | Action: 2 | Reward: 0.12 | Score: 528.0\n",
            "4\t2\t32\t2\n",
            "64\t4\t.\t.\n",
            "2\t16\t4\t2\n",
            "2\t16\t.\t.\n",
            "----------------------------------------\n",
            "\n",
            "Step 67 | Action: 1 | Reward: 1.25 | Score: 568.0\n",
            ".\t.\t.\t2\n",
            "4\t2\t.\t.\n",
            "64\t4\t32\t.\n",
            "4\t32\t4\t4\n",
            "----------------------------------------\n",
            "\n",
            "Step 68 | Action: 3 | Reward: 0.25 | Score: 576.0\n",
            ".\t.\t.\t2\n",
            "2\t.\t4\t2\n",
            ".\t64\t4\t32\n",
            ".\t4\t32\t8\n",
            "----------------------------------------\n",
            "\n",
            "Step 69 | Action: 0 | Reward: 0.38 | Score: 588.0\n",
            "2\t64\t8\t4\n",
            ".\t4\t32\t32\n",
            ".\t.\t.\t8\n",
            ".\t.\t.\t2\n",
            "----------------------------------------\n",
            "\n",
            "Step 70 | Action: 2 | Reward: 2.00 | Score: 652.0\n",
            "2\t64\t8\t4\n",
            "4\t64\t.\t.\n",
            "8\t.\t.\t.\n",
            "2\t2\t.\t.\n",
            "----------------------------------------\n",
            "\n",
            "Step 71 | Action: 1 | Reward: 4.00 | Score: 780.0\n",
            "2\t.\t2\t.\n",
            "4\t.\t.\t.\n",
            "8\t128\t.\t.\n",
            "2\t2\t8\t4\n",
            "----------------------------------------\n",
            "\n",
            "Step 72 | Action: 3 | Reward: 0.25 | Score: 788.0\n",
            ".\t2\t.\t4\n",
            ".\t.\t.\t4\n",
            ".\t.\t8\t128\n",
            ".\t4\t8\t4\n",
            "----------------------------------------\n",
            "\n",
            "Step 73 | Action: 1 | Reward: 0.75 | Score: 812.0\n",
            ".\t.\t.\t.\n",
            "2\t.\t.\t8\n",
            ".\t2\t.\t128\n",
            ".\t4\t16\t4\n",
            "----------------------------------------\n",
            "\n",
            "Step 74 | Action: 0 | Reward: 0.00 | Score: 812.0\n",
            "2\t2\t16\t8\n",
            "2\t4\t.\t128\n",
            ".\t.\t.\t4\n",
            ".\t.\t.\t.\n",
            "----------------------------------------\n",
            "\n",
            "Step 75 | Action: 2 | Reward: 0.12 | Score: 816.0\n",
            "4\t16\t8\t.\n",
            "2\t4\t128\t.\n",
            "4\t.\t.\t2\n",
            ".\t.\t.\t.\n",
            "----------------------------------------\n",
            "\n",
            "Step 76 | Action: 0 | Reward: 0.00 | Score: 816.0\n",
            "4\t16\t8\t2\n",
            "2\t4\t128\t.\n",
            "4\t.\t.\t2\n",
            ".\t.\t.\t.\n",
            "----------------------------------------\n",
            "\n",
            "Step 77 | Action: 3 | Reward: 0.00 | Score: 816.0\n",
            "4\t16\t8\t2\n",
            ".\t2\t4\t128\n",
            ".\t.\t4\t2\n",
            "2\t.\t.\t.\n",
            "----------------------------------------\n",
            "\n",
            "Step 78 | Action: 1 | Reward: 0.25 | Score: 824.0\n",
            "2\t.\t.\t.\n",
            ".\t.\t.\t2\n",
            "4\t16\t8\t128\n",
            "2\t2\t8\t2\n",
            "----------------------------------------\n",
            "\n",
            "Step 79 | Action: 0 | Reward: 0.50 | Score: 840.0\n",
            "2\t16\t16\t2\n",
            "4\t2\t.\t128\n",
            "2\t.\t.\t2\n",
            ".\t.\t.\t2\n",
            "----------------------------------------\n",
            "\n",
            "Step 80 | Action: 3 | Reward: 1.12 | Score: 876.0\n",
            ".\t2\t32\t2\n",
            ".\t4\t2\t128\n",
            ".\t.\t2\t4\n",
            ".\t.\t.\t2\n",
            "----------------------------------------\n",
            "\n",
            "Step 81 | Action: 0 | Reward: 0.12 | Score: 880.0\n",
            ".\t2\t32\t2\n",
            "2\t4\t4\t128\n",
            ".\t.\t.\t4\n",
            ".\t.\t.\t2\n",
            "----------------------------------------\n",
            "\n",
            "Step 82 | Action: 1 | Reward: 0.00 | Score: 880.0\n",
            ".\t.\t.\t2\n",
            ".\t.\t2\t128\n",
            ".\t2\t32\t4\n",
            "2\t4\t4\t2\n",
            "----------------------------------------\n",
            "\n",
            "Step 83 | Action: 1 | Reward: -1.00 | Score: 880.0\n",
            ".\t.\t.\t2\n",
            ".\t.\t2\t128\n",
            ".\t2\t32\t4\n",
            "2\t4\t4\t2\n",
            "----------------------------------------\n",
            "\n",
            "Step 84 | Action: 2 | Reward: 0.25 | Score: 888.0\n",
            "2\t2\t.\t.\n",
            "2\t128\t.\t.\n",
            "2\t32\t4\t.\n",
            "2\t8\t2\t.\n",
            "----------------------------------------\n",
            "\n",
            "Step 85 | Action: 2 | Reward: 0.12 | Score: 892.0\n",
            "4\t.\t.\t.\n",
            "2\t128\t2\t.\n",
            "2\t32\t4\t.\n",
            "2\t8\t2\t.\n",
            "----------------------------------------\n",
            "\n",
            "Step 86 | Action: 0 | Reward: 0.12 | Score: 896.0\n",
            "4\t128\t2\t.\n",
            "4\t32\t4\t.\n",
            "2\t8\t2\t.\n",
            ".\t.\t2\t.\n",
            "----------------------------------------\n",
            "\n",
            "Step 87 | Action: 1 | Reward: 0.38 | Score: 908.0\n",
            ".\t.\t.\t.\n",
            ".\t128\t2\t.\n",
            "8\t32\t4\t.\n",
            "2\t8\t4\t2\n",
            "----------------------------------------\n",
            "\n",
            "Step 88 | Action: 0 | Reward: 0.25 | Score: 916.0\n",
            "8\t128\t2\t2\n",
            "2\t32\t8\t.\n",
            "4\t8\t.\t.\n",
            ".\t.\t.\t.\n",
            "----------------------------------------\n",
            "\n",
            "Step 89 | Action: 0 | Reward: -1.00 | Score: 916.0\n",
            "8\t128\t2\t2\n",
            "2\t32\t8\t.\n",
            "4\t8\t.\t.\n",
            ".\t.\t.\t.\n",
            "----------------------------------------\n",
            "\n",
            "Step 90 | Action: 1 | Reward: 0.00 | Score: 916.0\n",
            "2\t.\t.\t.\n",
            "8\t128\t.\t.\n",
            "2\t32\t2\t.\n",
            "4\t8\t8\t2\n",
            "----------------------------------------\n",
            "\n",
            "Step 91 | Action: 3 | Reward: 0.50 | Score: 932.0\n",
            ".\t.\t2\t2\n",
            ".\t.\t8\t128\n",
            ".\t2\t32\t2\n",
            ".\t4\t16\t2\n",
            "----------------------------------------\n",
            "\n",
            "Step 92 | Action: 1 | Reward: 0.12 | Score: 936.0\n",
            ".\t2\t2\t.\n",
            ".\t.\t8\t2\n",
            ".\t2\t32\t128\n",
            ".\t4\t16\t4\n",
            "----------------------------------------\n",
            "\n",
            "Step 93 | Action: 1 | Reward: 0.12 | Score: 940.0\n",
            ".\t.\t2\t.\n",
            ".\t.\t8\t2\n",
            ".\t4\t32\t128\n",
            "2\t4\t16\t4\n",
            "----------------------------------------\n",
            "\n",
            "Step 94 | Action: 0 | Reward: 0.25 | Score: 948.0\n",
            "2\t8\t2\t2\n",
            "2\t.\t8\t128\n",
            ".\t.\t32\t4\n",
            ".\t.\t16\t.\n",
            "----------------------------------------\n",
            "\n",
            "Step 95 | Action: 1 | Reward: 0.12 | Score: 952.0\n",
            ".\t.\t2\t.\n",
            ".\t2\t8\t2\n",
            ".\t.\t32\t128\n",
            "4\t8\t16\t4\n",
            "----------------------------------------\n",
            "\n",
            "Step 96 | Action: 0 | Reward: 0.00 | Score: 952.0\n",
            "4\t2\t2\t2\n",
            ".\t8\t8\t128\n",
            ".\t.\t32\t4\n",
            ".\t.\t16\t2\n",
            "----------------------------------------\n",
            "\n",
            "Step 97 | Action: 1 | Reward: 0.00 | Score: 952.0\n",
            ".\t.\t2\t2\n",
            ".\t.\t8\t128\n",
            "2\t2\t32\t4\n",
            "4\t8\t16\t2\n",
            "----------------------------------------\n",
            "\n",
            "Step 98 | Action: 2 | Reward: 0.25 | Score: 960.0\n",
            "4\t.\t.\t.\n",
            "8\t128\t2\t.\n",
            "4\t32\t4\t.\n",
            "4\t8\t16\t2\n",
            "----------------------------------------\n",
            "\n",
            "Step 99 | Action: 0 | Reward: 0.25 | Score: 968.0\n",
            "4\t128\t2\t2\n",
            "8\t32\t4\t.\n",
            "8\t8\t16\t.\n",
            "4\t.\t.\t.\n",
            "----------------------------------------\n",
            "\n",
            "Step 100 | Action: 3 | Reward: 0.62 | Score: 988.0\n",
            ".\t4\t128\t4\n",
            ".\t8\t32\t4\n",
            ".\t.\t16\t16\n",
            ".\t.\t2\t4\n",
            "----------------------------------------\n",
            "\n",
            "Step 101 | Action: 1 | Reward: 0.25 | Score: 996.0\n",
            ".\t.\t128\t.\n",
            ".\t2\t32\t8\n",
            ".\t4\t16\t16\n",
            ".\t8\t2\t4\n",
            "----------------------------------------\n",
            "\n",
            "Step 102 | Action: 1 | Reward: -1.00 | Score: 996.0\n",
            ".\t.\t128\t.\n",
            ".\t2\t32\t8\n",
            ".\t4\t16\t16\n",
            ".\t8\t2\t4\n",
            "----------------------------------------\n",
            "\n",
            "Step 103 | Action: 0 | Reward: 0.00 | Score: 996.0\n",
            "2\t2\t128\t8\n",
            ".\t4\t32\t16\n",
            ".\t8\t16\t4\n",
            ".\t.\t2\t.\n",
            "----------------------------------------\n",
            "\n",
            "Step 104 | Action: 1 | Reward: 0.00 | Score: 996.0\n",
            ".\t.\t128\t2\n",
            ".\t2\t32\t8\n",
            ".\t4\t16\t16\n",
            "2\t8\t2\t4\n",
            "----------------------------------------\n",
            "\n",
            "Step 105 | Action: 0 | Reward: 0.00 | Score: 996.0\n",
            "2\t2\t128\t2\n",
            ".\t4\t32\t8\n",
            ".\t8\t16\t16\n",
            ".\t2\t2\t4\n",
            "----------------------------------------\n",
            "\n",
            "Step 106 | Action: 0 | Reward: -1.00 | Score: 996.0\n",
            "2\t2\t128\t2\n",
            ".\t4\t32\t8\n",
            ".\t8\t16\t16\n",
            ".\t2\t2\t4\n",
            "----------------------------------------\n",
            "\n",
            "Step 107 | Action: 0 | Reward: -1.00 | Score: 996.0\n",
            "2\t2\t128\t2\n",
            ".\t4\t32\t8\n",
            ".\t8\t16\t16\n",
            ".\t2\t2\t4\n",
            "----------------------------------------\n",
            "\n",
            "Step 108 | Action: 0 | Reward: -1.00 | Score: 996.0\n",
            "2\t2\t128\t2\n",
            ".\t4\t32\t8\n",
            ".\t8\t16\t16\n",
            ".\t2\t2\t4\n",
            "----------------------------------------\n",
            "\n",
            "Step 109 | Action: 1 | Reward: 0.00 | Score: 996.0\n",
            ".\t2\t128\t2\n",
            ".\t4\t32\t8\n",
            "2\t8\t16\t16\n",
            "2\t2\t2\t4\n",
            "----------------------------------------\n",
            "\n",
            "Step 110 | Action: 2 | Reward: 1.12 | Score: 1032.0\n",
            "2\t128\t2\t.\n",
            "4\t32\t8\t.\n",
            "2\t8\t32\t4\n",
            "4\t2\t4\t.\n",
            "----------------------------------------\n",
            "\n",
            "Step 111 | Action: 2 | Reward: -1.00 | Score: 1032.0\n",
            "2\t128\t2\t.\n",
            "4\t32\t8\t.\n",
            "2\t8\t32\t4\n",
            "4\t2\t4\t.\n",
            "----------------------------------------\n",
            "\n",
            "Step 112 | Action: 0 | Reward: 0.00 | Score: 1032.0\n",
            "2\t128\t2\t4\n",
            "4\t32\t8\t.\n",
            "2\t8\t32\t2\n",
            "4\t2\t4\t.\n",
            "----------------------------------------\n",
            "\n",
            "Step 113 | Action: 3 | Reward: 0.00 | Score: 1032.0\n",
            "2\t128\t2\t4\n",
            "2\t4\t32\t8\n",
            "2\t8\t32\t2\n",
            ".\t4\t2\t4\n",
            "----------------------------------------\n",
            "\n",
            "Step 114 | Action: 0 | Reward: 2.12 | Score: 1100.0\n",
            "4\t128\t2\t4\n",
            "2\t4\t64\t8\n",
            ".\t8\t2\t2\n",
            "2\t4\t.\t4\n",
            "----------------------------------------\n",
            "\n",
            "Step 115 | Action: 2 | Reward: 0.38 | Score: 1112.0\n",
            "4\t128\t2\t4\n",
            "2\t4\t64\t8\n",
            "8\t4\t.\t.\n",
            "2\t8\t.\t2\n",
            "----------------------------------------\n",
            "\n",
            "Step 116 | Action: 2 | Reward: 0.00 | Score: 1112.0\n",
            "4\t128\t2\t4\n",
            "2\t4\t64\t8\n",
            "8\t4\t.\t.\n",
            "2\t8\t2\t2\n",
            "----------------------------------------\n",
            "\n",
            "Step 117 | Action: 1 | Reward: 0.25 | Score: 1120.0\n",
            "4\t.\t.\t4\n",
            "2\t128\t2\t4\n",
            "8\t8\t64\t8\n",
            "2\t8\t2\t2\n",
            "----------------------------------------\n",
            "\n",
            "Step 118 | Action: 3 | Reward: 0.88 | Score: 1148.0\n",
            ".\t.\t4\t8\n",
            "2\t128\t2\t4\n",
            ".\t16\t64\t8\n",
            ".\t2\t8\t4\n",
            "----------------------------------------\n",
            "\n",
            "Step 119 | Action: 2 | Reward: 0.00 | Score: 1148.0\n",
            "4\t8\t.\t.\n",
            "2\t128\t2\t4\n",
            "16\t64\t8\t.\n",
            "2\t8\t4\t4\n",
            "----------------------------------------\n",
            "\n",
            "Step 120 | Action: 1 | Reward: 0.25 | Score: 1156.0\n",
            "4\t8\t.\t2\n",
            "2\t128\t2\t.\n",
            "16\t64\t8\t.\n",
            "2\t8\t4\t8\n",
            "----------------------------------------\n",
            "\n",
            "Step 121 | Action: 0 | Reward: 0.00 | Score: 1156.0\n",
            "4\t8\t2\t2\n",
            "2\t128\t8\t8\n",
            "16\t64\t4\t.\n",
            "2\t8\t2\t.\n",
            "----------------------------------------\n",
            "\n",
            "Step 122 | Action: 2 | Reward: 0.62 | Score: 1176.0\n",
            "4\t8\t4\t.\n",
            "2\t128\t16\t2\n",
            "16\t64\t4\t.\n",
            "2\t8\t2\t.\n",
            "----------------------------------------\n",
            "\n",
            "Step 123 | Action: 1 | Reward: 0.00 | Score: 1176.0\n",
            "4\t8\t4\t2\n",
            "2\t128\t16\t.\n",
            "16\t64\t4\t.\n",
            "2\t8\t2\t2\n",
            "----------------------------------------\n",
            "\n",
            "Step 124 | Action: 3 | Reward: 0.12 | Score: 1180.0\n",
            "4\t8\t4\t2\n",
            ".\t2\t128\t16\n",
            ".\t16\t64\t4\n",
            "2\t2\t8\t4\n",
            "----------------------------------------\n",
            "\n",
            "Step 125 | Action: 1 | Reward: 0.25 | Score: 1188.0\n",
            "2\t8\t4\t.\n",
            ".\t2\t128\t2\n",
            "4\t16\t64\t16\n",
            "2\t2\t8\t8\n",
            "----------------------------------------\n",
            "\n",
            "Step 126 | Action: 1 | Reward: 0.00 | Score: 1188.0\n",
            "2\t8\t4\t.\n",
            "2\t2\t128\t2\n",
            "4\t16\t64\t16\n",
            "2\t2\t8\t8\n",
            "----------------------------------------\n",
            "\n",
            "Step 127 | Action: 0 | Reward: 0.12 | Score: 1192.0\n",
            "4\t8\t4\t2\n",
            "4\t2\t128\t16\n",
            "2\t16\t64\t8\n",
            "2\t2\t8\t.\n",
            "----------------------------------------\n",
            "\n",
            "Step 128 | Action: 2 | Reward: 0.12 | Score: 1196.0\n",
            "4\t8\t4\t2\n",
            "4\t2\t128\t16\n",
            "2\t16\t64\t8\n",
            "4\t8\t.\t2\n",
            "----------------------------------------\n",
            "\n",
            "Step 129 | Action: 0 | Reward: 0.25 | Score: 1204.0\n",
            "8\t8\t4\t2\n",
            "2\t2\t128\t16\n",
            "4\t16\t64\t8\n",
            "2\t8\t.\t2\n",
            "----------------------------------------\n",
            "\n",
            "Step 130 | Action: 2 | Reward: 0.62 | Score: 1224.0\n",
            "16\t4\t2\t.\n",
            "4\t128\t16\t.\n",
            "4\t16\t64\t8\n",
            "2\t8\t2\t2\n",
            "----------------------------------------\n",
            "\n",
            "Step 131 | Action: 3 | Reward: 0.12 | Score: 1228.0\n",
            ".\t16\t4\t2\n",
            "2\t4\t128\t16\n",
            "4\t16\t64\t8\n",
            ".\t2\t8\t4\n",
            "----------------------------------------\n",
            "\n",
            "Step 132 | Action: 2 | Reward: 0.00 | Score: 1228.0\n",
            "16\t4\t2\t2\n",
            "2\t4\t128\t16\n",
            "4\t16\t64\t8\n",
            "2\t8\t4\t.\n",
            "----------------------------------------\n",
            "\n",
            "Step 133 | Action: 3 | Reward: 0.12 | Score: 1232.0\n",
            ".\t16\t4\t4\n",
            "2\t4\t128\t16\n",
            "4\t16\t64\t8\n",
            "2\t2\t8\t4\n",
            "----------------------------------------\n",
            "\n",
            "Step 134 | Action: 2 | Reward: 0.38 | Score: 1244.0\n",
            "16\t8\t2\t.\n",
            "2\t4\t128\t16\n",
            "4\t16\t64\t8\n",
            "4\t8\t4\t.\n",
            "----------------------------------------\n",
            "\n",
            "Step 135 | Action: 3 | Reward: 0.00 | Score: 1244.0\n",
            ".\t16\t8\t2\n",
            "2\t4\t128\t16\n",
            "4\t16\t64\t8\n",
            "2\t4\t8\t4\n",
            "----------------------------------------\n",
            "\n",
            "Step 136 | Action: 0 | Reward: 0.00 | Score: 1244.0\n",
            "2\t16\t8\t2\n",
            "4\t4\t128\t16\n",
            "2\t16\t64\t8\n",
            "2\t4\t8\t4\n",
            "----------------------------------------\n",
            "\n",
            "Step 137 | Action: 1 | Reward: 0.12 | Score: 1248.0\n",
            "2\t16\t8\t2\n",
            "2\t4\t128\t16\n",
            "4\t16\t64\t8\n",
            "4\t4\t8\t4\n",
            "----------------------------------------\n",
            "\n",
            "Step 138 | Action: 0 | Reward: 0.38 | Score: 1260.0\n",
            "4\t16\t8\t2\n",
            "8\t4\t128\t16\n",
            ".\t16\t64\t8\n",
            "2\t4\t8\t4\n",
            "----------------------------------------\n",
            "\n",
            "Step 139 | Action: 2 | Reward: 0.00 | Score: 1260.0\n",
            "4\t16\t8\t2\n",
            "8\t4\t128\t16\n",
            "16\t64\t8\t2\n",
            "2\t4\t8\t4\n",
            "----------------------------------------\n",
            "\n",
            "Step 140 | Action: 1 | Reward: 0.50 | Score: 1276.0\n",
            "4\t16\t2\t2\n",
            "8\t4\t8\t16\n",
            "16\t64\t128\t2\n",
            "2\t4\t16\t4\n",
            "----------------------------------------\n",
            "\n",
            "Step 141 | Action: 3 | Reward: 0.12 | Score: 1280.0\n",
            "2\t4\t16\t4\n",
            "8\t4\t8\t16\n",
            "16\t64\t128\t2\n",
            "2\t4\t16\t4\n",
            "----------------------------------------\n",
            "\n",
            "Step 142 | Action: 1 | Reward: 0.25 | Score: 1288.0\n",
            "2\t2\t16\t4\n",
            "8\t8\t8\t16\n",
            "16\t64\t128\t2\n",
            "2\t4\t16\t4\n",
            "----------------------------------------\n",
            "\n",
            "Step 143 | Action: 3 | Reward: 0.62 | Score: 1308.0\n",
            "2\t4\t16\t4\n",
            ".\t8\t16\t16\n",
            "16\t64\t128\t2\n",
            "2\t4\t16\t4\n",
            "----------------------------------------\n",
            "\n",
            "Step 144 | Action: 2 | Reward: 1.00 | Score: 1340.0\n",
            "2\t4\t16\t4\n",
            "8\t32\t2\t.\n",
            "16\t64\t128\t2\n",
            "2\t4\t16\t4\n",
            "----------------------------------------\n",
            "\n",
            "Step 145 | Action: 3 | Reward: 0.00 | Score: 1340.0\n",
            "2\t4\t16\t4\n",
            "2\t8\t32\t2\n",
            "16\t64\t128\t2\n",
            "2\t4\t16\t4\n",
            "----------------------------------------\n",
            "\n",
            "Step 146 | Action: 1 | Reward: 0.25 | Score: 1348.0\n",
            "2\t4\t16\t.\n",
            "4\t8\t32\t4\n",
            "16\t64\t128\t4\n",
            "2\t4\t16\t4\n",
            "----------------------------------------\n",
            "\n",
            "Step 147 | Action: 2 | Reward: -1.00 | Score: 1348.0\n",
            "2\t4\t16\t.\n",
            "4\t8\t32\t4\n",
            "16\t64\t128\t4\n",
            "2\t4\t16\t4\n",
            "----------------------------------------\n",
            "\n",
            "Step 148 | Action: 3 | Reward: 0.00 | Score: 1348.0\n",
            "2\t2\t4\t16\n",
            "4\t8\t32\t4\n",
            "16\t64\t128\t4\n",
            "2\t4\t16\t4\n",
            "----------------------------------------\n",
            "\n",
            "Step 149 | Action: 2 | Reward: 0.12 | Score: 1352.0\n",
            "4\t4\t16\t2\n",
            "4\t8\t32\t4\n",
            "16\t64\t128\t4\n",
            "2\t4\t16\t4\n",
            "----------------------------------------\n",
            "\n",
            "Step 150 | Action: 0 | Reward: 0.50 | Score: 1368.0\n",
            "8\t4\t16\t2\n",
            "16\t8\t32\t8\n",
            "2\t64\t128\t4\n",
            "2\t4\t16\t.\n",
            "----------------------------------------\n",
            "\n",
            "Step 151 | Action: 1 | Reward: 0.12 | Score: 1372.0\n",
            ".\t4\t16\t2\n",
            "8\t8\t32\t2\n",
            "16\t64\t128\t8\n",
            "4\t4\t16\t4\n",
            "----------------------------------------\n",
            "\n",
            "Step 152 | Action: 2 | Reward: 0.75 | Score: 1396.0\n",
            "4\t16\t2\t2\n",
            "16\t32\t2\t.\n",
            "16\t64\t128\t8\n",
            "8\t16\t4\t.\n",
            "----------------------------------------\n",
            "\n",
            "Step 153 | Action: 3 | Reward: 0.12 | Score: 1400.0\n",
            ".\t4\t16\t4\n",
            ".\t16\t32\t2\n",
            "16\t64\t128\t8\n",
            "2\t8\t16\t4\n",
            "----------------------------------------\n",
            "\n",
            "Step 154 | Action: 1 | Reward: -1.00 | Score: 1400.0\n",
            ".\t4\t16\t4\n",
            ".\t16\t32\t2\n",
            "16\t64\t128\t8\n",
            "2\t8\t16\t4\n",
            "----------------------------------------\n",
            "\n",
            "Step 155 | Action: 2 | Reward: 0.00 | Score: 1400.0\n",
            "4\t16\t4\t.\n",
            "16\t32\t2\t2\n",
            "16\t64\t128\t8\n",
            "2\t8\t16\t4\n",
            "----------------------------------------\n",
            "\n",
            "Step 156 | Action: 0 | Reward: 1.00 | Score: 1432.0\n",
            "4\t16\t4\t2\n",
            "32\t32\t2\t8\n",
            "2\t64\t128\t4\n",
            "2\t8\t16\t.\n",
            "----------------------------------------\n",
            "\n",
            "Step 157 | Action: 2 | Reward: 2.00 | Score: 1496.0\n",
            "4\t16\t4\t2\n",
            "64\t2\t8\t2\n",
            "2\t64\t128\t4\n",
            "2\t8\t16\t.\n",
            "----------------------------------------\n",
            "\n",
            "Step 158 | Action: 0 | Reward: 0.25 | Score: 1504.0\n",
            "4\t16\t4\t4\n",
            "64\t2\t8\t4\n",
            "4\t64\t128\t2\n",
            ".\t8\t16\t.\n",
            "----------------------------------------\n",
            "\n",
            "Step 159 | Action: 3 | Reward: 0.25 | Score: 1512.0\n",
            ".\t4\t16\t8\n",
            "64\t2\t8\t4\n",
            "4\t64\t128\t2\n",
            ".\t4\t8\t16\n",
            "----------------------------------------\n",
            "\n",
            "Step 160 | Action: 1 | Reward: 0.00 | Score: 1512.0\n",
            "2\t4\t16\t8\n",
            ".\t2\t8\t4\n",
            "64\t64\t128\t2\n",
            "4\t4\t8\t16\n",
            "----------------------------------------\n",
            "\n",
            "Step 161 | Action: 2 | Reward: 4.25 | Score: 1648.0\n",
            "2\t4\t16\t8\n",
            "2\t8\t4\t2\n",
            "128\t128\t2\t.\n",
            "8\t8\t16\t.\n",
            "----------------------------------------\n",
            "\n",
            "Step 162 | Action: 0 | Reward: 0.12 | Score: 1652.0\n",
            "4\t4\t16\t8\n",
            "128\t8\t4\t2\n",
            "8\t128\t2\t.\n",
            "2\t8\t16\t.\n",
            "----------------------------------------\n",
            "\n",
            "Step 163 | Action: 1 | Reward: 0.00 | Score: 1652.0\n",
            "4\t4\t16\t.\n",
            "128\t8\t4\t2\n",
            "8\t128\t2\t8\n",
            "2\t8\t16\t2\n",
            "----------------------------------------\n",
            "\n",
            "Step 164 | Action: 0 | Reward: 0.00 | Score: 1652.0\n",
            "4\t4\t16\t2\n",
            "128\t8\t4\t8\n",
            "8\t128\t2\t2\n",
            "2\t8\t16\t2\n",
            "----------------------------------------\n",
            "\n",
            "Step 165 | Action: 2 | Reward: 0.38 | Score: 1664.0\n",
            "8\t16\t2\t2\n",
            "128\t8\t4\t8\n",
            "8\t128\t4\t.\n",
            "2\t8\t16\t2\n",
            "----------------------------------------\n",
            "\n",
            "Step 166 | Action: 2 | Reward: 0.12 | Score: 1668.0\n",
            "8\t16\t4\t.\n",
            "128\t8\t4\t8\n",
            "8\t128\t4\t2\n",
            "2\t8\t16\t2\n",
            "----------------------------------------\n",
            "\n",
            "Step 167 | Action: 0 | Reward: 0.38 | Score: 1680.0\n",
            "8\t16\t8\t8\n",
            "128\t8\t4\t4\n",
            "8\t128\t16\t2\n",
            "2\t8\t.\t.\n",
            "----------------------------------------\n",
            "\n",
            "Step 168 | Action: 2 | Reward: 0.75 | Score: 1704.0\n",
            "8\t16\t16\t2\n",
            "128\t8\t8\t.\n",
            "8\t128\t16\t2\n",
            "2\t8\t.\t.\n",
            "----------------------------------------\n",
            "\n",
            "Step 169 | Action: 1 | Reward: 0.12 | Score: 1708.0\n",
            "8\t16\t.\t.\n",
            "128\t8\t16\t2\n",
            "8\t128\t8\t.\n",
            "2\t8\t16\t4\n",
            "----------------------------------------\n",
            "\n",
            "Step 170 | Action: 3 | Reward: 0.00 | Score: 1708.0\n",
            "2\t.\t8\t16\n",
            "128\t8\t16\t2\n",
            ".\t8\t128\t8\n",
            "2\t8\t16\t4\n",
            "----------------------------------------\n",
            "\n",
            "Step 171 | Action: 2 | Reward: 0.00 | Score: 1708.0\n",
            "2\t8\t16\t.\n",
            "128\t8\t16\t2\n",
            "8\t128\t8\t2\n",
            "2\t8\t16\t4\n",
            "----------------------------------------\n",
            "\n",
            "Step 172 | Action: 2 | Reward: -1.00 | Score: 1708.0\n",
            "2\t8\t16\t.\n",
            "128\t8\t16\t2\n",
            "8\t128\t8\t2\n",
            "2\t8\t16\t4\n",
            "----------------------------------------\n",
            "\n",
            "Step 173 | Action: 0 | Reward: 1.62 | Score: 1760.0\n",
            "2\t16\t32\t4\n",
            "128\t128\t8\t4\n",
            "8\t8\t16\t.\n",
            "2\t.\t.\t4\n",
            "----------------------------------------\n",
            "\n",
            "Step 174 | Action: 2 | Reward: 8.50 | Score: 2032.0\n",
            "2\t16\t32\t4\n",
            "256\t8\t4\t.\n",
            "16\t16\t.\t.\n",
            "2\t4\t2\t.\n",
            "----------------------------------------\n",
            "\n",
            "Step 175 | Action: 1 | Reward: 0.00 | Score: 2032.0\n",
            "2\t16\t.\t2\n",
            "256\t8\t32\t.\n",
            "16\t16\t4\t.\n",
            "2\t4\t2\t4\n",
            "----------------------------------------\n",
            "\n",
            "Step 176 | Action: 3 | Reward: 1.00 | Score: 2064.0\n",
            "2\t2\t16\t2\n",
            ".\t256\t8\t32\n",
            ".\t.\t32\t4\n",
            "2\t4\t2\t4\n",
            "----------------------------------------\n",
            "\n",
            "Step 177 | Action: 1 | Reward: 0.38 | Score: 2076.0\n",
            ".\t.\t16\t.\n",
            "4\t2\t8\t2\n",
            ".\t256\t32\t32\n",
            "4\t4\t2\t8\n",
            "----------------------------------------\n",
            "\n",
            "Step 178 | Action: 1 | Reward: 0.25 | Score: 2084.0\n",
            "2\t.\t16\t.\n",
            ".\t2\t8\t2\n",
            ".\t256\t32\t32\n",
            "8\t4\t2\t8\n",
            "----------------------------------------\n",
            "\n",
            "Step 179 | Action: 2 | Reward: 2.00 | Score: 2148.0\n",
            "2\t16\t.\t2\n",
            "2\t8\t2\t.\n",
            "256\t64\t.\t.\n",
            "8\t4\t2\t8\n",
            "----------------------------------------\n",
            "\n",
            "Step 180 | Action: 0 | Reward: 0.25 | Score: 2156.0\n",
            "4\t16\t4\t2\n",
            "256\t8\t.\t8\n",
            "8\t64\t.\t.\n",
            ".\t4\t.\t4\n",
            "----------------------------------------\n",
            "\n",
            "Step 181 | Action: 3 | Reward: 0.75 | Score: 2180.0\n",
            "4\t16\t4\t2\n",
            ".\t.\t256\t16\n",
            ".\t2\t8\t64\n",
            ".\t.\t.\t8\n",
            "----------------------------------------\n",
            "\n",
            "Step 182 | Action: 1 | Reward: 0.00 | Score: 2180.0\n",
            ".\t.\t.\t2\n",
            ".\t.\t4\t16\n",
            "4\t16\t256\t64\n",
            "4\t2\t8\t8\n",
            "----------------------------------------\n",
            "\n",
            "Step 183 | Action: 3 | Reward: 0.50 | Score: 2196.0\n",
            ".\t.\t2\t2\n",
            ".\t.\t4\t16\n",
            "4\t16\t256\t64\n",
            ".\t4\t2\t16\n",
            "----------------------------------------\n",
            "\n",
            "Step 184 | Action: 2 | Reward: 0.12 | Score: 2200.0\n",
            "4\t2\t.\t.\n",
            "4\t16\t.\t.\n",
            "4\t16\t256\t64\n",
            "4\t2\t16\t.\n",
            "----------------------------------------\n",
            "\n",
            "Step 185 | Action: 0 | Reward: 1.50 | Score: 2248.0\n",
            "8\t2\t256\t64\n",
            "8\t32\t16\t.\n",
            ".\t2\t.\t.\n",
            ".\t2\t.\t.\n",
            "----------------------------------------\n",
            "\n",
            "Step 186 | Action: 2 | Reward: 0.00 | Score: 2248.0\n",
            "8\t2\t256\t64\n",
            "8\t32\t16\t.\n",
            "2\t.\t.\t.\n",
            "2\t.\t2\t.\n",
            "----------------------------------------\n",
            "\n",
            "Step 187 | Action: 2 | Reward: 0.12 | Score: 2252.0\n",
            "8\t2\t256\t64\n",
            "8\t32\t16\t.\n",
            "2\t.\t.\t.\n",
            "4\t.\t2\t.\n",
            "----------------------------------------\n",
            "\n",
            "Step 188 | Action: 0 | Reward: 0.50 | Score: 2268.0\n",
            "16\t2\t256\t64\n",
            "2\t32\t16\t.\n",
            "4\t.\t2\t.\n",
            ".\t.\t2\t.\n",
            "----------------------------------------\n",
            "\n",
            "Step 189 | Action: 2 | Reward: 0.00 | Score: 2268.0\n",
            "16\t2\t256\t64\n",
            "2\t32\t16\t.\n",
            "4\t2\t2\t.\n",
            "2\t.\t.\t.\n",
            "----------------------------------------\n",
            "\n",
            "Step 190 | Action: 1 | Reward: 0.00 | Score: 2268.0\n",
            "16\t.\t.\t.\n",
            "2\t2\t256\t4\n",
            "4\t32\t16\t.\n",
            "2\t2\t2\t64\n",
            "----------------------------------------\n",
            "\n",
            "Step 191 | Action: 1 | Reward: 0.00 | Score: 2268.0\n",
            "16\t2\t.\t.\n",
            "2\t2\t256\t.\n",
            "4\t32\t16\t4\n",
            "2\t2\t2\t64\n",
            "----------------------------------------\n",
            "\n",
            "Step 192 | Action: 3 | Reward: 0.25 | Score: 2276.0\n",
            ".\t.\t16\t2\n",
            ".\t.\t4\t256\n",
            "4\t32\t16\t4\n",
            "2\t2\t4\t64\n",
            "----------------------------------------\n",
            "\n",
            "Step 193 | Action: 0 | Reward: 0.00 | Score: 2276.0\n",
            "4\t32\t16\t2\n",
            "2\t2\t4\t256\n",
            "4\t.\t16\t4\n",
            ".\t.\t4\t64\n",
            "----------------------------------------\n",
            "\n",
            "Step 194 | Action: 1 | Reward: 0.00 | Score: 2276.0\n",
            ".\t2\t16\t2\n",
            "4\t.\t4\t256\n",
            "2\t32\t16\t4\n",
            "4\t2\t4\t64\n",
            "----------------------------------------\n",
            "\n",
            "Step 195 | Action: 0 | Reward: 0.00 | Score: 2276.0\n",
            "4\t2\t16\t2\n",
            "2\t32\t4\t256\n",
            "4\t2\t16\t4\n",
            "2\t.\t4\t64\n",
            "----------------------------------------\n",
            "\n",
            "Step 196 | Action: 1 | Reward: 0.00 | Score: 2276.0\n",
            "4\t2\t16\t2\n",
            "2\t2\t4\t256\n",
            "4\t32\t16\t4\n",
            "2\t2\t4\t64\n",
            "----------------------------------------\n",
            "\n",
            "Step 197 | Action: 1 | Reward: 0.12 | Score: 2280.0\n",
            "4\t4\t16\t2\n",
            "2\t4\t4\t256\n",
            "4\t32\t16\t4\n",
            "2\t2\t4\t64\n",
            "----------------------------------------\n",
            "\n",
            "Step 198 | Action: 2 | Reward: 0.62 | Score: 2300.0\n",
            "8\t16\t2\t.\n",
            "2\t8\t256\t.\n",
            "4\t32\t16\t4\n",
            "4\t4\t64\t2\n",
            "----------------------------------------\n",
            "\n",
            "Step 199 | Action: 0 | Reward: 0.25 | Score: 2308.0\n",
            "8\t16\t2\t4\n",
            "2\t8\t256\t2\n",
            "8\t32\t16\t.\n",
            ".\t4\t64\t2\n",
            "----------------------------------------\n",
            "\n",
            "Step 200 | Action: 1 | Reward: 0.12 | Score: 2312.0\n",
            ".\t16\t2\t2\n",
            "8\t8\t256\t.\n",
            "2\t32\t16\t4\n",
            "8\t4\t64\t4\n",
            "----------------------------------------\n",
            "\n",
            "Step 201 | Action: 1 | Reward: 0.25 | Score: 2320.0\n",
            ".\t16\t2\t.\n",
            "8\t8\t256\t2\n",
            "2\t32\t16\t2\n",
            "8\t4\t64\t8\n",
            "----------------------------------------\n",
            "\n",
            "Step 202 | Action: 3 | Reward: 0.50 | Score: 2336.0\n",
            ".\t2\t16\t2\n",
            ".\t16\t256\t2\n",
            "2\t32\t16\t2\n",
            "8\t4\t64\t8\n",
            "----------------------------------------\n",
            "\n",
            "Step 203 | Action: 1 | Reward: 0.12 | Score: 2340.0\n",
            "2\t2\t16\t.\n",
            ".\t16\t256\t2\n",
            "2\t32\t16\t4\n",
            "8\t4\t64\t8\n",
            "----------------------------------------\n",
            "\n",
            "Step 204 | Action: 3 | Reward: 0.12 | Score: 2344.0\n",
            "2\t.\t4\t16\n",
            ".\t16\t256\t2\n",
            "2\t32\t16\t4\n",
            "8\t4\t64\t8\n",
            "----------------------------------------\n",
            "\n",
            "Step 205 | Action: 0 | Reward: 0.12 | Score: 2348.0\n",
            "4\t16\t4\t16\n",
            "8\t32\t256\t2\n",
            ".\t4\t16\t4\n",
            ".\t2\t64\t8\n",
            "----------------------------------------\n",
            "\n",
            "Step 206 | Action: 2 | Reward: 0.00 | Score: 2348.0\n",
            "4\t16\t4\t16\n",
            "8\t32\t256\t2\n",
            "4\t16\t4\t.\n",
            "2\t64\t8\t2\n",
            "----------------------------------------\n",
            "\n",
            "Step 207 | Action: 1 | Reward: 0.12 | Score: 2352.0\n",
            "4\t16\t4\t.\n",
            "8\t32\t256\t2\n",
            "4\t16\t4\t16\n",
            "2\t64\t8\t4\n",
            "----------------------------------------\n",
            "\n",
            "Step 208 | Action: 1 | Reward: -1.00 | Score: 2352.0\n",
            "4\t16\t4\t.\n",
            "8\t32\t256\t2\n",
            "4\t16\t4\t16\n",
            "2\t64\t8\t4\n",
            "----------------------------------------\n",
            "\n",
            "Step 209 | Action: 0 | Reward: 0.00 | Score: 2352.0\n",
            "4\t16\t4\t2\n",
            "8\t32\t256\t16\n",
            "4\t16\t4\t4\n",
            "2\t64\t8\t2\n",
            "----------------------------------------\n",
            "\n",
            "Step 210 | Action: 1 | Reward: -1.00 | Score: 2352.0\n",
            "4\t16\t4\t2\n",
            "8\t32\t256\t16\n",
            "4\t16\t4\t4\n",
            "2\t64\t8\t2\n",
            "----------------------------------------\n",
            "\n",
            "Step 211 | Action: 3 | Reward: 0.25 | Score: 2360.0\n",
            "4\t16\t4\t2\n",
            "8\t32\t256\t16\n",
            "2\t4\t16\t8\n",
            "2\t64\t8\t2\n",
            "----------------------------------------\n",
            "\n",
            "Step 212 | Action: 2 | Reward: -1.00 | Score: 2360.0\n",
            "4\t16\t4\t2\n",
            "8\t32\t256\t16\n",
            "2\t4\t16\t8\n",
            "2\t64\t8\t2\n",
            "----------------------------------------\n",
            "\n",
            "Step 213 | Action: 3 | Reward: -1.00 | Score: 2360.0\n",
            "4\t16\t4\t2\n",
            "8\t32\t256\t16\n",
            "2\t4\t16\t8\n",
            "2\t64\t8\t2\n",
            "----------------------------------------\n",
            "\n",
            "Step 214 | Action: 0 | Reward: 0.12 | Score: 2364.0\n",
            "4\t16\t4\t2\n",
            "8\t32\t256\t16\n",
            "4\t4\t16\t8\n",
            "2\t64\t8\t2\n",
            "----------------------------------------\n",
            "\n",
            "Step 215 | Action: 0 | Reward: -1.00 | Score: 2364.0\n",
            "4\t16\t4\t2\n",
            "8\t32\t256\t16\n",
            "4\t4\t16\t8\n",
            "2\t64\t8\t2\n",
            "----------------------------------------\n",
            "\n",
            "Step 216 | Action: 3 | Reward: 0.25 | Score: 2372.0\n",
            "4\t16\t4\t2\n",
            "8\t32\t256\t16\n",
            "2\t8\t16\t8\n",
            "2\t64\t8\t2\n",
            "----------------------------------------\n",
            "\n",
            "Step 217 | Action: 2 | Reward: -1.00 | Score: 2372.0\n",
            "4\t16\t4\t2\n",
            "8\t32\t256\t16\n",
            "2\t8\t16\t8\n",
            "2\t64\t8\t2\n",
            "----------------------------------------\n",
            "\n",
            "Step 218 | Action: 2 | Reward: -1.00 | Score: 2372.0\n",
            "4\t16\t4\t2\n",
            "8\t32\t256\t16\n",
            "2\t8\t16\t8\n",
            "2\t64\t8\t2\n",
            "----------------------------------------\n",
            "\n",
            "Step 219 | Action: 1 | Reward: 0.12 | Score: 2376.0\n",
            "4\t16\t4\t2\n",
            "4\t32\t256\t16\n",
            "8\t8\t16\t8\n",
            "4\t64\t8\t2\n",
            "----------------------------------------\n",
            "\n",
            "Step 220 | Action: 3 | Reward: 0.50 | Score: 2392.0\n",
            "4\t16\t4\t2\n",
            "4\t32\t256\t16\n",
            "2\t16\t16\t8\n",
            "4\t64\t8\t2\n",
            "----------------------------------------\n",
            "\n",
            "Step 221 | Action: 3 | Reward: 1.00 | Score: 2424.0\n",
            "4\t16\t4\t2\n",
            "4\t32\t256\t16\n",
            "2\t2\t32\t8\n",
            "4\t64\t8\t2\n",
            "----------------------------------------\n",
            "\n",
            "Step 222 | Action: 3 | Reward: 0.12 | Score: 2428.0\n",
            "4\t16\t4\t2\n",
            "4\t32\t256\t16\n",
            "2\t4\t32\t8\n",
            "4\t64\t8\t2\n",
            "----------------------------------------\n",
            "\n",
            "Step 223 | Action: 1 | Reward: 0.25 | Score: 2436.0\n",
            "2\t16\t4\t2\n",
            "8\t32\t256\t16\n",
            "2\t4\t32\t8\n",
            "4\t64\t8\t2\n",
            "----------------------------------------\n",
            "\n",
            "=== Episode Finished ===\n",
            "Final Score: 2436.0\n",
            "Max Tile: 256\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from stable_baselines3 import PPO\n",
        "\n",
        "NUM_EPISODES = 30\n",
        "\n",
        "# Load model\n",
        "ppo_model = PPO.load(\"ppo_2048_v3_big\")\n",
        "\n",
        "def run_episode(env, policy_fn):\n",
        "    obs, info = env.reset()\n",
        "    done = False\n",
        "    total_reward = 0.0\n",
        "    final_score = 0.0\n",
        "    max_tile = 0\n",
        "\n",
        "    while not done:\n",
        "        action = policy_fn(obs, env)\n",
        "        obs, reward, terminated, truncated, info = env.step(action)\n",
        "        done = terminated or truncated\n",
        "\n",
        "        total_reward += reward\n",
        "        final_score = info[\"score\"]\n",
        "        max_tile = info[\"max_tile\"]\n",
        "\n",
        "    return total_reward, final_score, max_tile\n",
        "\n",
        "def random_policy(obs, env):\n",
        "    return env.action_space.sample()\n",
        "\n",
        "def ppo_policy(obs, env):\n",
        "    action, _ = ppo_model.predict(obs, deterministic=True)\n",
        "    return int(action)\n",
        "\n",
        "def evaluate(name, policy_fn, num_episodes=NUM_EPISODES):\n",
        "    rewards, scores, tiles = [], [], []\n",
        "    for _ in range(num_episodes):\n",
        "        env = Game2048EnvV3()\n",
        "        R, S, T = run_episode(env, policy_fn)\n",
        "        rewards.append(R)\n",
        "        scores.append(S)\n",
        "        tiles.append(T)\n",
        "    print(f\"\\n=== {name} over {num_episodes} episodes ===\")\n",
        "    print(f\"Avg total_reward: {np.mean(rewards):.2f} ¬± {np.std(rewards):.2f}\")\n",
        "    print(f\"Avg final score:  {np.mean(scores):.2f} ¬± {np.std(scores):.2f}\")\n",
        "    print(f\"Avg max tile:     {np.mean(tiles):.1f}\")\n",
        "    print(f\"Max of max tiles: {np.max(tiles)}\")\n",
        "    return rewards, scores, tiles\n",
        "\n",
        "rand_r, rand_s, rand_t = evaluate(\"Random\", random_policy)\n",
        "ppo_r,  ppo_s,  ppo_t  = evaluate(\"PPO\",    ppo_policy,num_episodes=2)\n",
        "\n",
        "print(\"\\nDone.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "J507PgsTVgf6",
        "outputId": "4bc69650-ce8b-4eda-fb1f-aa58ca784e8a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Random over 30 episodes ===\n",
            "Avg total_reward: 9.68 ¬± 10.65\n",
            "Avg final score:  962.40 ¬± 466.98\n",
            "Avg max tile:     89.6\n",
            "Max of max tiles: 128\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2184795140.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0mrand_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrand_s\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrand_t\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Random\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_policy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m \u001b[0mppo_r\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mppo_s\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mppo_t\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"PPO\"\u001b[0m\u001b[0;34m,\u001b[0m    \u001b[0mppo_policy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_episodes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nDone.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2184795140.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(name, policy_fn, num_episodes)\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_episodes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGame2048EnvV3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mR\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_episode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpolicy_fn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0mrewards\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mR\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2184795140.py\u001b[0m in \u001b[0;36mrun_episode\u001b[0;34m(env, policy_fn)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpolicy_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m         \u001b[0mobs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minfo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m         \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mterminated\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtruncated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3159462754.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0maction\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# left\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboard_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                 \u001b[0mnew_line\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slide_and_merge_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mboard\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_line\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0mmerged_value\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmv\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-3159462754.py\u001b[0m in \u001b[0;36m_slide_and_merge_line\u001b[0;34m(self, line)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_slide_and_merge_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mnon_zero\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mline\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mnew\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mmerged_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}