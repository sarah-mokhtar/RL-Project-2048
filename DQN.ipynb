{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87d80f67",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium import spaces\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "class TwentyFortyEightEnv(gym.Env):\n",
    "    metadata = {\"render_modes\": [\"human\"], \"render_fps\": 4}\n",
    "\n",
    "    def __init__(self, render_mode=None):\n",
    "        super().__init__()\n",
    "        self.board_size = 4\n",
    "\n",
    "        # Actions: 0 = up, 1 = down, 2 = left, 3 = right\n",
    "        self.action_space = spaces.Discrete(4)\n",
    "\n",
    "        # Board is 4x4 integers; observation is a flattened vector of size 16\n",
    "        self.observation_space = spaces.Box(\n",
    "            low=0,\n",
    "            high=2**16,\n",
    "            shape=(16,),\n",
    "            dtype=np.int32\n",
    "        )\n",
    "\n",
    "        self.render_mode = render_mode\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self, seed=None, options=None):\n",
    "        super().reset(seed=seed)\n",
    "\n",
    "        self.board = np.zeros((self.board_size, self.board_size), dtype=np.int32)\n",
    "        self.score = 0\n",
    "\n",
    "        self._add_tile()\n",
    "        self._add_tile()\n",
    "\n",
    "        return self._get_obs(), {}\n",
    "\n",
    "    def step(self, action):\n",
    "        old_board = self.board[:][:]\n",
    "\n",
    "        if action == 0:\n",
    "            reward = self._move_up()\n",
    "        elif action == 1:\n",
    "            reward = self._move_down()\n",
    "        elif action == 2:\n",
    "            reward = self._move_left()\n",
    "        elif action == 3:\n",
    "            reward = self._move_right()\n",
    "\n",
    "        # Invalid move (board unchanged)\n",
    "        if np.array_equal(self.board, old_board):\n",
    "            reward = -2  # small penalty for useless actions\n",
    "\n",
    "        else:\n",
    "            # Only add a tile after a valid move\n",
    "            self._add_tile()\n",
    "\n",
    "        done = not self._moves_available()\n",
    "\n",
    "        return self._get_obs(), reward, done, False, {\"score\": self.score}\n",
    "\n",
    "    # -------- Rendering -------- #\n",
    "\n",
    "    def render(self):\n",
    "        print(\"\\nScore:\", self.score)\n",
    "        print(\"-\" * 25)\n",
    "        for row in self.board:\n",
    "            print(\"|\" + \"|\".join(f\"{num:^5}\" if num != 0 else \"     \" for num in row) + \"|\")\n",
    "            print(\"-\" * 25)\n",
    "\n",
    "    # -------- Helper Methods -------- #\n",
    "\n",
    "    def _get_obs(self):\n",
    "        return self.board.flatten()\n",
    "\n",
    "    def _add_tile(self):\n",
    "        empty = list(zip(*np.where(self.board == 0)))\n",
    "        if not empty:\n",
    "            return\n",
    "        i, j = random.choice(empty)\n",
    "        self.board[i, j] = 4 if random.random() < 0.1 else 2\n",
    "\n",
    "    def _moves_available(self):\n",
    "        if np.any(self.board == 0):\n",
    "            return True\n",
    "        for i in range(4):\n",
    "            for j in range(4):\n",
    "                if j < 3 and self.board[i, j] == self.board[i, j + 1]:\n",
    "                    return True\n",
    "                if i < 3 and self.board[i, j] == self.board[i + 1, j]:\n",
    "                    return True\n",
    "        return False\n",
    "\n",
    "    # -------- Movement Logic -------- #\n",
    "\n",
    "    def _compress(self, row):\n",
    "        new = row[row != 0]\n",
    "        return np.concatenate([new, np.zeros(4 - len(new), dtype=np.int32)])\n",
    "\n",
    "    def _merge(self, row):\n",
    "        score_gain = 0\n",
    "        for i in range(3):\n",
    "            if row[i] != 0 and row[i] == row[i + 1]:\n",
    "                row[i] *= 2\n",
    "                row[i + 1] = 0\n",
    "                score_gain += row[i]\n",
    "        return row, score_gain\n",
    "\n",
    "    def _move_left(self):\n",
    "        total_gain = 0\n",
    "        new_board = np.zeros((self.board_size, self.board_size), dtype=np.int32)\n",
    "\n",
    "        for i in range(4):\n",
    "            row = self._compress(self.board[i])\n",
    "            row, gain = self._merge(row)\n",
    "            row = self._compress(row)\n",
    "\n",
    "            new_board[i] = row\n",
    "            total_gain += gain\n",
    "\n",
    "        self.board = new_board\n",
    "        self.score += total_gain\n",
    "        return float(total_gain)\n",
    "\n",
    "    def _move_right(self):\n",
    "        self.board = np.fliplr(self.board)\n",
    "        reward = self._move_left()\n",
    "        self.board = np.fliplr(self.board)\n",
    "        return reward\n",
    "\n",
    "    def _move_up(self):\n",
    "        self.board = self.board.T\n",
    "        reward = self._move_left()\n",
    "        self.board = self.board.T\n",
    "        return reward\n",
    "\n",
    "    def _move_down(self):\n",
    "        self.board = self.board.T\n",
    "        reward = self._move_right()\n",
    "        self.board = self.board.T\n",
    "        return reward\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "03b65c0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 0\n",
      "-------------------------\n",
      "|     |     |     |     |\n",
      "-------------------------\n",
      "|  2  |     |     |     |\n",
      "-------------------------\n",
      "|  2  |     |     |     |\n",
      "-------------------------\n",
      "|     |     |     |     |\n",
      "-------------------------\n",
      "\n",
      "Score: 4\n",
      "-------------------------\n",
      "|  4  |     |     |     |\n",
      "-------------------------\n",
      "|     |     |     |     |\n",
      "-------------------------\n",
      "|     |     |     |     |\n",
      "-------------------------\n",
      "|     |     |  2  |     |\n",
      "-------------------------\n",
      "\n",
      "Score: 4\n",
      "-------------------------\n",
      "|  4  |     |  2  |     |\n",
      "-------------------------\n",
      "|  4  |     |     |     |\n",
      "-------------------------\n",
      "|     |     |     |     |\n",
      "-------------------------\n",
      "|     |     |     |     |\n",
      "-------------------------\n"
     ]
    }
   ],
   "source": [
    "env = TwentyFortyEightEnv()\n",
    "env.reset()\n",
    "env.render()\n",
    "env.step(0)\n",
    "env.render()\n",
    "env.step(0)\n",
    "env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc90ce11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 186      |\n",
      "|    ep_rew_mean      | 1.56e+03 |\n",
      "|    exploration_rate | 0.996    |\n",
      "| time/               |          |\n",
      "|    episodes         | 4        |\n",
      "|    fps              | 9510     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 744      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 170      |\n",
      "|    ep_rew_mean      | 1.38e+03 |\n",
      "|    exploration_rate | 0.994    |\n",
      "| time/               |          |\n",
      "|    episodes         | 8        |\n",
      "|    fps              | 8746     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 1357     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 159      |\n",
      "|    ep_rew_mean      | 1.26e+03 |\n",
      "|    exploration_rate | 0.991    |\n",
      "| time/               |          |\n",
      "|    episodes         | 12       |\n",
      "|    fps              | 8852     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 1906     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 163      |\n",
      "|    ep_rew_mean      | 1.3e+03  |\n",
      "|    exploration_rate | 0.988    |\n",
      "| time/               |          |\n",
      "|    episodes         | 16       |\n",
      "|    fps              | 8991     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 2601     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 158      |\n",
      "|    ep_rew_mean      | 1.25e+03 |\n",
      "|    exploration_rate | 0.985    |\n",
      "| time/               |          |\n",
      "|    episodes         | 20       |\n",
      "|    fps              | 9014     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 3170     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 159      |\n",
      "|    ep_rew_mean      | 1.24e+03 |\n",
      "|    exploration_rate | 0.982    |\n",
      "| time/               |          |\n",
      "|    episodes         | 24       |\n",
      "|    fps              | 9042     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 3815     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 151      |\n",
      "|    ep_rew_mean      | 1.16e+03 |\n",
      "|    exploration_rate | 0.98     |\n",
      "| time/               |          |\n",
      "|    episodes         | 28       |\n",
      "|    fps              | 9051     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 4241     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 155      |\n",
      "|    ep_rew_mean      | 1.18e+03 |\n",
      "|    exploration_rate | 0.977    |\n",
      "| time/               |          |\n",
      "|    episodes         | 32       |\n",
      "|    fps              | 9075     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 4947     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 154      |\n",
      "|    ep_rew_mean      | 1.18e+03 |\n",
      "|    exploration_rate | 0.974    |\n",
      "| time/               |          |\n",
      "|    episodes         | 36       |\n",
      "|    fps              | 9076     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 5534     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 159      |\n",
      "|    ep_rew_mean      | 1.25e+03 |\n",
      "|    exploration_rate | 0.97     |\n",
      "| time/               |          |\n",
      "|    episodes         | 40       |\n",
      "|    fps              | 9077     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 6356     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 157      |\n",
      "|    ep_rew_mean      | 1.23e+03 |\n",
      "|    exploration_rate | 0.967    |\n",
      "| time/               |          |\n",
      "|    episodes         | 44       |\n",
      "|    fps              | 9097     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 6910     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 158      |\n",
      "|    ep_rew_mean      | 1.25e+03 |\n",
      "|    exploration_rate | 0.964    |\n",
      "| time/               |          |\n",
      "|    episodes         | 48       |\n",
      "|    fps              | 9114     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 7587     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 157      |\n",
      "|    ep_rew_mean      | 1.25e+03 |\n",
      "|    exploration_rate | 0.961    |\n",
      "| time/               |          |\n",
      "|    episodes         | 52       |\n",
      "|    fps              | 9130     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 8181     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 157      |\n",
      "|    ep_rew_mean      | 1.24e+03 |\n",
      "|    exploration_rate | 0.958    |\n",
      "| time/               |          |\n",
      "|    episodes         | 56       |\n",
      "|    fps              | 9133     |\n",
      "|    time_elapsed     | 0        |\n",
      "|    total_timesteps  | 8765     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 156      |\n",
      "|    ep_rew_mean      | 1.23e+03 |\n",
      "|    exploration_rate | 0.956    |\n",
      "| time/               |          |\n",
      "|    episodes         | 60       |\n",
      "|    fps              | 9139     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 9332     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 154      |\n",
      "|    ep_rew_mean      | 1.21e+03 |\n",
      "|    exploration_rate | 0.953    |\n",
      "| time/               |          |\n",
      "|    episodes         | 64       |\n",
      "|    fps              | 9140     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 9832     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 153      |\n",
      "|    ep_rew_mean      | 1.2e+03  |\n",
      "|    exploration_rate | 0.951    |\n",
      "| time/               |          |\n",
      "|    episodes         | 68       |\n",
      "|    fps              | 5593     |\n",
      "|    time_elapsed     | 1        |\n",
      "|    total_timesteps  | 10388    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 873      |\n",
      "|    n_updates        | 96       |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 153      |\n",
      "|    ep_rew_mean      | 1.21e+03 |\n",
      "|    exploration_rate | 0.948    |\n",
      "| time/               |          |\n",
      "|    episodes         | 72       |\n",
      "|    fps              | 3716     |\n",
      "|    time_elapsed     | 2        |\n",
      "|    total_timesteps  | 11024    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 975      |\n",
      "|    n_updates        | 255      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 154      |\n",
      "|    ep_rew_mean      | 1.23e+03 |\n",
      "|    exploration_rate | 0.944    |\n",
      "| time/               |          |\n",
      "|    episodes         | 76       |\n",
      "|    fps              | 2786     |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 11740    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 838      |\n",
      "|    n_updates        | 434      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 152      |\n",
      "|    ep_rew_mean      | 1.2e+03  |\n",
      "|    exploration_rate | 0.942    |\n",
      "| time/               |          |\n",
      "|    episodes         | 80       |\n",
      "|    fps              | 2445     |\n",
      "|    time_elapsed     | 4        |\n",
      "|    total_timesteps  | 12178    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.05e+03 |\n",
      "|    n_updates        | 544      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 152      |\n",
      "|    ep_rew_mean      | 1.19e+03 |\n",
      "|    exploration_rate | 0.94     |\n",
      "| time/               |          |\n",
      "|    episodes         | 84       |\n",
      "|    fps              | 2140     |\n",
      "|    time_elapsed     | 5        |\n",
      "|    total_timesteps  | 12736    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 883      |\n",
      "|    n_updates        | 683      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 151      |\n",
      "|    ep_rew_mean      | 1.18e+03 |\n",
      "|    exploration_rate | 0.937    |\n",
      "| time/               |          |\n",
      "|    episodes         | 88       |\n",
      "|    fps              | 1930     |\n",
      "|    time_elapsed     | 6        |\n",
      "|    total_timesteps  | 13253    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.17e+03 |\n",
      "|    n_updates        | 813      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 150      |\n",
      "|    ep_rew_mean      | 1.18e+03 |\n",
      "|    exploration_rate | 0.935    |\n",
      "| time/               |          |\n",
      "|    episodes         | 92       |\n",
      "|    fps              | 1768     |\n",
      "|    time_elapsed     | 7        |\n",
      "|    total_timesteps  | 13781    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.27e+03 |\n",
      "|    n_updates        | 945      |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 150      |\n",
      "|    ep_rew_mean      | 1.17e+03 |\n",
      "|    exploration_rate | 0.932    |\n",
      "| time/               |          |\n",
      "|    episodes         | 96       |\n",
      "|    fps              | 1629     |\n",
      "|    time_elapsed     | 8        |\n",
      "|    total_timesteps  | 14362    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.48e+03 |\n",
      "|    n_updates        | 1090     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 149      |\n",
      "|    ep_rew_mean      | 1.16e+03 |\n",
      "|    exploration_rate | 0.929    |\n",
      "| time/               |          |\n",
      "|    episodes         | 100      |\n",
      "|    fps              | 1535     |\n",
      "|    time_elapsed     | 9        |\n",
      "|    total_timesteps  | 14856    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.45e+03 |\n",
      "|    n_updates        | 1213     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 146      |\n",
      "|    ep_rew_mean      | 1.14e+03 |\n",
      "|    exploration_rate | 0.927    |\n",
      "| time/               |          |\n",
      "|    episodes         | 104      |\n",
      "|    fps              | 1450     |\n",
      "|    time_elapsed     | 10       |\n",
      "|    total_timesteps  | 15391    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.77e+03 |\n",
      "|    n_updates        | 1347     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 147      |\n",
      "|    ep_rew_mean      | 1.14e+03 |\n",
      "|    exploration_rate | 0.924    |\n",
      "| time/               |          |\n",
      "|    episodes         | 108      |\n",
      "|    fps              | 1363     |\n",
      "|    time_elapsed     | 11       |\n",
      "|    total_timesteps  | 16050    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.83e+03 |\n",
      "|    n_updates        | 1512     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 147      |\n",
      "|    ep_rew_mean      | 1.14e+03 |\n",
      "|    exploration_rate | 0.921    |\n",
      "| time/               |          |\n",
      "|    episodes         | 112      |\n",
      "|    fps              | 1297     |\n",
      "|    time_elapsed     | 12       |\n",
      "|    total_timesteps  | 16651    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 1.91e+03 |\n",
      "|    n_updates        | 1662     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 144      |\n",
      "|    ep_rew_mean      | 1.11e+03 |\n",
      "|    exploration_rate | 0.919    |\n",
      "| time/               |          |\n",
      "|    episodes         | 116      |\n",
      "|    fps              | 1260     |\n",
      "|    time_elapsed     | 13       |\n",
      "|    total_timesteps  | 17046    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.15e+03 |\n",
      "|    n_updates        | 1761     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 144      |\n",
      "|    ep_rew_mean      | 1.11e+03 |\n",
      "|    exploration_rate | 0.917    |\n",
      "| time/               |          |\n",
      "|    episodes         | 120      |\n",
      "|    fps              | 1216     |\n",
      "|    time_elapsed     | 14       |\n",
      "|    total_timesteps  | 17566    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.02e+03 |\n",
      "|    n_updates        | 1891     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 141      |\n",
      "|    ep_rew_mean      | 1.08e+03 |\n",
      "|    exploration_rate | 0.915    |\n",
      "| time/               |          |\n",
      "|    episodes         | 124      |\n",
      "|    fps              | 1185     |\n",
      "|    time_elapsed     | 15       |\n",
      "|    total_timesteps  | 17960    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.08e+03 |\n",
      "|    n_updates        | 1989     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 143      |\n",
      "|    ep_rew_mean      | 1.1e+03  |\n",
      "|    exploration_rate | 0.912    |\n",
      "| time/               |          |\n",
      "|    episodes         | 128      |\n",
      "|    fps              | 1145     |\n",
      "|    time_elapsed     | 16       |\n",
      "|    total_timesteps  | 18559    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.33e+03 |\n",
      "|    n_updates        | 2139     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 141      |\n",
      "|    ep_rew_mean      | 1.08e+03 |\n",
      "|    exploration_rate | 0.909    |\n",
      "| time/               |          |\n",
      "|    episodes         | 132      |\n",
      "|    fps              | 1114     |\n",
      "|    time_elapsed     | 17       |\n",
      "|    total_timesteps  | 19069    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.4e+03  |\n",
      "|    n_updates        | 2267     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 141      |\n",
      "|    ep_rew_mean      | 1.08e+03 |\n",
      "|    exploration_rate | 0.907    |\n",
      "| time/               |          |\n",
      "|    episodes         | 136      |\n",
      "|    fps              | 1083     |\n",
      "|    time_elapsed     | 18       |\n",
      "|    total_timesteps  | 19651    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.45e+03 |\n",
      "|    n_updates        | 2412     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 139      |\n",
      "|    ep_rew_mean      | 1.05e+03 |\n",
      "|    exploration_rate | 0.904    |\n",
      "| time/               |          |\n",
      "|    episodes         | 140      |\n",
      "|    fps              | 1054     |\n",
      "|    time_elapsed     | 19       |\n",
      "|    total_timesteps  | 20272    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.69e+03 |\n",
      "|    n_updates        | 2567     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 138      |\n",
      "|    ep_rew_mean      | 1.04e+03 |\n",
      "|    exploration_rate | 0.902    |\n",
      "| time/               |          |\n",
      "|    episodes         | 144      |\n",
      "|    fps              | 1033     |\n",
      "|    time_elapsed     | 20       |\n",
      "|    total_timesteps  | 20736    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.5e+03  |\n",
      "|    n_updates        | 2683     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 137      |\n",
      "|    ep_rew_mean      | 1.02e+03 |\n",
      "|    exploration_rate | 0.899    |\n",
      "| time/               |          |\n",
      "|    episodes         | 148      |\n",
      "|    fps              | 1010     |\n",
      "|    time_elapsed     | 21       |\n",
      "|    total_timesteps  | 21322    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.66e+03 |\n",
      "|    n_updates        | 2830     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 138      |\n",
      "|    ep_rew_mean      | 1.04e+03 |\n",
      "|    exploration_rate | 0.895    |\n",
      "| time/               |          |\n",
      "|    episodes         | 152      |\n",
      "|    fps              | 985      |\n",
      "|    time_elapsed     | 22       |\n",
      "|    total_timesteps  | 22019    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.03e+03 |\n",
      "|    n_updates        | 3004     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 137      |\n",
      "|    ep_rew_mean      | 1.02e+03 |\n",
      "|    exploration_rate | 0.893    |\n",
      "| time/               |          |\n",
      "|    episodes         | 156      |\n",
      "|    fps              | 971      |\n",
      "|    time_elapsed     | 23       |\n",
      "|    total_timesteps  | 22461    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.07e+03 |\n",
      "|    n_updates        | 3115     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 136      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.891    |\n",
      "| time/               |          |\n",
      "|    episodes         | 160      |\n",
      "|    fps              | 957      |\n",
      "|    time_elapsed     | 23       |\n",
      "|    total_timesteps  | 22908    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 2.81e+03 |\n",
      "|    n_updates        | 3226     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 137      |\n",
      "|    ep_rew_mean      | 1.01e+03 |\n",
      "|    exploration_rate | 0.888    |\n",
      "| time/               |          |\n",
      "|    episodes         | 164      |\n",
      "|    fps              | 940      |\n",
      "|    time_elapsed     | 24       |\n",
      "|    total_timesteps  | 23506    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.17e+03 |\n",
      "|    n_updates        | 3376     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 136      |\n",
      "|    ep_rew_mean      | 999      |\n",
      "|    exploration_rate | 0.886    |\n",
      "| time/               |          |\n",
      "|    episodes         | 168      |\n",
      "|    fps              | 927      |\n",
      "|    time_elapsed     | 25       |\n",
      "|    total_timesteps  | 24017    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.39e+03 |\n",
      "|    n_updates        | 3504     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 135      |\n",
      "|    ep_rew_mean      | 984      |\n",
      "|    exploration_rate | 0.883    |\n",
      "| time/               |          |\n",
      "|    episodes         | 172      |\n",
      "|    fps              | 914      |\n",
      "|    time_elapsed     | 26       |\n",
      "|    total_timesteps  | 24560    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.25e+03 |\n",
      "|    n_updates        | 3639     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 134      |\n",
      "|    ep_rew_mean      | 966      |\n",
      "|    exploration_rate | 0.881    |\n",
      "| time/               |          |\n",
      "|    episodes         | 176      |\n",
      "|    fps              | 901      |\n",
      "|    time_elapsed     | 27       |\n",
      "|    total_timesteps  | 25109    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.48e+03 |\n",
      "|    n_updates        | 3777     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 137      |\n",
      "|    ep_rew_mean      | 999      |\n",
      "|    exploration_rate | 0.877    |\n",
      "| time/               |          |\n",
      "|    episodes         | 180      |\n",
      "|    fps              | 885      |\n",
      "|    time_elapsed     | 29       |\n",
      "|    total_timesteps  | 25841    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.54e+03 |\n",
      "|    n_updates        | 3960     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 137      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.874    |\n",
      "| time/               |          |\n",
      "|    episodes         | 184      |\n",
      "|    fps              | 873      |\n",
      "|    time_elapsed     | 30       |\n",
      "|    total_timesteps  | 26453    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.59e+03 |\n",
      "|    n_updates        | 4113     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 138      |\n",
      "|    ep_rew_mean      | 1.01e+03 |\n",
      "|    exploration_rate | 0.872    |\n",
      "| time/               |          |\n",
      "|    episodes         | 188      |\n",
      "|    fps              | 862      |\n",
      "|    time_elapsed     | 31       |\n",
      "|    total_timesteps  | 27039    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.8e+03  |\n",
      "|    n_updates        | 4259     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 140      |\n",
      "|    ep_rew_mean      | 1.03e+03 |\n",
      "|    exploration_rate | 0.868    |\n",
      "| time/               |          |\n",
      "|    episodes         | 192      |\n",
      "|    fps              | 850      |\n",
      "|    time_elapsed     | 32       |\n",
      "|    total_timesteps  | 27741    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.83e+03 |\n",
      "|    n_updates        | 4435     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 139      |\n",
      "|    ep_rew_mean      | 1.02e+03 |\n",
      "|    exploration_rate | 0.866    |\n",
      "| time/               |          |\n",
      "|    episodes         | 196      |\n",
      "|    fps              | 843      |\n",
      "|    time_elapsed     | 33       |\n",
      "|    total_timesteps  | 28217    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.97e+03 |\n",
      "|    n_updates        | 4554     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 137      |\n",
      "|    ep_rew_mean      | 1.01e+03 |\n",
      "|    exploration_rate | 0.864    |\n",
      "| time/               |          |\n",
      "|    episodes         | 200      |\n",
      "|    fps              | 837      |\n",
      "|    time_elapsed     | 34       |\n",
      "|    total_timesteps  | 28573    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 3.85e+03 |\n",
      "|    n_updates        | 4643     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 136      |\n",
      "|    ep_rew_mean      | 998      |\n",
      "|    exploration_rate | 0.862    |\n",
      "| time/               |          |\n",
      "|    episodes         | 204      |\n",
      "|    fps              | 831      |\n",
      "|    time_elapsed     | 34       |\n",
      "|    total_timesteps  | 29035    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.18e+03 |\n",
      "|    n_updates        | 4758     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 136      |\n",
      "|    ep_rew_mean      | 979      |\n",
      "|    exploration_rate | 0.859    |\n",
      "| time/               |          |\n",
      "|    episodes         | 208      |\n",
      "|    fps              | 823      |\n",
      "|    time_elapsed     | 35       |\n",
      "|    total_timesteps  | 29602    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.17e+03 |\n",
      "|    n_updates        | 4900     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 137      |\n",
      "|    ep_rew_mean      | 999      |\n",
      "|    exploration_rate | 0.856    |\n",
      "| time/               |          |\n",
      "|    episodes         | 212      |\n",
      "|    fps              | 812      |\n",
      "|    time_elapsed     | 37       |\n",
      "|    total_timesteps  | 30360    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.35e+03 |\n",
      "|    n_updates        | 5089     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 138      |\n",
      "|    ep_rew_mean      | 1.01e+03 |\n",
      "|    exploration_rate | 0.853    |\n",
      "| time/               |          |\n",
      "|    episodes         | 216      |\n",
      "|    fps              | 806      |\n",
      "|    time_elapsed     | 38       |\n",
      "|    total_timesteps  | 30861    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.29e+03 |\n",
      "|    n_updates        | 5215     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 139      |\n",
      "|    ep_rew_mean      | 1.02e+03 |\n",
      "|    exploration_rate | 0.85     |\n",
      "| time/               |          |\n",
      "|    episodes         | 220      |\n",
      "|    fps              | 799      |\n",
      "|    time_elapsed     | 39       |\n",
      "|    total_timesteps  | 31503    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.4e+03  |\n",
      "|    n_updates        | 5375     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 142      |\n",
      "|    ep_rew_mean      | 1.05e+03 |\n",
      "|    exploration_rate | 0.847    |\n",
      "| time/               |          |\n",
      "|    episodes         | 224      |\n",
      "|    fps              | 792      |\n",
      "|    time_elapsed     | 40       |\n",
      "|    total_timesteps  | 32173    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.78e+03 |\n",
      "|    n_updates        | 5543     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 142      |\n",
      "|    ep_rew_mean      | 1.05e+03 |\n",
      "|    exploration_rate | 0.845    |\n",
      "| time/               |          |\n",
      "|    episodes         | 228      |\n",
      "|    fps              | 786      |\n",
      "|    time_elapsed     | 41       |\n",
      "|    total_timesteps  | 32713    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.74e+03 |\n",
      "|    n_updates        | 5678     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 144      |\n",
      "|    ep_rew_mean      | 1.07e+03 |\n",
      "|    exploration_rate | 0.841    |\n",
      "| time/               |          |\n",
      "|    episodes         | 232      |\n",
      "|    fps              | 778      |\n",
      "|    time_elapsed     | 42       |\n",
      "|    total_timesteps  | 33472    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.96e+03 |\n",
      "|    n_updates        | 5867     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 143      |\n",
      "|    ep_rew_mean      | 1.06e+03 |\n",
      "|    exploration_rate | 0.839    |\n",
      "| time/               |          |\n",
      "|    episodes         | 236      |\n",
      "|    fps              | 774      |\n",
      "|    time_elapsed     | 43       |\n",
      "|    total_timesteps  | 33955    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.77e+03 |\n",
      "|    n_updates        | 5988     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 142      |\n",
      "|    ep_rew_mean      | 1.05e+03 |\n",
      "|    exploration_rate | 0.836    |\n",
      "| time/               |          |\n",
      "|    episodes         | 240      |\n",
      "|    fps              | 769      |\n",
      "|    time_elapsed     | 44       |\n",
      "|    total_timesteps  | 34485    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.3e+03  |\n",
      "|    n_updates        | 6121     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 141      |\n",
      "|    ep_rew_mean      | 1.04e+03 |\n",
      "|    exploration_rate | 0.835    |\n",
      "| time/               |          |\n",
      "|    episodes         | 244      |\n",
      "|    fps              | 765      |\n",
      "|    time_elapsed     | 45       |\n",
      "|    total_timesteps  | 34842    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 4.89e+03 |\n",
      "|    n_updates        | 6210     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 140      |\n",
      "|    ep_rew_mean      | 1.02e+03 |\n",
      "|    exploration_rate | 0.832    |\n",
      "| time/               |          |\n",
      "|    episodes         | 248      |\n",
      "|    fps              | 762      |\n",
      "|    time_elapsed     | 46       |\n",
      "|    total_timesteps  | 35308    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.01e+03 |\n",
      "|    n_updates        | 6326     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 139      |\n",
      "|    ep_rew_mean      | 1.01e+03 |\n",
      "|    exploration_rate | 0.829    |\n",
      "| time/               |          |\n",
      "|    episodes         | 252      |\n",
      "|    fps              | 756      |\n",
      "|    time_elapsed     | 47       |\n",
      "|    total_timesteps  | 35959    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.23e+03 |\n",
      "|    n_updates        | 6489     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 141      |\n",
      "|    ep_rew_mean      | 1.02e+03 |\n",
      "|    exploration_rate | 0.827    |\n",
      "| time/               |          |\n",
      "|    episodes         | 256      |\n",
      "|    fps              | 752      |\n",
      "|    time_elapsed     | 48       |\n",
      "|    total_timesteps  | 36520    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.68e+03 |\n",
      "|    n_updates        | 6629     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 142      |\n",
      "|    ep_rew_mean      | 1.03e+03 |\n",
      "|    exploration_rate | 0.824    |\n",
      "| time/               |          |\n",
      "|    episodes         | 260      |\n",
      "|    fps              | 747      |\n",
      "|    time_elapsed     | 49       |\n",
      "|    total_timesteps  | 37107    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.33e+03 |\n",
      "|    n_updates        | 6776     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 144      |\n",
      "|    ep_rew_mean      | 1.05e+03 |\n",
      "|    exploration_rate | 0.82     |\n",
      "| time/               |          |\n",
      "|    episodes         | 264      |\n",
      "|    fps              | 742      |\n",
      "|    time_elapsed     | 51       |\n",
      "|    total_timesteps  | 37881    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.66e+03 |\n",
      "|    n_updates        | 6970     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 144      |\n",
      "|    ep_rew_mean      | 1.06e+03 |\n",
      "|    exploration_rate | 0.817    |\n",
      "| time/               |          |\n",
      "|    episodes         | 268      |\n",
      "|    fps              | 738      |\n",
      "|    time_elapsed     | 52       |\n",
      "|    total_timesteps  | 38467    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.66e+03 |\n",
      "|    n_updates        | 7116     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 145      |\n",
      "|    ep_rew_mean      | 1.06e+03 |\n",
      "|    exploration_rate | 0.814    |\n",
      "| time/               |          |\n",
      "|    episodes         | 272      |\n",
      "|    fps              | 733      |\n",
      "|    time_elapsed     | 53       |\n",
      "|    total_timesteps  | 39104    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.8e+03  |\n",
      "|    n_updates        | 7275     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 146      |\n",
      "|    ep_rew_mean      | 1.07e+03 |\n",
      "|    exploration_rate | 0.811    |\n",
      "| time/               |          |\n",
      "|    episodes         | 276      |\n",
      "|    fps              | 730      |\n",
      "|    time_elapsed     | 54       |\n",
      "|    total_timesteps  | 39707    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 5.9e+03  |\n",
      "|    n_updates        | 7426     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 143      |\n",
      "|    ep_rew_mean      | 1.04e+03 |\n",
      "|    exploration_rate | 0.809    |\n",
      "| time/               |          |\n",
      "|    episodes         | 280      |\n",
      "|    fps              | 727      |\n",
      "|    time_elapsed     | 55       |\n",
      "|    total_timesteps  | 40171    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.19e+03 |\n",
      "|    n_updates        | 7542     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 142      |\n",
      "|    ep_rew_mean      | 1.02e+03 |\n",
      "|    exploration_rate | 0.807    |\n",
      "| time/               |          |\n",
      "|    episodes         | 284      |\n",
      "|    fps              | 723      |\n",
      "|    time_elapsed     | 56       |\n",
      "|    total_timesteps  | 40695    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.06e+03 |\n",
      "|    n_updates        | 7673     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 143      |\n",
      "|    ep_rew_mean      | 1.02e+03 |\n",
      "|    exploration_rate | 0.804    |\n",
      "| time/               |          |\n",
      "|    episodes         | 288      |\n",
      "|    fps              | 720      |\n",
      "|    time_elapsed     | 57       |\n",
      "|    total_timesteps  | 41325    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.51e+03 |\n",
      "|    n_updates        | 7831     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 142      |\n",
      "|    ep_rew_mean      | 1e+03    |\n",
      "|    exploration_rate | 0.801    |\n",
      "| time/               |          |\n",
      "|    episodes         | 292      |\n",
      "|    fps              | 717      |\n",
      "|    time_elapsed     | 58       |\n",
      "|    total_timesteps  | 41924    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.16e+03 |\n",
      "|    n_updates        | 7980     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 143      |\n",
      "|    ep_rew_mean      | 1.01e+03 |\n",
      "|    exploration_rate | 0.798    |\n",
      "| time/               |          |\n",
      "|    episodes         | 296      |\n",
      "|    fps              | 713      |\n",
      "|    time_elapsed     | 59       |\n",
      "|    total_timesteps  | 42557    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.59e+03 |\n",
      "|    n_updates        | 8139     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 147      |\n",
      "|    ep_rew_mean      | 1.05e+03 |\n",
      "|    exploration_rate | 0.794    |\n",
      "| time/               |          |\n",
      "|    episodes         | 300      |\n",
      "|    fps              | 709      |\n",
      "|    time_elapsed     | 61       |\n",
      "|    total_timesteps  | 43304    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.6e+03  |\n",
      "|    n_updates        | 8325     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 148      |\n",
      "|    ep_rew_mean      | 1.06e+03 |\n",
      "|    exploration_rate | 0.792    |\n",
      "| time/               |          |\n",
      "|    episodes         | 304      |\n",
      "|    fps              | 706      |\n",
      "|    time_elapsed     | 62       |\n",
      "|    total_timesteps  | 43868    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.64e+03 |\n",
      "|    n_updates        | 8466     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 149      |\n",
      "|    ep_rew_mean      | 1.07e+03 |\n",
      "|    exploration_rate | 0.789    |\n",
      "| time/               |          |\n",
      "|    episodes         | 308      |\n",
      "|    fps              | 703      |\n",
      "|    time_elapsed     | 63       |\n",
      "|    total_timesteps  | 44514    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.71e+03 |\n",
      "|    n_updates        | 8628     |\n",
      "----------------------------------\n",
      "----------------------------------\n",
      "| rollout/            |          |\n",
      "|    ep_len_mean      | 146      |\n",
      "|    ep_rew_mean      | 1.03e+03 |\n",
      "|    exploration_rate | 0.786    |\n",
      "| time/               |          |\n",
      "|    episodes         | 312      |\n",
      "|    fps              | 701      |\n",
      "|    time_elapsed     | 64       |\n",
      "|    total_timesteps  | 44974    |\n",
      "| train/              |          |\n",
      "|    learning_rate    | 0.0001   |\n",
      "|    loss             | 6.75e+03 |\n",
      "|    n_updates        | 8743     |\n",
      "----------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sb3_contrib import QRDQN\n",
    "from stable_baselines3.common.env_checker import check_env\n",
    "\n",
    "env = TwentyFortyEightEnv()\n",
    "check_env(env)\n",
    "\n",
    "model = QRDQN(\n",
    "    \"MlpPolicy\",\n",
    "    env,\n",
    "    verbose=1,\n",
    "    learning_rate=1e-4,\n",
    "    buffer_size=200_000,\n",
    "    batch_size=512,\n",
    "    learning_starts=10_000,\n",
    "    exploration_fraction=0.2,\n",
    "    exploration_final_eps=0.05,\n",
    "    target_update_interval=1_000,\n",
    "    train_freq=4,\n",
    ")\n",
    "\n",
    "model.learn(total_timesteps=10**6)\n",
    "model.save(\"qr_dqn_2048\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3e64d714",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error: Unexpected observation shape (16,) for Box environment, please use (4, 4) or (n_env, 4, 4) for the observation shape.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m total_reward = \u001b[32m0\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m done:\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m     action, _ = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     14\u001b[39m     obs, reward, terminated, truncated, _ = env.step(action)\n\u001b[32m     15\u001b[39m     done = terminated \u001b[38;5;129;01mor\u001b[39;00m truncated\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.11/site-packages/sb3_contrib/qrdqn/qrdqn.py:271\u001b[39m, in \u001b[36mQRDQN.predict\u001b[39m\u001b[34m(self, observation, state, episode_start, deterministic)\u001b[39m\n\u001b[32m    269\u001b[39m         action = np.array(\u001b[38;5;28mself\u001b[39m.action_space.sample())\n\u001b[32m    270\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m271\u001b[39m     action, state = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepisode_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    272\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m action, state\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.11/site-packages/stable_baselines3/common/policies.py:365\u001b[39m, in \u001b[36mBasePolicy.predict\u001b[39m\u001b[34m(self, observation, state, episode_start, deterministic)\u001b[39m\n\u001b[32m    356\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(observation, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(observation) == \u001b[32m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(observation[\u001b[32m1\u001b[39m], \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m    357\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    358\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mYou have passed a tuple to the predict() function instead of a Numpy array or a Dict. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    359\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mYou are probably mixing Gym API with SB3 VecEnv API: `obs, info = env.reset()` (Gym) \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   (...)\u001b[39m\u001b[32m    362\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mand documentation for more information: https://stable-baselines3.readthedocs.io/en/master/guide/vec_envs.html#vecenv-api-vs-gym-api\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    363\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m365\u001b[39m obs_tensor, vectorized_env = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mobs_to_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    367\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m th.no_grad():\n\u001b[32m    368\u001b[39m     actions = \u001b[38;5;28mself\u001b[39m._predict(obs_tensor, deterministic=deterministic)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.11/site-packages/stable_baselines3/common/policies.py:272\u001b[39m, in \u001b[36mBaseModel.obs_to_tensor\u001b[39m\u001b[34m(self, observation)\u001b[39m\n\u001b[32m    268\u001b[39m     observation = np.array(observation)\n\u001b[32m    270\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(observation, \u001b[38;5;28mdict\u001b[39m):\n\u001b[32m    271\u001b[39m     \u001b[38;5;66;03m# Dict obs need to be handled separately\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m272\u001b[39m     vectorized_env = \u001b[43mis_vectorized_observation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mobservation_space\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    273\u001b[39m     \u001b[38;5;66;03m# Add batch dimension if needed\u001b[39;00m\n\u001b[32m    274\u001b[39m     observation = observation.reshape((-\u001b[32m1\u001b[39m, *\u001b[38;5;28mself\u001b[39m.observation_space.shape))  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.11/site-packages/stable_baselines3/common/utils.py:489\u001b[39m, in \u001b[36mis_vectorized_observation\u001b[39m\u001b[34m(observation, observation_space)\u001b[39m\n\u001b[32m    487\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m space_type, is_vec_obs_func \u001b[38;5;129;01min\u001b[39;00m is_vec_obs_func_dict.items():\n\u001b[32m    488\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(observation_space, space_type):\n\u001b[32m--> \u001b[39m\u001b[32m489\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mis_vec_obs_func\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mobservation_space\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[operator]\u001b[39;00m\n\u001b[32m    490\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    491\u001b[39m     \u001b[38;5;66;03m# for-else happens if no break is called\u001b[39;00m\n\u001b[32m    492\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError: Cannot determine if the observation is vectorized with the space type \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobservation_space\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.venv/lib/python3.11/site-packages/stable_baselines3/common/utils.py:356\u001b[39m, in \u001b[36mis_vectorized_box_observation\u001b[39m\u001b[34m(observation, observation_space)\u001b[39m\n\u001b[32m    354\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m    355\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m356\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    357\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mError: Unexpected observation shape \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobservation.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m for \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    358\u001b[39m         + \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBox environment, please use \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mobservation_space.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    359\u001b[39m         + \u001b[33m\"\u001b[39m\u001b[33mor (n_env, \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m) for the observation shape.\u001b[39m\u001b[33m\"\u001b[39m.format(\u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28mstr\u001b[39m, observation_space.shape)))\n\u001b[32m    360\u001b[39m     )\n",
      "\u001b[31mValueError\u001b[39m: Error: Unexpected observation shape (16,) for Box environment, please use (4, 4) or (n_env, 4, 4) for the observation shape."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sb3_contrib import QRDQN\n",
    "\n",
    "model = QRDQN.load(\"qr_dqn_2048\")\n",
    "\n",
    "env = TwentyFortyEightEnv()\n",
    "obs, _ = env.reset()\n",
    "\n",
    "done = False\n",
    "total_reward = 0\n",
    "\n",
    "while not done:\n",
    "    action, _ = model.predict(obs, deterministic=True)\n",
    "    obs, reward, terminated, truncated, _ = env.step(action)\n",
    "    done = terminated or truncated\n",
    "    total_reward += reward\n",
    "\n",
    "    print(env.board)\n",
    "    print(\"Reward:\", total_reward)\n",
    "    input(\"Press Enter for next step...\")\n",
    "\n",
    "print(\"Final Score:\", env.score)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
